[
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "18  Referencias",
    "section": "",
    "text": "Baker, M. (2016). 1,500 scientists lift the lid on reproducibility. Nature, 533(7604), 452–454. https://doi.org/10.1038/533452a\nBelsley, D. A., Kuh, E., & Welsch, R. E. (1980). Regression Diagnostics: Identifying Influential Data and Sources of Collinearity. Wiley. https://doi.org/10.1002/0471725153\nBryan, J. (2018). Happy Git and GitHub for the useR. https://happygitwithr.com/\nCleveland, W. S. (1993). Visualizing Data. Hobart Press.\nCohen, J., Cohen, P., West, S. G., & Aiken, L. S. (2003). Applied multiple regression/correlation analysis for the behavioral sciences (3rd ed.). Lawrence Erlbaum Associates Publishers.\nCui, B. (2020). Automate Data Exploration and Treatment [R package DataExplorer version 0.8.2]. R-Project.org. https://cran.r-project.org/package=DataExplorer\nDraper, N. R., & Smith, H. (1998). Applied Regression Analysis (3rd ed.). Wiley. https://doi.org/10.1002/9781118625590\nField, A. P. (2013). Discovering statistics using IBM SPSS statistics: and sex and drugs and rock’n’roll (4th edition). Sage.\nFriendly, M. (2008). A Brief History of Data Visualization. In: Handbook of Data Visualization. Springer Handbooks Comp.Statistics. Springer, Berlin, Heidelberg. https://doi.org/10.1007/978-3-540-33037-0_2\nGentleman, R., & Temple Lang, D. (2007). Statistical analyses and reproducible research. Journal of Computational and Graphical Statistics, 16(1), 1–23. https://doi.org/10.1198/106186007X178663\nHernández, F., Usuga, O., & Mazo, M. (12 de agosto de 2024). Modelos de Regresión con R. Github.io. https://fhernanb.github.io/libro_regresion/\nHmelo-Silver, C. E., Duncan, R. G., & Chinn, C. A. (2007). Scaffolding and achievement in problem-based and inquiry learning: A response to Kirschner, Sweller, and Clark (2006). Educational Psychologist, 42(2), 99–107. https://doi.org/10.1080/00461520701263368\nIhaka, R., & Gentleman, R. (1996). R: A Language for Data Analysis and Graphics. Journal of Computational and Graphical Statistics, 5(3), 299–314. https://doi.org/10.1080/10618600.1996.10474713\nKolb, D. (1984). Experiential learning: Experience as the source of learning and development. Prentice Hall.\nKutner, M. H., Nachtsheim, C. J., Neter, J., & Li, W. (2005). Applied Linear Statistical Models (5th ed.). McGraw-Hill, Irwin, New York.\nLópez, E., & González, B. (2016). Diseño y análisis de experimentos. Internet Archive. https://archive.org/details/DiseoYAnlisisDeExperimentos2016\nMontgomery, D.C., Peck, E.A. and Vining, G.G. (2012) Introduction to Linear Regression Analysis. Vol. 821, John Wiley & Sons, Hoboken.\nMurrell, P. (2018). R Graphics (3rd ed.). Chapman and Hall/CRC. https://doi.org/10.1201/9780429422768\nNational Academies of Sciences, Engineering, and Medicine. (2019). Reproducibility and replicability in science. National Academies Press. https://doi.org/10.17226/25303\nR Core Team. (2023). R: A Language and Environment for Statistical Computing. R Foundation for Statistical Computing. https://www.r-project.org/\nRosales Castillo, J. M. (2005). Micropropagación de Calahuala Phlebodium psedoaureum (Cav.) Lellinger con tres tipos de explantes en diferentes medios de cultivo in vitro. Tesis Ing. Agr. Guatemala, Universidad de San Carlos de Guatemala, Facultad de Agronomía. 51 p.\nTabachnick, B., & Fidell, L. (2013). Using Multivariate Statistics (6th ed.). Boston, MA: Pearson.\nThe Turing Way Community. (2023). The Turing Way: A handbook for reproducible, ethical and collaborative research. https://the-turing-way.netlify.app\nTufte, E. (2001). The Visual Display of Quantitative Information (2nd ed.). Graphics Press.\nTukey, J. W. (1977). Exploratory Data Analysis. Addison-Wesley.\nVenables, W. N., & Ripley, B. D. (2002). Modern Applied Statistics with S (4th ed.). Springer. https://doi.org/10.1007/978-0-387-21706-2\nWickham, H. (2016). ggplot2: Elegant graphics for data analysis (2. ed.). Springer Cham. https://doi.org/10.1007/978-3-319-24277-4\nWilkinson, L. (2005). The grammar of graphics (2nd ed.). Springer. https://doi.org/10.1007/0-387-28695-0\nWilkinson, M. D. et al. (2016). The FAIR Guiding Principles for scientific data management and stewardship. Scientific Data 3, 160018. https://doi.org/10.1038/sdata.2016.18\nXie, Y., Allaire, J.J., & Grolemund, G. (2018). R Markdown: The Definitive Guide (1st ed.). Chapman and Hall/CRC. https://doi.org/10.1201/9781138359444",
    "crumbs": [
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Referencias</span>"
    ]
  },
  {
    "objectID": "01_cbasicos.html",
    "href": "01_cbasicos.html",
    "title": "1  Conceptos básicos de R",
    "section": "",
    "text": "1.1 ¿Qué es R?\nR es un lenguaje de programación y un entorno computacional ampliamente empleado en el análisis estadístico, la visualización de datos y la investigación científica. Desarrollado por Ross Ihaka y Robert Gentleman en 1996, R fue concebido como una herramienta flexible y potente para realizar análisis reproducibles y generar visualizaciones de alta calidad (Ihaka & Gentleman, 1996). Desde entonces, se ha consolidado como una de las opciones preferidas en los ámbitos científico, académico y profesional.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Conceptos básicos de R</span>"
    ]
  },
  {
    "objectID": "01_cbasicos.html#qué-es-r",
    "href": "01_cbasicos.html#qué-es-r",
    "title": "1  Conceptos básicos de R",
    "section": "",
    "text": "1.1.1 Características principales de R\nR destaca por su enfoque en el análisis estadístico, permitiendo desde pruebas básicas como t-tests y ANOVA hasta modelos avanzados de regresión y análisis multivariado. Ofrece potentes herramientas de visualización, como el paquete ggplot2, que facilitan la creación de gráficos personalizables y de alta calidad para explorar y comunicar patrones en los datos.\nComo software de código abierto, R es gratuito y accesible, lo que fomenta la colaboración y el desarrollo continuo por parte de una comunidad global. Su extensibilidad es notable: existen más de 19,000 paquetes disponibles en CRAN hasta 2023, que amplían sus capacidades para tareas especializadas como análisis genómico, minería de texto o modelado espacial (R Core Team, 2023).\nR también promueve la reproducibilidad científica, ya que permite documentar los análisis en scripts, facilitando la replicación de resultados. Además, es interoperable con otros lenguajes como Python, C++ y SQL, y admite diversos formatos de datos, incluyendo CSV, Excel, JSON y bases de datos relacionales.\n\n\n1.1.2 ¿Por qué es especial R?\nMás allá de ser una herramienta para cálculos estadísticos, R constituye un entorno integral para la manipulación de datos, la generación de gráficos y la automatización de flujos de trabajo. Su flexibilidad y capacidad de personalización lo hacen ideal para investigadores, analistas y profesionales de distintas áreas. La comunidad activa que lo respalda impulsa el desarrollo constante de nuevos paquetes y recursos, asegurando su evolución continua.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Conceptos básicos de R</span>"
    ]
  },
  {
    "objectID": "01_cbasicos.html#qué-es-rstudio",
    "href": "01_cbasicos.html#qué-es-rstudio",
    "title": "1  Conceptos básicos de R",
    "section": "1.2 ¿Qué es RStudio?",
    "text": "1.2 ¿Qué es RStudio?\nRStudio es un Entorno de Desarrollo Integrado (IDE) creado para facilitar el trabajo con el lenguaje de programación R. Su diseño proporciona una interfaz clara y organizada, compuesta por paneles que permiten acceder de manera eficiente a las principales herramientas y funciones necesarias para el análisis estadístico y la visualización de datos (Allaire et al., 2022).\n\n\n\n\n\n\n1.2.1 Características principales de RStudio\nUna de las ventajas más notables de RStudio es su sistema de proyectos, que permite gestionar archivos, scripts y datos de manera estructurada, asignando a cada proyecto su propio directorio de trabajo. Esto contribuye a mantener la organización y favorece la reproducibilidad de los análisis realizados.\nRStudio es compatible con una amplia variedad de formatos de datos, como CSV, Excel, HTML y bases de datos SQL. Además, facilita la creación de gráficos interactivos y aplicaciones web mediante paquetes especializados como shiny y plotly. La integración con paquetes de R es sencilla, permitiendo instalar, actualizar y gestionar extensiones como ggplot2, dplyr y tidyr, lo que amplía considerablemente las capacidades del entorno.\nEste IDE es multiplataforma, disponible para Windows, macOS y Linux, lo que lo hace accesible para usuarios de diferentes sistemas operativos. Además, ofrece opciones de personalización, permitiendo modificar la apariencia, los atajos de teclado y la disposición de los paneles, así como integrar herramientas externas como Git para el control de versiones.\n\n\n1.2.2 Beneficios de usar RStudio\nEl uso de RStudio aporta beneficios significativos: incrementa la eficiencia al organizar y agilizar las tareas de análisis de datos, promueve la reproducibilidad mediante herramientas como R Markdown y el sistema de proyectos, y resulta accesible tanto para principiantes como para usuarios avanzados gracias a su interfaz gráfica. Asimismo, su flexibilidad permite trabajar con datos, gráficos, modelos estadísticos y aplicaciones interactivas en un solo entorno, adaptándose a diversas necesidades analíticas (Allaire et al., 2022).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Conceptos básicos de R</span>"
    ]
  },
  {
    "objectID": "01_cbasicos.html#reproducibilidad-y-replicabilidad-en-la-investigación-científica",
    "href": "01_cbasicos.html#reproducibilidad-y-replicabilidad-en-la-investigación-científica",
    "title": "1  Conceptos básicos de R",
    "section": "1.3 Reproducibilidad y replicabilidad en la investigación científica",
    "text": "1.3 Reproducibilidad y replicabilidad en la investigación científica\nLa reproducibilidad y la replicabilidad constituyen principios esenciales en la investigación científica moderna. Diversos estudios han señalado que una proporción significativa de investigadores enfrenta dificultades para replicar estudios previos, principalmente debido a la falta de documentación adecuada en los análisis originales (Baker, 2016). Herramientas tradicionales como Excel o Infostat suelen ocultar parte de los cálculos y requieren ajustes manuales en los gráficos, lo que complica la replicación exacta de los resultados.\n\n1.3.1 El papel de R en la reproducibilidad\nR se distingue por su capacidad para documentar de manera precisa cada paso del análisis a través de scripts. Esta característica permite que los procedimientos sean replicados y reinterpretados en el futuro, incrementando la transparencia y la credibilidad científica. Además, facilita la reutilización de métodos en nuevos estudios, optimizando tanto el tiempo como los recursos. Un script en R puede compararse con una receta detallada, donde cada paso está claramente especificado y puede adaptarse a diferentes conjuntos de datos según las necesidades del análisis.\n\n\n\n\n\n\n\n1.3.2 Definición y características de la reproducibilidad\nLa reproducibilidad se refiere a la posibilidad de obtener los mismos resultados utilizando los mismos datos y métodos empleados en el análisis original. Este principio es fundamental para verificar y validar los hallazgos científicos, ya que permite que otros investigadores, o el propio autor, puedan replicar los resultados siempre que dispongan de los datos y procedimientos originales (National Academies of Sciences, Engineering, and Medicine, 2019). Para lograr la reproducibilidad, es indispensable contar con acceso a los datos originales y una documentación detallada de los métodos utilizados, asegurando que los resultados sean consistentes al repetir el análisis.\nLa reproducibilidad fomenta la transparencia, facilita la verificación de los resultados y promueve la colaboración científica, ya que otros investigadores pueden comprender y construir sobre el trabajo existente.\n\n\n1.3.3 Definición y características de la replicabilidad\nPor su parte, la replicabilidad implica la obtención de resultados consistentes al realizar un estudio similar en un contexto diferente, utilizando nuevos datos o métodos ajustados. Este concepto evalúa la capacidad de generalización de los hallazgos y su aplicabilidad en distintos escenarios (National Academies of Sciences, Engineering, and Medicine, 2019). La replicabilidad requiere el uso de datos diferentes, la adaptación de los métodos y la obtención de resultados coherentes con los del estudio original, aunque no necesariamente idénticos.\nLa replicabilidad permite evaluar la generalización de los resultados, refuerza la credibilidad científica y facilita la extensión del conocimiento a nuevas aplicaciones o contextos.\n\n\n1.3.4 Beneficios de utilizar R para la ciencia reproducible\nEl uso de R en la investigación científica aporta ventajas significativas para la reproducibilidad y la replicabilidad. El código generado en R es accesible para revisión por pares, lo que incrementa la transparencia de los análisis (The Turing Way Community, 2023). Además, los métodos desarrollados pueden ser reutilizados en nuevos estudios, optimizando recursos y tiempo (Gentleman & Temple Lang, 2007). R también facilita el cumplimiento de los principios FAIR (Findable, Accessible, Interoperable, Reusable), promoviendo una gestión adecuada y responsable de los datos científicos (Wilkinson et al., 2016).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Conceptos básicos de R</span>"
    ]
  },
  {
    "objectID": "02_instalacion_confi.html",
    "href": "02_instalacion_confi.html",
    "title": "2  Instalación y configuración",
    "section": "",
    "text": "2.1 Descarga de R y RStudio\nAntes de comenzar a trabajar con R y RStudio, es fundamental realizar la instalación y configuración de ambos programas. R es un lenguaje de programación y entorno computacional ampliamente utilizado en el análisis estadístico, la visualización de datos y la investigación reproducible (Ihaka & Gentleman, 1996). Por su parte, RStudio es un Entorno de Desarrollo Integrado (IDE, por sus siglas en inglés) diseñado específicamente para trabajar con R, proporcionando una interfaz amigable y herramientas avanzadas que optimizan el flujo de trabajo (Allaire et al., 2022). Esta sección detalla los pasos necesarios para descargar, instalar y configurar ambos programas, asegurando un entorno de trabajo funcional y eficiente.\nPara utilizar R y RStudio, es necesario descargar ambos programas. Mientras que R proporciona el núcleo del lenguaje y las herramientas computacionales, RStudio actúa como una interfaz que simplifica su uso y mejora la experiencia del usuario.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Instalación y configuración</span>"
    ]
  },
  {
    "objectID": "02_instalacion_confi.html#descarga-de-r-y-rstudio",
    "href": "02_instalacion_confi.html#descarga-de-r-y-rstudio",
    "title": "2  Instalación y configuración",
    "section": "",
    "text": "2.1.1 Descarga de R\nSe recomienda descargar una versión estable de R para evitar posibles incompatibilidades con paquetes que aún no han sido actualizados para las versiones más recientes. Por ejemplo, la versión R 4.4.2 es reconocida por su estabilidad y amplio soporte en la comunidad (R Core Team, 2023).\nEl repositorio oficial de R está disponible en https://cran.r-project.org/bin/windows/base/old/, donde se pueden encontrar todas las versiones publicadas. Para descargar una versión específica, basta con seleccionar el nombre de la versión deseada y, posteriormente, hacer clic en el archivo con terminación -win.exe para iniciar la descarga del instalador.\n\n\n2.1.2 Descarga de RStudio\nLa descarga de RStudio se realiza desde su página oficial, donde se encuentra la versión más reciente para distintos sistemas operativos. Para usuarios de Windows, se debe seleccionar la opción “Download RStudio Desktop for Windows”. En caso de utilizar macOS o Linux, la misma página ofrece las versiones correspondientes para estos sistemas (Allaire et al., 2022).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Instalación y configuración</span>"
    ]
  },
  {
    "objectID": "02_instalacion_confi.html#instalación-de-r-y-rstudio",
    "href": "02_instalacion_confi.html#instalación-de-r-y-rstudio",
    "title": "2  Instalación y configuración",
    "section": "2.2 Instalación de R y RStudio",
    "text": "2.2 Instalación de R y RStudio\nLa instalación de R y RStudio debe realizarse en un orden específico para evitar conflictos y errores. A continuación, se describen los pasos detallados para cada programa:\n\n2.2.1 Instalación de R\nUna vez descargado el instalador de R, se debe ejecutar el archivo .exe y seguir las instrucciones del asistente de instalación. Generalmente, es suficiente con aceptar las configuraciones predeterminadas, salvo que se requiera una configuración personalizada.\n\n\n2.2.2 Instalación de RStudio\nDespués de instalar R, se procede a ejecutar el instalador de RStudio previamente descargado. Al igual que en el caso de R, se pueden aceptar las opciones predeterminadas durante la instalación. Es importante destacar que RStudio permite gestionar múltiples versiones de R en un mismo dispositivo, lo que resulta útil para trabajar en proyectos que requieren versiones específicas del lenguaje. Esta selección se realiza desde la configuración de RStudio (R Core Team, 2023).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Instalación y configuración</span>"
    ]
  },
  {
    "objectID": "02_instalacion_confi.html#configuración-inicial",
    "href": "02_instalacion_confi.html#configuración-inicial",
    "title": "2  Instalación y configuración",
    "section": "2.3 Configuración inicial",
    "text": "2.3 Configuración inicial\nUna vez completada la instalación de R y RStudio, es recomendable realizar una configuración inicial que permita personalizar el entorno de trabajo, mejorar la organización y facilitar el desarrollo de análisis estadísticos. Estas configuraciones optimizan la experiencia del usuario y contribuyen a un flujo de trabajo más eficiente (Allaire et al., 2022). A continuación, se describen los pasos esenciales para configurar RStudio de manera eficiente.\n\n2.3.1 Seleccionar la versión de R\nRStudio permite elegir la versión de R que se utilizará, esto es especialmente útil si se tienen múltiples versiones instaladas en el mismo dispositivo. Esta funcionalidad garantiza la compatibilidad con proyectos que requieren versiones específicas del lenguaje (R Core Team, 2023). Para configurar la versión de R en RStudio, se deben seguir los siguientes pasos:\n\nIr a Tools &gt; Global Options &gt; General.\nEn el apartado R version, seleccionar la versión deseada de R.\n\n\n\n2.3.2 Configurar la apariencia de RStudio\nRStudio ofrece opciones de personalización para adaptar su apariencia a las preferencias del usuario, mejorando la experiencia de trabajo y reduciendo la fatiga visual durante sesiones prolongadas (Allaire et al., 2022). A continuación, se detallan las configuraciones principales:\n\n2.3.2.1 Cambiar el tema de la interfaz\n\nEn la barra de menú, se debe seleccionar Tools &gt; Global Options.\nEn la ventana emergente, se accede a la pestaña Appearance.\nEn esta sección, es posible elegir entre diferentes temas para la interfaz, como temas claros u oscuros. Por ejemplo, los temas oscuros como Cobalt son recomendables para reducir la fatiga visual.\nTambién se pueden ajustar el tamaño y el tipo de fuente para facilitar la lectura del código, según las preferencias del usuario.\n\n\n\n2.3.2.2 Configurar el panel de trabajo\nLa interfaz de RStudio está organizada en cuatro paneles principales: el editor de scripts, la consola, el entorno/archivos y los gráficos/ayuda. Estos paneles pueden reorganizarse según las necesidades del usuario para optimizar el flujo de trabajo. Los pasos para configurar los paneles son:\n\nDesde la barra de menú, se selecciona Tools &gt; Global Options &gt; Pane Layout.\nEn esta sección, se ajusta la disposición de los paneles. Por ejemplo, se puede colocar el editor de scripts en la parte superior izquierda y la consola en la parte inferior para facilitar el acceso.\nGuardar los cambios para aplicar la nueva disposición.\n\n\n\n2.3.2.3 Habilitar el número de líneas en el editor de scripts\nLa numeración de líneas en el editor de scripts facilita la navegación y depuración del código. Para habilitar esta opción:\n\nSe accede a Tools &gt; Global Options &gt; Code &gt; Display.\nEn esta sección, se marca la casilla Show line numbers para activar la numeración de líneas.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Instalación y configuración</span>"
    ]
  },
  {
    "objectID": "02_instalacion_confi.html#organización-de-proyectos",
    "href": "02_instalacion_confi.html#organización-de-proyectos",
    "title": "2  Instalación y configuración",
    "section": "2.4 Organización de proyectos",
    "text": "2.4 Organización de proyectos\nLa organización adecuada de proyectos en RStudio es fundamental para lograr un flujo de trabajo eficiente, reproducible y estructurado. Una gestión ordenada de archivos y scripts no solo facilita el desarrollo de los análisis, sino que también mejora la colaboración y la reproducibilidad de los resultados (Allaire et al., 2022).\n\n2.4.1 Crear un proyecto en RStudio\nPara organizar los archivos, datos y scripts de un análisis específico, RStudio permite crear proyectos siguiendo estos pasos:\n\nEn la barra de menú, selecciona File &gt; New Project.\nElige entre las opciones disponibles:\n\nNew Directory: Crea un proyecto desde cero en una nueva carpeta.\nExisting Directory: Convierte una carpeta existente en un proyecto de RStudio.\nVersion Control: Clona un repositorio de Git para trabajar en un proyecto versionado.\n\nConfigurar el nombre y la ubicación del proyecto.\nHacer clic en Create Project para finalizar la configuración.\n\nEl uso de proyectos en RStudio permite mantener una estructura clara y organizada, lo que facilita la gestión de los recursos necesarios para el análisis (Allaire et al., 2022).\n\n\n2.4.2 Establecer un directorio de trabajo\nEl directorio de trabajo es la carpeta donde R buscará los archivos y guardará los resultados generados durante el análisis. Para establecerlo manualmente, se puede utilizar la función setwd(), como se muestra a continuación:\n\n# Establecer directorio de trabajo\nsetwd(\"ruta/del/directorio\")\n\nNo obstante, al trabajar con proyectos en RStudio, el directorio de trabajo se configura automáticamente al abrir el archivo del proyecto, lo que elimina la necesidad de establecerlo manualmente y reduce errores relacionados con rutas incorrectas (R Core Team, 2023).\n\n\n2.4.3 Uso de archivos .Rproj\nEl archivo .Rproj es el elemento central de cada proyecto en RStudio. Este archivo almacena las configuraciones específicas del proyecto, como el directorio de trabajo, las opciones de visualización y otros ajustes personalizados. Al abrir un archivo .Rproj, se carga automáticamente el entorno de trabajo asociado, lo que facilita la continuidad y la gestión del análisis.\n\n\n2.4.4 Beneficios de la organización de proyectos\nLa correcta organización de proyectos en RStudio ofrece varios beneficios clave:\n\nReproducibilidad: Facilita que otros usuarios (o el propio usuario en el futuro) comprendan y reproduzcan el análisis, asegurando que los resultados sean consistentes.\nEficiencia: Reduce el tiempo perdido buscando archivos o configurando rutas manualmente, permitiendo un enfoque más directo en el análisis.\nColaboración: Mejora la comunicación y el trabajo en equipo al mantener una estructura clara y consistente, especialmente en proyectos compartidos.\nOptimización del flujo de trabajo: La combinación de una apariencia personalizada y una estructura organizada permite al usuario enfocarse en el análisis de datos de manera más eficiente y profesional (Allaire et al., 2022).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Instalación y configuración</span>"
    ]
  },
  {
    "objectID": "03_inicio.html",
    "href": "03_inicio.html",
    "title": "3  Primeros pasos en R",
    "section": "",
    "text": "3.1 Creación de scripts en RStudio\nIniciar el trabajo en R y RStudio puede resultar desafiante para quienes no están familiarizados con estos entornos, pero una orientación adecuada facilita considerablemente el proceso. Esta sección guía al usuario en los aspectos fundamentales para comenzar a programar en R, desde la creación de scripts hasta la comprensión de los objetos básicos del lenguaje. Estos conocimientos iniciales son esenciales para establecer un flujo de trabajo eficiente y reproducible (Allaire et al., 2022).\nEl script es el archivo principal donde se escribe, guarda y ejecuta el código en R. Utilizar scripts no solo permite desarrollar análisis de datos, sino también documentar cada paso del proceso, lo que contribuye a la reproducibilidad y la organización del trabajo. Para crear un script en RStudio, se puede optar por dos métodos:\nUna vez creado, el script se convierte en el espacio central para el desarrollo de los análisis. Es recomendable guardar el archivo desde el inicio para evitar la pérdida de información y facilitar la gestión de versiones.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Primeros pasos en R</span>"
    ]
  },
  {
    "objectID": "03_inicio.html#creación-de-scripts-en-rstudio",
    "href": "03_inicio.html#creación-de-scripts-en-rstudio",
    "title": "3  Primeros pasos en R",
    "section": "",
    "text": "Desde la barra de menú, seleccionar File &gt; New File &gt; R Script.\nUtilizar el atajo de teclado Ctrl + Shift + N para abrir un nuevo script de manera rápida.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Primeros pasos en R</span>"
    ]
  },
  {
    "objectID": "03_inicio.html#guardado-y-organización-de-archivos",
    "href": "03_inicio.html#guardado-y-organización-de-archivos",
    "title": "3  Primeros pasos en R",
    "section": "3.2 Guardado y organización de archivos",
    "text": "3.2 Guardado y organización de archivos\nUna gestión adecuada de los archivos es esencial para mantener la eficiencia y la reproducibilidad en el trabajo con R y RStudio. El uso de nombres descriptivos, la organización en carpetas y la documentación clara de los scripts contribuyen a un entorno de trabajo ordenado y profesional (Allaire et al., 2022).\n\n3.2.1 Guardado de scripts y archivos\nPara guardar un script en RStudio, se debe seleccionar la opción “Save As…” en el menú “File”, lo que permite definir tanto la ubicación como el nombre del archivo. Es recomendable emplear nombres que reflejen el contenido y propósito del archivo, por ejemplo: “analisis_rendimiento.R” para scripts o “datos_suelo_2023.csv” para archivos de datos. Además, se sugiere evitar espacios y caracteres especiales en los nombres, utilizando guiones bajos (_) o guiones medios (-) para separar palabras, lo que previene posibles errores en la ejecución del código. Incluir fechas en formato estándar (YYYY-MM-DD) facilita la identificación de versiones y actualizaciones, como en “2023-10-15_importacion_datos.R”.\n\n\n3.2.2 Organización de directorios y proyectos\nLa estructura de carpetas es clave para mantener el orden en los proyectos. Se recomienda crear una carpeta específica para cada proyecto, agrupando en ella todos los scripts, datos y resultados relacionados. Al trabajar con archivos de proyecto .Rproj, RStudio configura automáticamente el directorio de trabajo, lo que simplifica la gestión de archivos y reduce errores asociados a rutas incorrectas (R Core Team, 2023).\n\n\n3.2.3 Buenas prácticas para la organización de archivos\nPara optimizar la organización y facilitar la colaboración, se aconseja:\n\nEstandarizar los nombres de archivos, siguiendo un formato uniforme y descriptivo.\nDocumentar los pasos del análisis mediante comentarios claros en los scripts, lo que ayuda a comprender y reproducir el trabajo en el futuro.\nUtilizar proyectos de RStudio (.Rproj) para asegurar que el entorno de trabajo esté correctamente configurado y todos los archivos relevantes se encuentren en la misma ubicación.\nRealizar copias de seguridad periódicas, ya sea mediante sistemas de control de versiones como Git o almacenando archivos importantes en ubicaciones seguras.\n\nLa aplicación de estas prácticas contribuye a un flujo de trabajo más eficiente, facilita la colaboración y asegura la reproducibilidad de los análisis realizados en RStudio (Allaire et al., 2022; R Core Team, 2023).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Primeros pasos en R</span>"
    ]
  },
  {
    "objectID": "03_inicio.html#introducción-a-los-objetos-en-r",
    "href": "03_inicio.html#introducción-a-los-objetos-en-r",
    "title": "3  Primeros pasos en R",
    "section": "3.3 Introducción a los objetos en R",
    "text": "3.3 Introducción a los objetos en R\nEn R, la gestión de datos y resultados se basa en el uso de objetos. Un objeto es una entidad que almacena información y puede tener atributos como nombre, tipo y en algunos casos, dimensiones. Esta estructura permite organizar, manipular y analizar datos de manera eficiente, lo que convierte a los objetos en el pilar fundamental del trabajo en R (R Core Team, 2023).\n\n3.3.1 Creación de objetos en R\nPara crear un objeto en R, se utiliza un operador de asignación, que puede ser = o &lt;-. Sin embargo, el uso de &lt;- es el estándar recomendado por la comunidad de R, ya que mejora la legibilidad del código y sigue las convenciones del lenguaje (Ihaka & Gentleman, 1996). Por ejemplo, para asignar el valor 10 a un objeto llamado x, se escibe:\n\n# Creación del primer objeto en R\nx &lt;- 10\n\nEl valor a la derecha del operador se asigna al nombre del objeto a la izquierda. Este método facilita la organización y claridad del código.\n\n\n3.3.2 Buenas prácticas y documentación\nEn R, el símbolo numeral # se utiliza para incluir comentarios en el código. Los comentarios no son ejecutados y sirven para documentar el propósito de cada línea o bloque, facilitando la comprensión y el mantenimiento del script tanto para el autor como para otros usuarios (Ihaka & Gentleman, 1996).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Primeros pasos en R</span>"
    ]
  },
  {
    "objectID": "03_inicio.html#tipos-principales-de-objetos-en-r",
    "href": "03_inicio.html#tipos-principales-de-objetos-en-r",
    "title": "3  Primeros pasos en R",
    "section": "3.4 Tipos principales de objetos en R",
    "text": "3.4 Tipos principales de objetos en R\nR permite trabajar con diferentes tipos de objetos, cada uno adecuado para almacenar y manipular distintos tipos de datos. Los más comunes son:\n\n3.4.1 Objetos Numéricos\nLos objetos numéricos almacenan datos como números enteros o decimales. Son esenciales para representar variables cuantitativas, como edad, altura o peso.\nEjemplo de creación de objetos numéricos:\n\n# Creación de objetos numéricos\nedad &lt;- 21 \naltura_m &lt;- 1.70 \npeso_lb &lt;- 150\n\n\n\n3.4.2 Objetos de Texto\nLos objetos de texto, también conocidos como objetos de tipo carácter, almacenan cadenas de texto. Estos se escriben entre comillas dobles (\") o simples ('). Son útiles para representar información cualitativa, como nombres, descripciones o etiquetas.\nEjemplo de creación de objetos de texto:\n\n# Creación de objetos tipo carácter\nnombre &lt;- \"Juan\" \ncolor_favorito &lt;- \"azul\"\n\n\n\n3.4.3 Objetos de Tipo Factor\nLos objetos de tipo factor se utilizan para almacenar variables categóricas con niveles definidos. Estos niveles representan categorías discretas, como escalas, estados o clasificaciones. Los factores son especialmente útiles en análisis estadísticos, ya que permiten manejar variables categóricas de manera eficiente.\nEjemplo de creación de objetos tipo factor:\n\n# Creación de objetos tipo factor\nestado_civil &lt;- factor(\"soltero\") \nsexo &lt;- factor(\"masculino\")\n\nEn este ejemplo, estado_civil y sexo son factores con un único nivel. Los factores también pueden tener múltiples niveles, que se definen explícitamente al crearlos. Por ejemplo:\n\n# Creación de un factor con múltiples niveles\nestado_civil &lt;- factor(\"soltero\", levels = c(\"soltero\", \"casado\", \"divorciado\"))\nsexo &lt;- factor(\"masculino\", levels = c(\"masculino\", \"femenino\"))\n\n\n\n3.4.4 Objetos Lógicos\nLos objetos lógicos almacenan valores TRUE o FALSE, que resultan de comparaciones lógicas. Estos objetos son esenciales para realizar análisis condicionales, aplicar filtros y evaluaciones condiconales.\nEjemplo de creación de objetos lógicos:\n\n# Creación de objetos lógicos\nmayoria_de_edad &lt;- edad &gt;= 18\nmayoria_de_edad\n\n[1] TRUE\n\n\nEn este ejemplo, el objeto mayoria_de_edad almacenará TRUE si la edad es mayor o igual a 18, y FALSE en caso contrario.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Primeros pasos en R</span>"
    ]
  },
  {
    "objectID": "04_datos.html",
    "href": "04_datos.html",
    "title": "4  Estructuras de datos en R",
    "section": "",
    "text": "4.1 Vectores\nLas estructuras de datos constituyen la base fundamental para el trabajo estadístico y científico en R, ya que permiten organizar, almacenar y manipular información de manera sistemática y eficiente. Gracias a estas estructuras, es posible gestionar desde datos simples, como valores individuales, hasta conjuntos complejos y heterogéneos, adaptándose a las necesidades de distintos tipos de análisis. El dominio de las estructuras de datos facilita la realización de operaciones estadísticas, la transformación de información y la generación de visualizaciones precisas. En R, las principales estructuras de datos incluyen los vectores, matrices, data frames y listas, cada una diseñada para resolver problemas específicos y optimizar el flujo de trabajo en el análisis de datos (R Core Team, 2023).\nLos vectores representan la estructura de datos más fundamental en R, actuando como bloques de construcción para estructuras más complejas como matrices y data frames. Un vector se define como una secuencia ordenada de elementos del mismo tipo (numérico, texto, lógico), organizados de manera unidimensional. Esta característica de homogeneidad en el tipo de datos garantiza la eficiencia y consistencia en las operaciones analíticas (Ihaka & Gentleman, 1996).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Estructuras de datos en R</span>"
    ]
  },
  {
    "objectID": "04_datos.html#vectores",
    "href": "04_datos.html#vectores",
    "title": "4  Estructuras de datos en R",
    "section": "",
    "text": "4.1.1 Tipos de Vectores y su Creación\nEn R, la función c() (concatenar) es la herramienta principal para crear vectores. Esta función permite combinar elementos individuales o incluso otros vectores. Los tipos más comunes de vectores incluyen:\n\n# Vectores numéricos\nedades &lt;- c(17, 20, 18, 25)          # Enteros\nalturas &lt;- c(1.75, 1.68, 1.82, 1.65) # Decimales\n\n# Vectores de texto (character)\nnombres &lt;- c(\"Juan\", \"Ana\", \"Luis\", \"María\")\n\n# Vectores lógicos\n# Creados usando la función c()\nmayores_de_edad &lt;- c(FALSE, TRUE, TRUE, TRUE)\n# O mediante una comparación empleando operadores lógicos  \nmayores_de_edad &lt;- edades &gt;= 18\n\nEn estos ejemplos:\n\nEl vector edades almacena valores numéricos.\nEl vector nombres contiene cadenas de texto.\nEl vector mayores_de_edad almacena valores lógicos (TRUE o FALSE) que resultan de una comparación lógica.\n\nNota importante: R convertirá automáticamente todos los elementos al tipo más general si se intentan combinar diferentes tipos de datos en un mismo vector. Por ejemplo:\n\n# Mezcla de números y texto\nvector_mixto &lt;- c(1, 2, \"tres\")\n# R convertirá todo a texto: \"1\" \"2\" \"tres\"\n\n\n\n4.1.2 Operaciones con Vectores\nLos vectores en R permiten realizar una amplia variedad de operaciones matemáticas, lógicas y de manipulación de datos. Estas operaciones son fundamentales para el análisis estadístico y la transformación de datos. A continuación, se describen algunas de las operaciones más comunes:\n\n4.1.2.1 Acceso a elementos específicos\nSe pueden acceder a elementos individuales de un vector utilizando índices entre corchetes ([]). Los índices en R comienzan en 1.\n\n# Acceder a elementos individuales\nprimer_nombre &lt;- nombres[1]    # \"Juan\"\nultima_edad &lt;- edades[4]       # 25\n\n# Acceder a múltiples elementos\nnombres_seleccionados &lt;- nombres[c(1, 3)]  # \"Juan\" \"Luis\"\n\nEn este ejemplo, edades[1] devuelve el primer elemento del vector edades, que es 17.\n\n\n4.1.2.2 Filtrado de elementos\nEs posible filtrar elementos de un vector aplicando condiciones lógicas. Esto resulta útil para seleccionar subconjuntos de datos.\n\n# Filtrar personas mayores de 20 años\nmayores_20 &lt;- edades[edades &gt; 20]\n\n# Obtener nombres de personas mayores de 20\nnombres_mayores_20 &lt;- nombres[edades &gt; 20]\n\nEn este caso, la condición edades &gt; 20 devuelve un vector con los valores que cumplen la condición, es decir, las edades mayores a 20.\n\n\n4.1.2.3 Combinación de vectores\nLos vectores pueden combinarse para crear nuevos vectores utilizando la función concatenar c().\n\n# Combinar dos vectores\nnuevo_vector &lt;- c(edades, c(22, 21))\nnuevo_vector\n\n[1] 17 20 18 25 22 21\n\n\nAquí, el vector nuevo_vector combina los elementos del vector edades con los valores 22 y 21, generando un nuevo vector.\n\n\n4.1.2.4 Funciones Útiles para Vectores\nR proporciona numerosas funciones para analizar y manipular vectores:\n\n# Estadísticas básicas\npromedio_edades &lt;- mean(edades)       # Media\nedad_maxima &lt;- max(edades)            # Valor máximo\nedad_minima &lt;- min(edades)            # Valor mínimo\ntotal_elementos &lt;- length(edades)      # Número de elementos\n\n# Ordenamiento\nedades_ordenadas &lt;- sort(edades)      # Orden ascendente\nedades_descendente &lt;- sort(edades, decreasing = TRUE)  # Orden descendente\n\n\n\n4.1.2.5 Aplicaciones Prácticas\nLos vectores son fundamentales en análisis estadísticos básicos:\n\n# Análisis descriptivo\nsummary(edades)  # Resumen estadístico\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  17.00   17.75   19.00   20.00   21.25   25.00 \n\ntable(mayores_de_edad)  # Tabla de frecuencias\n\nmayores_de_edad\nFALSE  TRUE \n    1     3 \n\nhist(edades)  # Histograma de edades\n\n\n\n\n\n\n\n\nEsta estructura básica permite realizar análisis preliminares de datos y sirve como fundamento para operaciones más complejas en R. La comprensión sólida de los vectores es esencial para avanzar hacia estructuras de datos más sofisticadas y análisis estadísticos más elaborados.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Estructuras de datos en R</span>"
    ]
  },
  {
    "objectID": "04_datos.html#matrices",
    "href": "04_datos.html#matrices",
    "title": "4  Estructuras de datos en R",
    "section": "4.2 Matrices",
    "text": "4.2 Matrices\nLas matrices en R son estructuras de datos bidimensionales que permiten almacenar información organizada en filas y columnas, donde todos los elementos deben ser del mismo tipo, ya sea numérico, lógico o de texto. Esta homogeneidad garantiza que las operaciones matemáticas y estadísticas se realicen de manera eficiente y sin ambigüedades. Las matrices resultan especialmente útiles en el análisis estadístico y científico, ya que muchos algoritmos y procedimientos requieren datos estructurados en dos dimensiones para su procesamiento (Ihaka & Gentleman, 1996).\nA diferencia de los vectores, que solo permiten una dimensión (una sola fila o columna), las matrices ofrecen una organización más compleja y flexible, facilitando la representación de tablas de datos, resultados de experimentos, o la manipulación de grandes volúmenes de información en análisis multivariados. Por ejemplo, una matriz puede utilizarse para almacenar los resultados de mediciones repetidas en diferentes sujetos o para representar coeficientes en modelos matemáticos.\n\n4.2.1 Creación de Matrices\nEn R, la función principal para crear matrices es matrix(). Esta función permite definir el conjunto de elementos, así como el número de filas (nrow) y columnas (ncol) que tendrá la matriz. Es importante que la cantidad total de elementos coincida con el producto de filas por columnas; de lo contrario, R reciclará los valores para completar la matriz, lo que puede llevar a resultados inesperados si no se verifica cuidadosamente.\n\n# 1. Creación de una matriz de 3 filas y 2 columnas\nmatriz &lt;- matrix(1:6, nrow = 3, ncol = 2)\nprint(matriz)\n\n     [,1] [,2]\n[1,]    1    4\n[2,]    2    5\n[3,]    3    6\n\n# 2. Creación de una matriz de caracteres\nmatriz_caracteres &lt;- matrix(c(\"A\", \"B\", \"C\", \"D\"), nrow = 2, ncol = 2)\nprint(matriz_caracteres)\n\n     [,1] [,2]\n[1,] \"A\"  \"C\" \n[2,] \"B\"  \"D\" \n\n\nEn el primer ejemplo, la matriz llamada matriz almacena números enteros distribuidos en tres filas y dos columnas. En el segundo ejemplo, la matriz matriz_caracteres contiene cadenas de texto, también organizadas en filas y columnas.\n\n\n4.2.2 Manipulación de Matrices\nLas matrices en R permiten realizar una amplia variedad de operaciones matemáticas y de manipulación de datos. Estas operaciones son fundamentales para el análisis estadístico y la transformación de datos. A continuación, se describen algunas de las operaciones más comunes:\n\n4.2.2.1 Acceso a Elementos Específicos\nPara extraer un elemento concreto de una matriz, se utilizan corchetes indicando primero la fila y luego la columna, siguiendo la sintaxis [fila, columna]. Es importante recordar que en R la indexación comienza en 1.\n\n# Acceder al elemento en la segunda fila y primera columna\nelemento &lt;- matriz[2, 1]\nprint(elemento)  # Imprime 2\n\n[1] 2\n\n\nEn este caso, matriz[2, 1] selecciona el valor ubicado en la segunda fila y primera columna de la matriz, que corresponde al número 2.\n\n\n4.2.2.2 Combinación de Matrices\nR permite unir matrices para crear estructuras más grandes, utilizando las funciones rbind() para agregar filas y cbind() para agregar columnas. Esto es útil cuando se desea consolidar datos provenientes de diferentes fuentes o experimentos.\n\n# Crear una segunda matriz\nmatriz2 &lt;- matrix(7:12, nrow = 3, ncol = 2)\n\n# Combinar ambas matrices por filas\nmatriz_combinada &lt;- rbind(matriz, matriz2)\n\n# Resultado:\nprint(matriz_combinada)\n\n     [,1] [,2]\n[1,]    1    4\n[2,]    2    5\n[3,]    3    6\n[4,]    7   10\n[5,]    8   11\n[6,]    9   12\n\n\nEn este ejemplo, matriz_combinada contiene las filas de ambas matrices, una debajo de la otra, formando una nueva matriz de mayor tamaño.\nAdvertencia importante: Todas las columnas de una matriz deben ser del mismo tipo de dato. Si se intenta combinar datos de diferentes tipos (por ejemplo, números y texto), R convertirá todos los elementos al tipo más general, lo que puede alterar la interpretación de los datos. Por ello, se recomienda verificar la consistencia de los tipos de datos antes de crear o manipular matrices.\n\n\n\n4.2.3 Aplicaciones y referencia para álgebra matricial\nLas matrices son ampliamente utilizadas en operaciones de álgebra lineal, como multiplicación de matrices, cálculo de determinantes, inversas y descomposiciones, que son esenciales en modelos estadísticos avanzados y análisis multivariados. Para profundizar en el uso de matrices y su aplicación en el análisis estadístico con R, se recomienda consultar el capítulo 20 del libro Modelos de Regresión con R de Hernández, Usuga y Mazo (2024), donde se aborda el álgebra matricial de manera detallada y aplicada.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Estructuras de datos en R</span>"
    ]
  },
  {
    "objectID": "04_datos.html#data-frames",
    "href": "04_datos.html#data-frames",
    "title": "4  Estructuras de datos en R",
    "section": "4.3 Data frames",
    "text": "4.3 Data frames\nEl data frame es una de las estructuras de datos más importantes y versátiles en R. Se trata de una tabla bidimensional que organiza la información en filas y columnas, de manera similar a una hoja de cálculo de Excel o a una tabla en una base de datos relacional. En un data frame, cada columna corresponde a una variable y está compuesta por un vector, mientras que cada fila representa una observación o caso individual (R Core Team, 2023).\nUna característica fundamental de los data frames es que cada columna puede contener un tipo de dato diferente, como números, texto (caracteres), valores lógicos o factores. Esta flexibilidad permite almacenar y analizar datos heterogéneos de manera eficiente, lo que resulta especialmente útil en contextos como encuestas, experimentos científicos, registros administrativos o cualquier conjunto de datos estructurados. Además, son compatibles con una amplia variedad de funciones y paquetes en R, lo que los convierte en la estructura más utilizada en este lenguaje (Wickham & Grolemund, 2017).\n\n4.3.1 Creación de data frames\nPara crear un data frame en R, se utiliza la función data.frame(), que combina varios vectores de igual longitud. Es importante que todos los vectores tengan la misma cantidad de elementos, ya que cada fila del data frame representa una observación completa. A continuación, se presenta un ejemplo usando los vectores creados en la sección anterior:\n\n# Creación de un data frame con vectores\ndatos &lt;- data.frame(nombres,  edades,  mayores_de_edad)\n\n# Visualización del data frame\ndatos\n\n  nombres edades mayores_de_edad\n1    Juan     17           FALSE\n2     Ana     20            TRUE\n3    Luis     18            TRUE\n4   María     25            TRUE\n\n\nEn este ejemplo, el data frame datos contiene tres columnas:\n\nLa columna nombres contiene texto.\nLa columna edades almacena valores numéricos.\nLa columna mayores_de_edad contiene valores lógicos (TRUE o FALSE).\n\n\n\n4.3.2 Ventajas de un data frame\nLos data frames ofrecen múltiples ventajas que los hacen indispensables para el análisis de datos en R:\n\nEstructura clara: Cada fila representa una observación y cada columna una variable, lo que facilita la interpretación de los datos.\nCompatibilidad: Son compatibles con funciones estadísticas y de visualización, así como con paquetes populares como ggplot2 y dplyr.\nFlexibilidad: Permiten almacenar diferentes tipos de datos en columnas, como números, texto y factores.\nFacilidad de manipulación: Existen numerosas funciones y herramientas para filtrar, seleccionar, transformar y resumir la información contenida en un data frame.\n\n\n\n4.3.3 Manipulación de data frames\nR proporciona diversas formas de manipular data frames, tanto con funciones básicas como con herramientas avanzadas de paquetes especializados. A continuación, se describen algunas operaciones comunes:\n\n4.3.3.1 Acceso a columnas\nPara acceder a una columna específica, se utiliza el operador $ seguido del nombre de la columna:\n\n# Acceso a la columna 'nombres'\ndatos$nombres\n\n[1] \"Juan\"  \"Ana\"   \"Luis\"  \"María\"\n\n\nEsto devuelve el vector correspondiente a la columna seleccionada.\n\n\n4.3.3.2 Filtrado de filas\nEs posible seleccionar filas que cumplan ciertas condiciones lógicas. Por ejemplo, para obtener solo las observaciones donde la edad es mayor a 20:\n\n# Filtrar filas donde la edad sea mayor a 20\ndatos_filtrados &lt;- datos[datos$edades &gt; 20, ]\ndatos_filtrados\n\n  nombres edades mayores_de_edad\n4   María     25            TRUE\n\n\nEn este caso, datos_filtrados contendrá únicamente las filas donde la condición se cumple.\n\n\n\n4.3.4 Otras operaciones comunes\nAdemás de acceder y filtrar datos, los data frames permiten realizar muchas otras operaciones útiles para el análisis y la organización de la información. A continuación se explican algunas de las más frecuentes, acompañadas de ejemplos y explicaciones paso a paso.\n\n4.3.4.1 Agregar nuevas columnas\nEs posible añadir nuevas variables a un data frame simplemente asignando un vector a un nuevo nombre de columna. Por ejemplo, si se desea agregar la altura de cada persona al data frame datos, se puede hacer de la siguiente manera:\n\n# Agregar una columna llamada 'altura' al data frame\ndatos$altura &lt;- c(1.75, 1.60, 1.80, 1.65)\n\nDespués de esta operación, el data frame datos tendrá una columna adicional llamada altura, donde cada valor corresponde a la altura de la persona en la misma fila.\n\n\n4.3.4.2 Seleccionar varias columnas\nEn ocasiones, es útil trabajar solo con un subconjunto de las columnas del data frame, por ejemplo, para enfocar el análisis en ciertas variables. La función subset() permite crear un nuevo data frame que contiene únicamente las columnas seleccionadas:\n\n# Crear un nuevo data frame solo con las columnas 'nombres' y 'edades'\nsubgrupo &lt;- subset(datos, select = c(nombres, edades))\n\nEn este ejemplo, el objeto subgrupo contendrá únicamente las columnas nombres y edades del data frame original.\n\n\n4.3.4.3 Resumir información\nPara obtener una visión general rápida de los datos, R ofrece la función summary(), que genera un resumen estadístico de cada columna del data frame:\n\n# Obtener un resumen estadístico de todas las columnas del data frame\nsummary(datos)\n\n   nombres              edades      mayores_de_edad     altura     \n Length:4           Min.   :17.00   Mode :logical   Min.   :1.600  \n Class :character   1st Qu.:17.75   FALSE:1         1st Qu.:1.637  \n Mode  :character   Median :19.00   TRUE :3         Median :1.700  \n                    Mean   :20.00                   Mean   :1.700  \n                    3rd Qu.:21.25                   3rd Qu.:1.762  \n                    Max.   :25.00                   Max.   :1.800  \n\n\nEl resultado mostrará, para cada columna, información relevante como el valor mínimo, máximo, media, mediana y, en el caso de variables de texto o lógicas, la frecuencia de cada categoría. Esta función es muy útil para explorar y comprender la estructura de los datos antes de realizar análisis más detallados.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Estructuras de datos en R</span>"
    ]
  },
  {
    "objectID": "04_datos.html#listas",
    "href": "04_datos.html#listas",
    "title": "4  Estructuras de datos en R",
    "section": "4.4 Listas",
    "text": "4.4 Listas\nLas listas en R son estructuras de datos sumamente flexibles y potentes, ya que permiten almacenar elementos de diferentes tipos y longitudes dentro de un mismo objeto. A diferencia de los data frames, donde todas las columnas deben tener la misma longitud y cada columna representa una variable, en una lista cada elemento puede ser un vector, un data frame, una matriz, una función, o incluso otra lista. Esta característica hace que las listas sean ideales para guardar resultados complejos, como salidas de modelos estadísticos, colecciones de datos heterogéneos o cualquier conjunto de información que no encaje en una estructura tabular tradicional (R Core Team, 2023).\n\n4.4.1 Creación de listas\nPara crear una lista en R, se utiliza la función list(), donde cada elemento puede tener un nombre y puede ser de cualquier tipo. Por ejemplo:\n\n# Crear una lista con diferentes tipos de elementos\nmi_lista &lt;- list(\n  nombres = c(\"Juan\", \"Ana\"),      # Vector de texto\n  edades = c(18, 20),              # Vector numérico\n  datos_completos = datos          # Data frame\n)\n\nEn este ejemplo, la lista mi_lista contiene tres elementos:\n\nEl elemento nombres es un vector de texto.\nEl elemento edades es un vector numérico.\nEl elemento datos_completos es un data frame.\n\nCada elemento de la lista puede tener un nombre, lo que facilita su identificación y acceso posterior.\n\n\n4.4.2 Acceso a elementos de una lista\nLos elementos de una lista pueden accederse mediante su nombre o índice:\n\nPor nombre: Utilizando el operador $ o corchetes dobles [[ ]]\n\n\n# Acceder al elemento 'nombres' usando $\nmi_lista$nombres\n\n[1] \"Juan\" \"Ana\" \n\n# Acceder al elemento 'nombres' usando corchetes dobles\nmi_lista[[\"nombres\"]]\n\n[1] \"Juan\" \"Ana\" \n\n\nAmbas formas devuelven el vector de nombres almacenado en la lista.\n\nPor índice: Utilizando corchetes dobles [[ ]]:\n\n\n# Acceder al primer elemento de la lista (en este caso, el vector de nombres)\nmi_lista[[1]]\n\n[1] \"Juan\" \"Ana\" \n\n\nEsto es útil cuando se desconoce el nombre del elemento, pero se conoce su posición dentro de la lista.\nAdvertencia importante: Si se utilizan corchetes simples [ ] para acceder a un elemento de la lista, el resultado será una sublista (es decir, una lista que contiene el elemento seleccionado), no el elemento en sí. Para obtener directamente el contenido, siempre utilice corchetes dobles [[ ]] o el operador $ si el elemento tiene nombre.\n\n# Devuelve una sublista\nmi_lista[1]\n\n$nombres\n[1] \"Juan\" \"Ana\" \n\n# Devuelve el elemento directamente\nmi_lista[[1]]\n\n[1] \"Juan\" \"Ana\" \n\n\n\n\n4.4.3 Aplicaciones prácticas\nLas listas en R resultan especialmente valiosas cuando se requiere almacenar y organizar resultados complejos derivados de análisis estadísticos. Por ejemplo, al ajustar un modelo de regresión, la función lm() devuelve una lista que contiene los coeficientes estimados, los residuos, los valores ajustados y otros diagnósticos relevantes. Esta estructura permite acceder fácilmente a cada componente del análisis para su interpretación o procesamiento posterior (R Core Team, 2023).\nAdemás, las listas son ideales para agrupar diferentes tipos de datos relacionados en un solo objeto, como vectores, data frames, matrices o incluso otras listas. Esta capacidad de contener elementos heterogéneos facilita la gestión de información en proyectos de análisis de datos, donde es común trabajar con resultados de distintas etapas o fuentes (Wickham & Grolemund, 2017).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Estructuras de datos en R</span>"
    ]
  },
  {
    "objectID": "04_datos.html#comparación-entre-data-frames-y-listas",
    "href": "04_datos.html#comparación-entre-data-frames-y-listas",
    "title": "4  Estructuras de datos en R",
    "section": "4.5 Comparación entre Data Frames y Listas",
    "text": "4.5 Comparación entre Data Frames y Listas\nEn R, los data frames y las listas son estructuras de datos esenciales, pero se diferencian en su organización y aplicaciones. Los data frames están diseñados para almacenar datos tabulares, donde cada columna puede contener un tipo de dato distinto y cada fila representa una observación, lo que los hace ideales para análisis estadísticos y visualización de datos estructurados. Por otro lado, las listas permiten almacenar elementos de cualquier tipo y longitud, lo que proporciona flexibilidad para manejar resultados complejos o heterogéneos, como salidas de modelos, pruebas estadísticas o combinaciones de diferentes estructuras de datos.\nLa siguiente tabla resume las diferencias principales:\n\n\n\n\n\n\n\n\nCaracterística\nData Frame\nLista\n\n\n\n\nEstructura\nTabular (filas y columnas)\nColección de objetos heterogéneos\n\n\nTipos de datos\nColumnas con tipos diferentes\nElementos de cualquier tipo\n\n\nUso principal\nAnálisis estadístico y visualización\nAlmacenamiento de resultados complejos\n\n\nAcceso a elementos\nPor columnas o índices\nPor nombres o índices\n\n\n\nLa elección entre ambas estructuras depende del tipo de información y del objetivo del análisis. Para datos tabulares, como encuestas o resultados experimentales, se recomienda el uso de data frames. En cambio, para almacenar y manipular resultados complejos o combinaciones de diferentes tipos de datos, las listas resultan más apropiadas (R Core Team, 2023; Wickham & Grolemund, 2017).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Estructuras de datos en R</span>"
    ]
  },
  {
    "objectID": "05_importacion.html",
    "href": "05_importacion.html",
    "title": "5  Importación de datos",
    "section": "",
    "text": "5.1 Configuración previa: el directorio de trabajo\nLa importación de datos es un paso fundamental en cualquier análisis estadístico, ya que permite trabajar con información proveniente de diversas fuentes, como archivos CSV, Excel o páginas web. R proporciona funciones y paquetes especializados para importar datos de manera eficiente y reproducible, lo que facilita el manejo de grandes volúmenes de información (R Core Team, 2023).\nAntes de importar datos, es esencial asegurarse de que el directorio de trabajo esté correctamente configurado. El directorio de trabajo, o working directory, es la carpeta desde la cual R buscará archivos y guardará los resultados generados. Una configuración adecuada del directorio de trabajo contribuye a la organización, reproducibilidad y eficiencia del análisis.\nCuando se utiliza un proyecto de RStudio (.Rproj), el directorio de trabajo se establece automáticamente al abrir el proyecto, lo que simplifica la gestión de archivos. Sin embargo, si se trabaja con scripts independientes, es necesario definir manualmente el directorio utilizando la función setwd(). Por ejemplo:\n# Establecer directorio de trabajo\nsetwd(\"ruta/del/directorio\")\nConfigurar el directorio de trabajo correctamente evita errores como “archivo no encontrado” y asegura que el código sea portable y replicable en diferentes computadoras o ubicaciones.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Importación de datos</span>"
    ]
  },
  {
    "objectID": "05_importacion.html#configuración-previa-el-directorio-de-trabajo",
    "href": "05_importacion.html#configuración-previa-el-directorio-de-trabajo",
    "title": "5  Importación de datos",
    "section": "",
    "text": "5.1.1 Automatización del directorio de trabajo en scripts independientes\nPara scripts que no forman parte de un proyecto, se puede automatizar la configuración del directorio de trabajo utilizando el paquete rstudioapi. Este método establece como directorio de trabajo la carpeta donde está guardado el script, facilitando la portabilidad y colaboración:\n\n# Instalación y carga del paquete rstudioapi\nif (!require(\"rstudioapi\")) install.packages(\"rstudioapi\")\n\n# Linea empleada para establecer  el directorio de trabajo\nsetwd(dirname(rstudioapi::getActiveDocumentContext()$path))\n\nEste código verifica si el paquete rstudioapi está instalado y, de no ser así, lo instala automáticamente. Luego, obtiene la ruta del script actual y la utiliza para definir el directorio de trabajo, permitiendo acceder a los archivos de la carpeta sin necesidad de rutas completas.\n\n\n5.1.2 Verificación y buenas prácticas\nAntes de importar datos o guardar resultados, es recomendable verificar el directorio de trabajo actual con la función getwd():\n\n# Verificación del directorio de trabajo actual\ngetwd()\n\nAdemás, se sugiere guardar el script antes de ejecutar la configuración automática del directorio, ya que R necesita conocer la ubicación del archivo para establecer correctamente el entorno de trabajo.\nSiempre que sea posible, se recomienda trabajar dentro de un proyecto de RStudio, ya que esto automatiza la gestión del directorio de trabajo y mejora la organización de los archivos relacionados con el análisis.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Importación de datos</span>"
    ]
  },
  {
    "objectID": "05_importacion.html#importación-de-archivos-csv-y-excel-en-r",
    "href": "05_importacion.html#importación-de-archivos-csv-y-excel-en-r",
    "title": "5  Importación de datos",
    "section": "5.2 Importación de archivos CSV y Excel en R",
    "text": "5.2 Importación de archivos CSV y Excel en R\nLa importación de datos tabulares es una tarea fundamental en el análisis estadístico. R facilita este proceso mediante funciones y paquetes que permiten trabajar con archivos en formatos ampliamente utilizados, como CSV y Excel. Comprender cómo importar estos archivos correctamente es esencial para garantizar la integridad y reproducibilidad del análisis (Wickham, 2016; Wickham & Bryan, 2023).\n\n5.2.1 Importación de archivos CSV\nLos archivos CSV (Comma-Separated Values) son ampliamente utilizados debido a su simplicidad y compatibilidad con diferentes plataformas. Para importar un archivo CSV en R, se emplea la función read.csv(), que permite leer datos tabulares de manera eficiente. Un ejemplo básico de uso es el siguiente:\n\n# Importar un archivo CSV\ndatos &lt;- read.csv(\"ruta/del/archivo/datos.csv\", \n                  header = TRUE, \n                  sep = \",\")\n\nLos parámetros principales de esta función son:\n\nheader: Indica si la primera fila del archivo contiene los nombres de las columnas (TRUE) o si los datos comienzan desde la primera fila (FALSE).\nsep: Especifica el carácter separador de los valores. Por defecto, es la coma (,), pero puede ajustarse a otros separadores como punto y coma (;) o tabulación (\\t) según el formato del archivo.\n\n\n\n5.2.2 Importación de archivos Excel\nPara trabajar con archivos de Excel (.xlsx), R dispone del paquete readxl, que permite importar datos directamente desde hojas de cálculo sin necesidad de convertir previamente el archivo a otro formato (Wickham & Bryan, 2023). El proceso recomendado es el siguiente:\n\nInstalar y cargar el paquete readxl.\n\n\n# Instalar y cargar el paquete readxl\nif (!require(\"readxl\")) install.packages(\"readxl\")\n\n\nImportar el archivo Excel utilizando la función read_excel():\n\n\n# Importar un archivo Excel\ndatos_excel &lt;- read_excel(\"ruta/del/archivo/datos.xlsx\",\n                          sheet = \"Hoja1\",  \n                          col_names = TRUE/FALSE) \n\nLos parámetros más relevantes son:\n\nsheet: Permite especificar el nombre o el número de la hoja que se desea importar.\ncol_names: Indica si la primera fila debe ser utilizada como nombres de las columnas (TRUE) o si los datos comienzan desde la primera fila (FALSE).",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Importación de datos</span>"
    ]
  },
  {
    "objectID": "05_importacion.html#ejemplo-práctico-base-de-datos-de-estudiantes-usac",
    "href": "05_importacion.html#ejemplo-práctico-base-de-datos-de-estudiantes-usac",
    "title": "5  Importación de datos",
    "section": "5.3 Ejemplo práctico: Base de datos de estudiantes USAC",
    "text": "5.3 Ejemplo práctico: Base de datos de estudiantes USAC\nPara consolidar los conceptos de importación de datos, se utilizará como ejemplo una base de datos recopilada en 2002 en la Universidad de San Carlos de Guatemala. Esta base contiene información de 460 estudiantes de distintas facultades y está disponible tanto en formato CSV como Excel. A lo largo del manual, esta base de datos servirá como referencia para los ejercicios y ejemplos prácticos.\n\n5.3.1 Importación de la base de datos\nA continuación, se muestra cómo importar la base de datos en ambos formatos:\n\nImportar archivo CSV:\n\n\n# Importar datos en formato CSV\ndatos_csv &lt;- read.csv(\"datos_estudiantes.csv\", \n                      header = TRUE, \n                      sep = \",\")\n\n\nImportar archivo Excel: Primero, el usuario se debe asegurar de tener instalado y cargado el paquete readxl.\n\n\n# Instalar y cargar el paquete readxl\nif (!require(\"readxl\")) install.packages(\"readxl\")\n\n\n# Importar datos en formato Excel\ndatos_excel &lt;- read_excel(\"datos_estudiantes_2002.xlsx\",\n                         sheet = \"datos\",\n                         col_names = TRUE)\n\n\n\n5.3.2 Verificación de la importación de datos\nUna vez importados los datos, es fundamental comprobar que la importación se realizó correctamente. R ofrece varias funciones útiles para este propósito:\n\nVisualizar las primeras filas del conjunto de datos:\n\n\n# Visualizar las primeras filas de la base de datos\nhead(datos_csv)\n\n\nExaminar la estructura del data frame:\n\n\n# Examinar la estructura de la base de datos\nstr(datos_csv)\n\n\nObtener un resumen estadístico básico:\n\n\n# Resumen estadístico básico de la base de datos\nsummary(datos_csv)\n\n\nConocer las dimensiones del data frame (número de filas y columnas):\n\n\n# Conocer las dimensiones del data frame\ndim(datos_csv)\n\n\n\n5.3.3 Consideraciones adicionales\n\nUbicación de archivos: Cuando se trabaja con proyectos de RStudio, los archivos deben estar en el directorio del proyecto para facilitar su acceso.\nCodificación de caracteres: En caso de problemas con caracteres especiales (ñ, tildes), se puede especificar la codificación:\n\ndatos &lt;- read.csv(\"archivo.csv\", encoding = \"UTF-8\")",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Importación de datos</span>"
    ]
  },
  {
    "objectID": "06_operadores.html",
    "href": "06_operadores.html",
    "title": "6  Operadores en R",
    "section": "",
    "text": "6.1 Operadores de Asignación\nEn R, los operadores son herramientas fundamentales que permiten realizar cálculos, comparaciones, asignaciones y manipulaciones de datos. Son el equivalente a las herramientas básicas de un taller, que se combinan para construir soluciones más complejas. Comprender su funcionamiento es esencial para aprovechar al máximo las capacidades del lenguaje en el análisis estadístico y la programación (R Core Team, 2023).\nLos operadores en R se clasifican en diferentes categorías según su función. A continuación, se describen los principales tipos de operadores disponibles en el lenguaje, junto con ejemplos prácticos para ilustrar su uso.\nEn R, los operadores de asignación permiten crear objetos y almacenar valores en ellos, lo que constituye una de las bases para la manipulación de datos y la programación en este lenguaje. Los dos operadores de asignación más utilizados son &lt;- y =. Ambos operadores cumplen la función de asignar un valor a un objeto, sin embargo, la convención en la comunidad de R es emplear &lt;-, ya que este evita posibles ambigüedades con el operador lógico de igualdad (==) y mantiene la claridad en el código (Ihaka & Gentleman, 1996).\nPor ejemplo, al ejecutar la instrucción x &lt;- 10, se asigna el valor 10 al objeto x. De manera similar, y = 20 asigna el valor 20 al objeto y, aunque esta forma es menos recomendada en contextos profesionales. Posteriormente, es posible utilizar estos objetos en operaciones, como se muestra a continuación:\n# Asignación de valores a objetos\nx &lt;- 10          \ny = 20           \n\n# Uso de objetos\nx + y    # Resultado: 30\n\n[1] 30\nEs importante destacar que, aunque el operador = puede emplearse para asignar valores, su uso puede generar confusiones, especialmente cuando se trabaja con expresiones lógicas, ya que = también se utiliza en otros contextos dentro del lenguaje. Por esta razón, se recomienda preferir el uso de &lt;- para la asignación de valores en la mayoría de los casos (Ihaka & Gentleman, 1996).",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Operadores en R</span>"
    ]
  },
  {
    "objectID": "06_operadores.html#operadores-aritméticos",
    "href": "06_operadores.html#operadores-aritméticos",
    "title": "6  Operadores en R",
    "section": "6.2 Operadores aritméticos",
    "text": "6.2 Operadores aritméticos\nLos operadores aritméticos permiten realizar operaciones matemáticas básicas y avanzadas. Son fundamentales para trabajar con datos numéricos y realizar cálculos en análisis estadísticos. Estos operadores operan sobre valores numéricos y devuelven resultados numéricos. Los operadores aritméticos permiten realizar operaciones matemáticas básicas y avanzadas. Son fundamentales para trabajar con datos numéricos y realizar cálculos en análisis estadísticos. Estos operadores operan sobre valores numéricos y devuelven resultados numéricos (R Core Team, 2023).\nA continuación se presenta un cuadro con los principales operadores aritméticos disponibles en R y las operaciones que ejecutan:\n\n\n\nOperador\nAcción\nEjemplo\nResultado\n\n\n\n\n+\nSuma\n5 + 3\n8\n\n\n-\nResta\n10 - 4\n6\n\n\n*\nMultiplicación\n6 * 2\n12\n\n\n/\nDivisión\n15 / 3\n5\n\n\n^\nPotencia\n2 ^ 3\n8\n\n\n%/%\nDivisión entera\n17 %/% 5\n3\n\n\n%%\nMódulo o residuo\n17 %% 5\n2",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Operadores en R</span>"
    ]
  },
  {
    "objectID": "06_operadores.html#operadores-lógicos",
    "href": "06_operadores.html#operadores-lógicos",
    "title": "6  Operadores en R",
    "section": "6.3 Operadores lógicos",
    "text": "6.3 Operadores lógicos\nLos operadores lógicos desempeñan un papel fundamental en la evaluación de condiciones y la toma de decisiones dentro del código. Estos operadores permiten comparar valores y establecer reglas condicionales, lo que resulta esencial para tareas como el filtrado de datos, la selección de subconjuntos y la implementación de estructuras de control. Los operadores lógicos trabajan con valores booleanos, es decir, TRUE o FALSE, y su correcta utilización facilita la construcción de análisis estadísticos robustos y flexibles (R Core Team, 2023).\nA continuación, se presenta una tabla que resume los principales operadores lógicos en R, junto con su función, un ejemplo de uso y el resultado esperado:\n\n\n\n\n\n\n\n\n\nOperador\nAcción\nEjemplo\nResultado\n\n\n\n\n&gt;\nMayor que\n5 &gt; 3\nTRUE\n\n\n&lt;\nMenor que\n5 &lt; 3\nFALSE\n\n\n&gt;=\nMayor o igual que\n5 &gt;= 5\nTRUE\n\n\n&lt;=\nMenor o igual que\n5 &lt;= 4\nFALSE\n\n\n==\nIgualdad\n5 == 5\nTRUE\n\n\n!=\nDesigualdad\n5 != 3\nTRUE\n\n\n&\nY lógico (AND)\n(5 &gt; 3) & (4 &gt; 2)\nTRUE\n\n\n|\nO lógico (OR)\n(4 &lt; 2)  | (5 &gt; 3)\nTRUE\n\n\n!\nNegación lógica\n!(5 &gt; 3)\nFALSE\n\n\n\n\n6.3.1 Ejemplo práctico\nA continuación, se muestra un ejemplo práctico, donde se emplean operadores lógicos para realizar comparaciones y evaluaciones condicionales:\n\n# Comparaciones simples\nedad &lt;- 25\nes_mayor &lt;- edad &gt; 18          # TRUE, porque 25 es mayor que 18\nes_menor &lt;- edad &lt; 30          # TRUE, porque 25 es menor que 30\nes_igual &lt;- edad == 25         # TRUE, porque 25 es igual a 25\nes_diferente &lt;- edad != 20     # TRUE, porque 25 es diferente de 20\n\n# Operaciones lógicas compuestas\npeso_Kg &lt;- 70\naltura &lt;- 1.75\nimc &lt;- peso_Kg / (altura^2)    # Cálculo del índice de masa corporal\n\nsobrepeso &lt;- imc &gt;= 25 & imc &lt; 30      \nsobrepeso   # FALSE, el IMC está fuera del rango de sobrepeso\n\n[1] FALSE\n\npeso_normal &lt;- imc &gt;= 18.5 & imc &lt; 25  \npeso_normal # TRUE, el IMC está en el rango de peso normal\n\n[1] TRUE\n\n\nEn este ejemplo, se observa cómo los operadores lógicos permiten evaluar condiciones tanto simples como compuestas, facilitando la clasificación de datos y la toma de decisiones dentro del análisis estadístico en R (R Core Team, 2023).",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Operadores en R</span>"
    ]
  },
  {
    "objectID": "06_operadores.html#operadores-de-manipulación-de-datos",
    "href": "06_operadores.html#operadores-de-manipulación-de-datos",
    "title": "6  Operadores en R",
    "section": "6.4 Operadores de Manipulación de Datos",
    "text": "6.4 Operadores de Manipulación de Datos\nEn R, los operadores de manipulación de datos cumplen una función central en el acceso, selección y modificación de elementos dentro de estructuras como vectores, listas y data frames. El dominio de estos operadores resulta indispensable para trabajar con datos organizados y ejecutar análisis estadísticos de manera eficiente, ya que permiten extraer, transformar y analizar información específica de grandes conjuntos de datos (R Core Team, 2023).\nLa siguiente tabla resume los principales operadores de manipulación de datos en R, su función, un ejemplo de uso y el resultado esperado:\n\n\n\n\n\n\n\n\n\nOperador\nAcción\nEjemplo\nResultado\n\n\n\n\n[]\nAcceso a elementos por posición\nvector[1]\nPrimer elemento del vector\n\n\n[ , ]\nAcceso a filas y columnas en un data frame\ndata[1, 2]\nElemento en la fila 1, columna 2\n\n\n$\nAcceso a una columna específica en un data frame\ndata$columna\nColumna seleccionada\n\n\n:\nCreación de secuencias\n1:10\nSecuencia del 1 al 10\n\n\n\nA continuación, se presenta un ejemplo práctico utilizando fragmentos de código en R para ilustrar el uso de estos operadores:\n\n# Crear un vector\nvector &lt;- c(10, 20, 30, 40, 50)\n\n# Acceder al primer elemento\nvector[1]       # Resultado: 10\n\n[1] 10\n\n# Crear un data frame para el ejemplo\ndata &lt;- data.frame(\n  nombre = c(\"Juan\", \"Ana\", \"Luis\"),\n  edad = c(25, 30, 22),\n  peso = c(70, 65, 80)\n)\n\n# Acceder a una columna\ndata$edad      # Resultado: 25, 30, 22\n\n[1] 25 30 22\n\n# Acceder a un elemento específico\ndata[2, 3]       # Resultado: 65 (peso de Ana)\n\n[1] 65\n\n# Crear una secuencia de números del 1 al 10\nsecuencia &lt;- 1:10   # Resultado: 1, 2, 3, ..., 10               \nsecuencia\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\nEste ejemplo muestra cómo los operadores de manipulación de datos permiten seleccionar elementos individuales, columnas completas o secuencias de valores dentro de las estructuras de datos más utilizadas en R. Estas operaciones son fundamentales para filtrar, transformar y analizar información de manera precisa y eficiente en el entorno estadístico (R Core Team, 2023).",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Operadores en R</span>"
    ]
  },
  {
    "objectID": "06.1_funciones.html",
    "href": "06.1_funciones.html",
    "title": "7  Funciones en R",
    "section": "",
    "text": "7.1 Definición y características de las funciones en R\nLas funciones son uno de los pilares fundamentales de la programación en R. Constituyen bloques de código que encapsulan una serie de instrucciones diseñadas para realizar tareas específicas. Estas permiten automatizar procesos, reducir la repetición de código y mejorar la legibilidad de los scripts. Comprender cómo funcionan las funciones y cómo crearlas es esencial para aprovechar al máximo las capacidades de R en el análisis estadístico y la programación (R Core Team, 2023; Wickham & Grolemund, 2017).\nEsta sección aborda el concepto de función en R, su utilización y el proceso para crear funciones personalizadas que resuelvan necesidades particulares.\nUna función en R se define como un objeto capaz de recibir uno o más valores de entrada, denominados argumentos, ejecutar una serie de operaciones sobre ellos y devolver un resultado. La utilización de funciones permite estructurar el código de manera eficiente y reutilizable, lo que es fundamental para el desarrollo de proyectos complejos (Chambers, 2008).\nToda función en R se compone de tres elementos principales:",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Funciones en R</span>"
    ]
  },
  {
    "objectID": "06.1_funciones.html#definición-y-características-de-las-funciones-en-r",
    "href": "06.1_funciones.html#definición-y-características-de-las-funciones-en-r",
    "title": "7  Funciones en R",
    "section": "",
    "text": "El nombre, que sirve como identificador para invocar la función.\nLos argumentos, que corresponden a los valores de entrada requeridos para ejecutar las operaciones internas.\nEl cuerpo, que contiene el conjunto de instrucciones que determinan el comportamiento de la función.\n\n\n7.1.1 Tipos de funciones\nEn R, las funciones se dividen en dos categorías principales:\n\nLas funciones predefinidas, también conocidas como built-in, están incluidas en el propio lenguaje o en paquetes adicionales. Estas funciones cubren una amplia gama de tareas, como cálculos matemáticos, operaciones estadísticas, manipulación de datos y generación de gráficos.\nLas funciones personalizadas, o user-defined, son creadas por el usuario para abordar necesidades específicas que no se resuelven con las funciones predefinidas. Este tipo de funciones resulta especialmente útil para automatizar procesos repetitivos o implementar cálculos complejos adaptados a un contexto particular.\n\nEl dominio de la creación y el uso de funciones, tanto predefinidas como personalizadas, es clave para desarrollar análisis eficientes y escalables en R (R Core Team, 2023; Wickham & Grolemund, 2017; Chambers, 2008).\n\n\n7.1.2 Funciones predefinidas en R\nLas funciones predefinidas en R constituyen herramientas fundamentales para la realización de operaciones habituales de manera eficiente y directa. Estas funciones, incluidas en el núcleo del lenguaje, permiten efectuar cálculos estadísticos, manipular datos y obtener resúmenes sin necesidad de definir procedimientos adicionales. Su uso facilita la resolución de tareas comunes y contribuye a la claridad del código (R Core Team, 2023).\nA continuación, se presentan ejemplos de algunas funciones predefinidas ampliamente utilizadas, junto con fragmentos de código que ilustran su aplicación:\n\n# Definición de un vector de datos\ndatos &lt;- c(1, 2, 3, 4, 5)\n\n# Cálculo de la media aritmética\nmean(datos)           # Resultado: 3\n\n[1] 3\n\n# Suma de los elementos del vector\nsum(datos)             # Resultado: 15\n\n[1] 15\n\n# Cálculo de la desviación estándar\nsd(datos)        # Resultado: 1.581139\n\n[1] 1.581139\n\n# Resumen estadístico del conjunto de datos\nsummary(datos)   # Resultado:\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n      1       2       3       3       4       5 \n\n\nEstas funciones están disponibles de forma predeterminada en R y permiten realizar análisis estadísticos básicos de manera inmediata, sin requerir definiciones adicionales por parte del usuario. Su dominio es esencial para el trabajo cotidiano con datos en R (R Core Team, 2023).\n\n7.1.2.1 Funciones personalizadas en R\nLas funciones personalizadas permiten al usuario definir procedimientos específicos para resolver problemas que no están cubiertos por las funciones predefinidas. Este tipo de funciones resulta especialmente útil para automatizar tareas repetitivas o implementar cálculos complejos adaptados a necesidades particulares. La creación de funciones personalizadas contribuye a la organización y reutilización del código, facilitando el desarrollo de análisis más eficientes (R Core Team, 2023).\nA continuación, se muestra un ejemplo de cómo definir y utilizar una función personalizada en R para calcular el área de un círculo a partir de su radio:\n\n# Definición de una función personalizada para calcular el área de un círculo\ncalcular_area_circulo &lt;- function(radio) {\n  area &lt;- pi * radio^2\n  return(area)\n}\n\n# Uso de la función personalizada\narea &lt;- calcular_area_circulo(5)   # Resultado: 78.53982\n\nEn este ejemplo, el usuario define la lógica de la función, especifica el argumento necesario (radio) y utiliza la función para obtener el resultado deseado.\n\n\n\n7.1.3 Diferencias entre funciones predefinidas y personalizadas\nLas principales diferencias entre funciones predefinidas y personalizadas en R se resumen en la siguiente tabla:\n\n\n\n\n\n\n\n\nCaracterística\nFunciones predefinidas\nFunciones personalizadas\n\n\n\n\nDisponibilidad\nIncluidas en R o en paquetes\nCreadas por el usuario\n\n\nFlexibilidad\nLimitada a las tareas para las que fueron diseñadas\nTotalmente adaptables a las necesidades del usuario\n\n\nEjemplos\nmean(), sum(), sd(), summary()\ncalcular_area_circulo()\n\n\nReutilización\nReutilizables en cualquier script\nReutilizables si se definen en el entorno o importan\n\n\n\nEsta distinción permite seleccionar el tipo de función más adecuado según el contexto y los objetivos del análisis (R Core Team, 2023).",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Funciones en R</span>"
    ]
  },
  {
    "objectID": "06.1_funciones.html#usos-y-beneficios-de-las-funciones-en-r",
    "href": "06.1_funciones.html#usos-y-beneficios-de-las-funciones-en-r",
    "title": "7  Funciones en R",
    "section": "7.2 Usos y beneficios de las funciones en R",
    "text": "7.2 Usos y beneficios de las funciones en R\nEl empleo de funciones en R aporta ventajas significativas que optimizan el desarrollo y la gestión de proyectos de análisis de datos. La reutilización de código es uno de los principales beneficios, ya que una función definida puede emplearse en distintas partes de un mismo proyecto o en proyectos diferentes, lo que reduce la duplicación y facilita el mantenimiento. Además, las funciones promueven la modularidad, permitiendo descomponer problemas complejos en componentes más simples y manejables, lo que mejora la organización y la estructura del código.\nOtro aspecto relevante es la legibilidad, ya que encapsular operaciones dentro de funciones contribuye a que el código sea más claro y comprensible, facilitando su revisión y colaboración entre usuarios. Asimismo, las funciones permiten automatizar tareas repetitivas, lo que incrementa la eficiencia y ahorra tiempo en la ejecución de procesos rutinarios (R Core Team, 2023; Wickham & Grolemund, 2017).\nA continuación, se presenta un ejemplo de automatización mediante una función personalizada. Si se requiere calcular el área de varios círculos con diferentes radios, basta con aplicar la función previamente definida a un vector de radios, evitando así la repetición manual del cálculo:\n\nradios &lt;- c(1, 2, 3, 4, 5)\n\n# Aplicar la función a cada radio\nareas &lt;- calcular_area_circulo(radios)\nareas  # Resultado:\n\n[1]  3.141593 12.566371 28.274334 50.265482 78.539816\n\n\nEste ejemplo ilustra cómo el uso de funciones personalizadas permite automatizar cálculos y trabajar de manera más eficiente con conjuntos de datos, reafirmando la importancia de las funciones en la programación con R (R Core Team, 2023).",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Funciones en R</span>"
    ]
  },
  {
    "objectID": "06.1_funciones.html#cómo-crear-funciones-en-r-sintaxis-y-ejemplos-básicos",
    "href": "06.1_funciones.html#cómo-crear-funciones-en-r-sintaxis-y-ejemplos-básicos",
    "title": "7  Funciones en R",
    "section": "7.3 Cómo crear funciones en R: Sintaxis y ejemplos básicos",
    "text": "7.3 Cómo crear funciones en R: Sintaxis y ejemplos básicos\nLa definición de funciones en R se realiza mediante una sintaxis clara y estructurada, lo que facilita la creación de procedimientos personalizados para resolver tareas específicas. Comprender la estructura básica de una función es fundamental para aprovechar al máximo la modularidad y reutilización del código en R (R Core Team, 2023; Wickham & Grolemund, 2017).\n\n7.3.1 Sintaxis básica\nLa sintaxis general para crear una función en R es la siguiente:\n\nnombre_funcion &lt;- function(argumento1, argumento2, ...) {\n  # Instrucciones y operaciones\n  return(resultado)\n}\n\n\n\n7.3.2 Elementos clave de una función\nCada función en R se compone de los siguientes elementos:\n\nNombre de la función: que debe ser descriptivo y reflejar claramente la tarea que realiza.\nArgumentos: representan los valores de entrada requeridos por la función. Es posible asignar valores por defecto a estos argumentos para hacer la función más flexible.\nCuerpo de la función: donde se incluyen las operaciones y cálculos que se ejecutan al llamar a la función.\nValor de retorno: que se especifica mediante la instrucción return(). Si no se utiliza return(), la función devolverá automáticamente el último valor evaluado en su cuerpo.\n\n\n\n7.3.3 Ejemplo básico\nA continuación, se muestra un ejemplo de una función personalizada que convierte temperaturas de grados Celsius a Fahrenheit:\n\n# Función para convertir grados Celsius a Fahrenheit\ncelsius_a_fahrenheit &lt;- function(celsius) {\n  fahrenheit &lt;- (celsius * 9/5) + 32\n  return(fahrenheit)\n}\n\n# Uso de la función\ncelsius_a_fahrenheit(25)   # Resultado: 77\n\n[1] 77",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Funciones en R</span>"
    ]
  },
  {
    "objectID": "07_paquetes.html",
    "href": "07_paquetes.html",
    "title": "8  Paquetes en R",
    "section": "",
    "text": "8.1 ¿Qué es un paquete en R?\nLos paquetes en R constituyen una de las herramientas más potentes del lenguaje, ya que permiten ampliar sus funcionalidades básicas y abordar tareas especializadas de manera eficiente. Gracias a los paquetes, es posible acceder a funciones, datos y documentación desarrollados por expertos, lo que facilita la realización de análisis estadísticos, manipulación de datos y visualización avanzada, entre otras aplicaciones (R Core Team, 2023).\nUn paquete en R se define como una colección estructurada de funciones, conjuntos de datos y documentación que extiende las capacidades del entorno base. Estos paquetes, desarrollados tanto por la comunidad como por equipos especializados, están orientados a resolver problemas concretos en diversas áreas, desde la manipulación de datos hasta el análisis estadístico avanzado o la generación de gráficos complejos (Wickham & Bryan, 2023).",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Paquetes en R</span>"
    ]
  },
  {
    "objectID": "07_paquetes.html#qué-es-un-paquete-en-r",
    "href": "07_paquetes.html#qué-es-un-paquete-en-r",
    "title": "8  Paquetes en R",
    "section": "",
    "text": "8.1.1 Características principales de los paquetes\nLas características más relevantes de los paquetes en R se resumen a continuación:\n\nFunciones especializadas: Cada paquete incluye funciones diseñadas para tareas específicas, como crear gráficos, realizar análisis estadísticos o manipular datos.\nDocumentación: Los paquetes incluyen documentación detallada que explica cómo utilizarlos, con ejemplos prácticos.\nDatos de ejemplo: Muchos paquetes incluyen conjuntos de datos que permiten practicar y entender su funcionalidad.\n\n\n\n8.1.2 Importancia del uso de paquetes en R\nEl uso de paquetes resulta fundamental para aprovechar plenamente el potencial de R, ya que ofrecen extensibilidad, eficiencia y especialización. Los paquetes permiten realizar tareas que no están disponibles en el entorno base, simplifican procesos complejos y proporcionan soluciones adaptadas a áreas específicas, como la agronomía, la biología o la economía. Además, la comunidad activa de R garantiza la actualización y el soporte continuo de una amplia variedad de paquetes, lo que contribuye a mantener el lenguaje a la vanguardia en el análisis de datos (Wickham & Grolemund, 2017).",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Paquetes en R</span>"
    ]
  },
  {
    "objectID": "07_paquetes.html#instalación-y-carga-de-paquetes",
    "href": "07_paquetes.html#instalación-y-carga-de-paquetes",
    "title": "8  Paquetes en R",
    "section": "8.2 Instalación y carga de paquetes",
    "text": "8.2 Instalación y carga de paquetes\nLa gestión de paquetes en R es un proceso fundamental para acceder a herramientas especializadas y ampliar las capacidades del entorno base. La mayoría de los paquetes se obtienen desde CRAN (Comprehensive R Archive Network), el repositorio oficial que alberga una amplia variedad de recursos para diferentes áreas de aplicación (R Core Team, 2023).\n\n8.2.1 Proceso de instalación\nPara instalar un paquete desde CRAN, se utiliza la función install.packages(). Por ejemplo, para instalar el paquete ggplot2, ampliamente utilizado para la visualización de datos, se emplea la siguiente instrucción:\n\n# Instalación del paquete ggplot2\ninstall.packages(\"ggplot2\")\n\nLa instalación de un paquete es un proceso que solo debe realizarse una vez en el sistema.\n\n\n8.2.2 Carga de paquetes\nDespués de instalar un paquete, es necesario cargarlo en cada nueva sesión de trabajo para poder utilizar sus funciones. Esto se realiza mediante la función library():\n\n# Cargar el paquete ggplot2\nlibrary(ggplot2)\n\nLa carga de paquetes debe repetirse cada vez que se inicia una nueva sesión en R, ya que los paquetes no se cargan automáticamente al abrir el entorno.\n\n\n8.2.3 Automatización de la instalación y carga\nPara asegurar que un paquete esté disponible y evitar errores al compartir scripts, es recomendable automatizar el proceso de verificación, instalación y carga. La siguiente estructura permite comprobar si el paquete está instalado y, en caso contrario, instalarlo y cargarlo automáticamente:\n\n# Verificar e instalar automáticamente un paquete\nif (!require(\"ggplot2\")) install.packages(\"ggplot2\")\n\nEste enfoque contribuye a la reproducibilidad del código y facilita el intercambio de scripts entre usuarios, garantizando que todas las dependencias necesarias estén disponibles en el entorno de trabajo (R Core Team, 2023).",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Paquetes en R</span>"
    ]
  },
  {
    "objectID": "07_paquetes.html#paquetes-recomendados-para-tareas-específicas",
    "href": "07_paquetes.html#paquetes-recomendados-para-tareas-específicas",
    "title": "8  Paquetes en R",
    "section": "8.3 Paquetes recomendados para tareas específicas",
    "text": "8.3 Paquetes recomendados para tareas específicas\nEn el ámbito del análisis estadístico y la manipulación de datos, existen diversos paquetes que facilitan tareas específicas y permiten realizar análisis complejos de manera eficiente. A continuación, se presenta una clasificación de los paquetes más relevantes según su área de aplicación:\n\n\n\n\n\n\n\n\nÁrea\nPaquete\nDescripción\n\n\n\n\nManipulación de datos\ndplyr\nFacilita la transformación y manipulación de datos mediante funciones intuitivas\n\n\n\ntidyr\nPermite reorganizar datos entre formatos ancho y largo\n\n\n\ndata.table\nOptimizado para el manejo de grandes conjuntos de datos\n\n\nAnálisis exploratorio\nDataExplorer\nAutomatiza el análisis exploratorio de datos\n\n\n\nsummarytools\nGenera resúmenes estadísticos detallados\n\n\n\npsych\nProporciona funciones para análisis psicométricos y estadística descriptiva\n\n\nAnálisis estadístico\nstats\nIncluye funciones base para pruebas estadísticas comunes\n\n\n\nagricolae\nEspecializado en diseños experimentales y análisis agrícolas\n\n\n\nAgroR\nProporciona funciones y herramientas para análisis estadísticos en agronomía\n\n\n\ncar\nFacilita análisis de regresión avanzados\n\n\nVisualización\nggplot2\nPermite crear gráficos personalizados de alta calidad\n\n\n\nplotly\nGenera gráficos interactivos\n\n\n\n\n8.3.1 Instalación y carga de paquetes esenciales\nEl siguiente código muestra cómo instalar y cargar un conjunto básico de paquetes para análisis estadísticos:\n\n# Paquetes para manipulación y visualización de datos\nif (!require(\"tidyverse\")) install.packages(\"tidyverse\")\nif (!require(\"data.table\")) install.packages(\"data.table\")\n\n# Paquetes para análisis exploratorio\nif (!require(\"DataExplorer\")) install.packages(\"DataExplorer\")\nif (!require(\"psych\")) install.packages(\"psych\")\n\n# Paquetes para análisis estadísticos especializados\nif (!require(\"agricolae\")) install.packages(\"agricolae\")\nif (!require(\"AgroR\")) install.packages(\"AgroR\")\nif (!require(\"car\")) install.packages(\"car\")\n\n# Paquetes para manejo de archivos\nif (!require(\"readxl\")) install.packages(\"readxl\")\nif (!require(\"writexl\")) install.packages(\"writexl\")\n\nEstos paquetes proporcionan un conjunto robusto de herramientas para realizar análisis estadísticos completos, desde la exploración inicial de datos hasta análisis especializados en áreas específicas como la agronomía o la psicometría (R Core Team, 2023).",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Paquetes en R</span>"
    ]
  },
  {
    "objectID": "07_paquetes.html#ejemplo-práctico-integración-de-paquetes-en-un-análisis-estadístico",
    "href": "07_paquetes.html#ejemplo-práctico-integración-de-paquetes-en-un-análisis-estadístico",
    "title": "8  Paquetes en R",
    "section": "8.4 Ejemplo práctico: Integración de paquetes en un análisis estadístico",
    "text": "8.4 Ejemplo práctico: Integración de paquetes en un análisis estadístico\nEste ejemplo ilustra la aplicación práctica de diversos paquetes de R en un análisis estadístico, basado en el estudio presentado por López y González (2016) sobre el crecimiento de plántulas de pino maximinoii. El código completo está disponible en: https://github.com/Ludwing-MJ/Paquetes_Ej.\n\n8.4.1 Contexto del estudio\nSe evaluó el efecto de cinco tratamientos de preparación del terreno sobre el crecimiento en altura de plántulas de pino maximinoii. El experimento incluyó 25 parcelas, con cinco repeticiones por tratamiento, asignadas aleatoriamente. Las mediciones de altura se realizaron después de cinco años de crecimiento.\n\n\n8.4.2 Implementación del análisis\n\n# Instalación y carga de paquetes necesarios\n## Incluye ggplot2, dplyr, tidyr\nif (!require(\"tidyverse\")) install.packages(\"tidyverse\")\n## Diseños experimentales agrícolas\nif (!require(\"agricolae\")) install.packages(\"agricolae\")\n## Importación de archivos Excel\nif (!require(\"readxl\")) install.packages(\"readxl\")    \n## Exportación a Excel\nif (!require(\"writexl\")) install.packages(\"writexl\")    \n## Establecer directorio de trabajo automaticamente\nif (!require(\"rstudioapi\")) install.packages(\"rstudioapi\")\n\n\n# Carga de datos\naltura_pino &lt;- read_excel(\"datos_arboles.xlsx\")\n\n# Análisis de varianza y comparaciones múltiples\nmodelo_anova &lt;- aov(altura_ft ~ tratamiento, data = altura_pino)\nsummary (modelo_anova)\n\n            Df Sum Sq Mean Sq F value  Pr(&gt;F)   \ntratamiento  4  34.64    8.66   5.851 0.00276 **\nResiduals   20  29.60    1.48                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\ncomparacion_tukey &lt;- HSD.test(modelo_anova, \"tratamiento\")\ncomparacion_tukey$groups\n\n  altura_ft groups\nB      14.4      a\nA      13.4     ab\nE      11.8      b\nC      11.6      b\nD      11.4      b\n\n# Visualización de resultados\nggplot(altura_pino, aes(x = tratamiento, y = altura_ft, fill = tratamiento)) +\n    geom_boxplot() +\n    labs(title = \"Altura por Tratamiento\",\n         x = \"Tratamiento\",\n         y = \"Altura en pies\") +\n    theme_minimal() +\n    theme(legend.position = \"none\")\n\n\n\n\n\n\n\n# Exportación de resultados\nwrite_xlsx(comparacion_tukey$groups, \"resultados_tukey.xlsx\")\nggsave(\"ggplot_pino.png\")\n\nEste ejemplo demuestra cómo los diferentes paquetes se integran en un flujo de trabajo coherente, desde la preparación de datos hasta la visualización y exportación de resultados. El uso de paquetes especializados como agricolae para el análisis estadístico, ggplot2 para la visualización y writexl para la exportación de resultados, simplifica significativamente el proceso de análisis y presentación de datos (López & González, 2016; R Core Team, 2023).\nLa estructura modular del código y el uso de paquetes especializados facilitan la reproducibilidad del análisis y permiten adaptarlo fácilmente a otros conjuntos de datos similares.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Paquetes en R</span>"
    ]
  },
  {
    "objectID": "08.1_manipulacion.html",
    "href": "08.1_manipulacion.html",
    "title": "9  Introducción a la manipulación de datos en R",
    "section": "",
    "text": "9.1 Principales tareas de manipulación de datos\nLa manipulación de datos representa una etapa crítica en el proceso de análisis estadístico, ya que los datos raramente se encuentran en condiciones óptimas para su análisis inmediato. Es común que los conjuntos de datos contengan errores, valores faltantes, duplicados o estén organizados de manera poco conveniente para los objetivos del estudio. Por ello, la manipulación de datos es esencial para transformar los datos crudos en información útil, confiable y lista para el análisis estadístico y la visualización. Sin una adecuada manipulación, los resultados pueden ser erróneos o difíciles de interpretar, lo que afecta la validez y la reproducibilidad de los análisis (Wickham & Grolemund, 2017; R Core Team, 2023).\nLa manipulación de datos en R abarca un conjunto de tareas fundamentales que permiten preparar la información para su análisis estadístico. Estas tareas son necesarias para garantizar que los datos sean consistentes, completos y estén organizados de acuerdo con los requerimientos del análisis a realizar (Wickham & Grolemund, 2017).",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Introducción a la manipulación de datos en R</span>"
    ]
  },
  {
    "objectID": "08.1_manipulacion.html#principales-tareas-de-manipulación-de-datos",
    "href": "08.1_manipulacion.html#principales-tareas-de-manipulación-de-datos",
    "title": "9  Introducción a la manipulación de datos en R",
    "section": "",
    "text": "9.1.1 Filtrado de datos\nEl filtrado consiste en seleccionar subconjuntos de datos que cumplen ciertas condiciones específicas. Esta tarea es fundamental para enfocar el análisis en grupos de interés, eliminar registros no relevantes o excluir observaciones que puedan distorsionar los resultados. Por ejemplo, se puede filtrar una base de datos para analizar únicamente los registros de un grupo demográfico particular o eliminar casos con información incompleta (R Core Team, 2023).\n\n\n9.1.2 Selección de variables\nLa selección de variables implica elegir únicamente las columnas o variables relevantes para el análisis. Esta tarea simplifica el conjunto de datos, reduce la complejidad del análisis y facilita la interpretación de los resultados. Seleccionar las variables adecuadas es especialmente importante cuando se trabaja con bases de datos extensas o con información redundante (Wickham & Grolemund, 2017).\n\n\n9.1.3 Transformación de datos\nLa transformación de datos abarca la creación de nuevas variables, la modificación de valores existentes o la recodificación de categorías. Estas operaciones permiten adaptar los datos a los requerimientos del análisis estadístico, por ejemplo, convirtiendo variables categóricas en numéricas, calculando índices o agrupando categorías similares. La transformación es clave para preparar los datos antes de aplicar técnicas estadísticas específicas (R Core Team, 2023).\n\n\n9.1.4 Agregación de información\nLa agregación consiste en resumir la información contenida en los datos, calculando medidas como promedios, totales, conteos o proporciones por grupo. Esta tarea es fundamental para comparar tendencias, identificar patrones y realizar análisis descriptivos o inferenciales. La agregación permite sintetizar grandes volúmenes de datos en resúmenes comprensibles y útiles para la toma de decisiones (Wickham & Grolemund, 2017).\n\n\n9.1.5 Reestructuración de datos\nLa reestructuración de datos implica cambiar la forma en que los datos están organizados, por ejemplo, convirtiendo un conjunto de datos de formato ancho a largo o viceversa. Esta tarea es necesaria cuando la estructura original de los datos no es compatible con las técnicas estadísticas o de visualización que se desean aplicar. La reestructuración facilita la aplicación de modelos y la generación de gráficos adecuados (Wickham & Grolemund, 2017).",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Introducción a la manipulación de datos en R</span>"
    ]
  },
  {
    "objectID": "08.1_manipulacion.html#enfoques-disponibles-en-r-para-la-manipulación-de-datos",
    "href": "08.1_manipulacion.html#enfoques-disponibles-en-r-para-la-manipulación-de-datos",
    "title": "9  Introducción a la manipulación de datos en R",
    "section": "9.2 Enfoques disponibles en R para la manipulación de datos",
    "text": "9.2 Enfoques disponibles en R para la manipulación de datos\nR ofrece dos enfoques principales para la manipulación de datos, cada uno con características y ventajas particulares que se adaptan a diferentes necesidades y niveles de experiencia del usuario (R Core Team, 2023).\n\n9.2.1 Herramientas base de R\nLas herramientas base de R incluyen funciones integradas como el uso de corchetes para seleccionar filas y columnas, así como funciones como subset(), aggregate() y tapply(). Estas herramientas permiten realizar operaciones fundamentales de manipulación de datos de manera flexible y eficiente. Sin embargo, la sintaxis puede resultar menos intuitiva para quienes se inician en R, y las operaciones complejas pueden requerir múltiples pasos o combinaciones de funciones (R Core Team, 2023).\n\n\n9.2.2 El enfoque tidyverse\nEl tidyverse es un conjunto de paquetes desarrollados para simplificar y estandarizar la manipulación de datos en R. Entre estos paquetes destacan dplyr y tidyr, que ofrecen funciones específicas para filtrar, seleccionar, transformar y reestructurar datos de manera clara y legible. El uso del tidyverse facilita la construcción de flujos de trabajo reproducibles y eficientes, y su sintaxis está diseñada para ser accesible tanto para principiantes como para usuarios avanzados. Además, el tidyverse promueve el principio de “datos ordenados” (tidy data), que facilita la aplicación de técnicas estadísticas y la generación de visualizaciones (Wickham & Grolemund, 2017).",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Introducción a la manipulación de datos en R</span>"
    ]
  },
  {
    "objectID": "08.2_manipulacion.html",
    "href": "08.2_manipulacion.html",
    "title": "10  Manipulación de Datos con Herramientas Base de R",
    "section": "",
    "text": "10.1 Datos de ejemplo\nLa manipulación de datos con herramientas base de R constituye una etapa esencial en el flujo de trabajo estadístico clásico. Antes de aplicar técnicas como el análisis de varianza, la regresión lineal o la comparación de medias, es necesario preparar los datos para asegurar su integridad y adecuación al análisis. Las funciones básicas de R permiten seleccionar, filtrar, transformar, agrupar y limpiar datos de manera eficiente, facilitando la obtención de resultados estadísticos válidos y reproducibles (R Core Team, 2023).\nPara ilustrar las técnicas de manipulación, se emplea un conjunto de datos simulado que representa un experimento agrícola. Este conjunto contiene variables numéricas y categóricas, así como algunos valores faltantes, lo que permite demostrar operaciones comunes en la estadística clásica.\n# Establecer una semilla para que el usuario pueda replicar el ejemplo\nset.seed(123) # Garantiza reproducibilidad\n\n# Simular los resultados de un experimento con el diseño bloques completos al azar\ndatos_cultivo &lt;- data.frame(\n  parcela = 1:20,\n  tratamiento = rep(c(\"Control\", \n                      \"Fertilizante A\", \n                      \"Fertilizante B\", \n                      \"Fertilizante C\"), each = 5),\n  bloque = rep(1:5, times = 4),\n  altura_cm = round(rnorm(20, mean = 65, sd = 10), 1),\n  peso_gr = round(rnorm(20, mean = 120, sd = 25), 1),\n  daño_plaga = sample(c(\"Alto\", \"Medio\", \"Bajo\"), 20, replace = TRUE),\n  fecha_siembra = as.Date(\"2024-01-01\") + sample(1:10, 20, replace = TRUE)\n)\n\n# Simular la presencia de datos faltantes en los resultados del experimento\ndatos_cultivo$altura_cm[c(3, 15)] &lt;- NA\ndatos_cultivo$peso_gr[c(7, 18)] &lt;- NA\n\n# Visualizar las primeras filas del data frame con los datos simulados\nhead(datos_cultivo)\n\n  parcela    tratamiento bloque altura_cm peso_gr daño_plaga fecha_siembra\n1       1        Control      1      59.4    93.3      Medio    2024-01-10\n2       2        Control      2      62.7   114.6      Medio    2024-01-08\n3       3        Control      3        NA    94.3       Bajo    2024-01-04\n4       4        Control      4      65.7   101.8      Medio    2024-01-09\n5       5        Control      5      66.3   104.4      Medio    2024-01-10\n6       6 Fertilizante A      1      82.2    77.8       Bajo    2024-01-04",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Manipulación de Datos con Herramientas Base de R</span>"
    ]
  },
  {
    "objectID": "08.2_manipulacion.html#selección-y-filtrado-de-datos-en-data-frames",
    "href": "08.2_manipulacion.html#selección-y-filtrado-de-datos-en-data-frames",
    "title": "10  Manipulación de Datos con Herramientas Base de R",
    "section": "10.2 Selección y filtrado de datos en data frames",
    "text": "10.2 Selección y filtrado de datos en data frames\nLa selección y el filtrado permiten trabajar con subconjuntos de datos relevantes para el análisis estadístico. Estas operaciones se realizan mediante la indexación y el uso de condiciones lógicas.\n\n10.2.1 Selección de columnas\nPara seleccionar columnas específicas, se utiliza la notación de corchetes [, ], donde el primer argumento indica las filas y el segundo las columnas.\n\n# Selección de columnas por nombre\ndatos_mediciones &lt;- datos_cultivo[, c(\"altura_cm\", \"peso_gr\")]\nhead(datos_mediciones) # Muestra las primeras filas del resultado\n\n  altura_cm peso_gr\n1      59.4    93.3\n2      62.7   114.6\n3        NA    94.3\n4      65.7   101.8\n5      66.3   104.4\n6      82.2    77.8\n\n# Exclusión de una columna\ndatos_sin_fecha &lt;- datos_cultivo[, !names(datos_cultivo) %in% \"fecha_siembra\"]\nhead(datos_sin_fecha) # Muestra las primeras filas del resultado\n\n  parcela    tratamiento bloque altura_cm peso_gr daño_plaga\n1       1        Control      1      59.4    93.3      Medio\n2       2        Control      2      62.7   114.6      Medio\n3       3        Control      3        NA    94.3       Bajo\n4       4        Control      4      65.7   101.8      Medio\n5       5        Control      5      66.3   104.4      Medio\n6       6 Fertilizante A      1      82.2    77.8       Bajo\n\n# Selección por posición\nprimeras_tres_columnas &lt;- datos_cultivo[, 1:3]\nhead(primeras_tres_columnas) # Muestra las primeras filas del resultado\n\n  parcela    tratamiento bloque\n1       1        Control      1\n2       2        Control      2\n3       3        Control      3\n4       4        Control      4\n5       5        Control      5\n6       6 Fertilizante A      1\n\n\nEl uso de nombres de columnas es recomendable para evitar errores si el orden de las variables cambia.\n\n\n10.2.2 Filtrado de filas por condiciones lógicas\nEl filtrado de filas se realiza especificando una condición lógica en la parte de filas de la notación de corchetes.\n\n# Filtrar por tratamiento\ndatos_control &lt;- datos_cultivo[datos_cultivo$tratamiento == \"Control\", ]\nhead(datos_control) # Muestra las primeras filas del resultado\n\n  parcela tratamiento bloque altura_cm peso_gr daño_plaga fecha_siembra\n1       1     Control      1      59.4    93.3      Medio    2024-01-10\n2       2     Control      2      62.7   114.6      Medio    2024-01-08\n3       3     Control      3        NA    94.3       Bajo    2024-01-04\n4       4     Control      4      65.7   101.8      Medio    2024-01-09\n5       5     Control      5      66.3   104.4      Medio    2024-01-10\n\n# Filtrar por condición múltiple\ndatos_altos &lt;- datos_cultivo[datos_cultivo$altura_cm &gt; 65 &\n                               datos_cultivo$tratamiento != \"Control\", ]\nhead(datos_altos) # Muestra las primeras filas del resultado\n\n   parcela    tratamiento bloque altura_cm peso_gr daño_plaga fecha_siembra\n6        6 Fertilizante A      1      82.2    77.8       Bajo    2024-01-04\n7        7 Fertilizante A      2      69.6      NA       Bajo    2024-01-08\n11      11 Fertilizante B      1      77.2   130.7       Alto    2024-01-11\n12      12 Fertilizante B      2      68.6   112.6      Medio    2024-01-06\n13      13 Fertilizante B      3      69.0   142.4       Alto    2024-01-06\n14      14 Fertilizante B      4      66.1   142.0       Alto    2024-01-09\n\n# Uso de subset para mayor legibilidad\ndatos_fertilizante_A &lt;- subset(datos_cultivo, tratamiento == \"Fertilizante A\" &\n                                 bloque %in% c(2,3,4))\nhead(datos_fertilizante_A) # Muestra las primeras filas del resultado\n\n  parcela    tratamiento bloque altura_cm peso_gr daño_plaga fecha_siembra\n7       7 Fertilizante A      2      69.6      NA       Bajo    2024-01-08\n8       8 Fertilizante A      3      52.3   123.8       Alto    2024-01-04\n9       9 Fertilizante A      4      58.1    91.5      Medio    2024-01-08\n\n\nLa función subset() permite expresar condiciones de manera más clara y evita la repetición del nombre del data frame.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Manipulación de Datos con Herramientas Base de R</span>"
    ]
  },
  {
    "objectID": "08.2_manipulacion.html#modificación-de-variables",
    "href": "08.2_manipulacion.html#modificación-de-variables",
    "title": "10  Manipulación de Datos con Herramientas Base de R",
    "section": "10.3 Modificación de variables",
    "text": "10.3 Modificación de variables\nLa modificación de variables es fundamental para adaptar los datos a los requerimientos de los métodos estadísticos clásicos.\n\n10.3.1 Creación de nuevas columnas\nNuevas variables pueden crearse mediante operaciones aritméticas o lógicas sobre las columnas existentes.\n\n# Índice de crecimiento: relación entre altura y peso\ndatos_cultivo$indice_crecimiento &lt;- datos_cultivo$altura_cm/datos_cultivo$peso_gr\n\n# Clasificación de peso en alto o bajo\ndatos_cultivo$categoria_peso &lt;- ifelse(datos_cultivo$peso_gr &gt; 120, \n                                       \"Alto\", \"Bajo\")\n\n# Transformación logarítmica para normalizar la variable peso\ndatos_cultivo$log_peso &lt;- log(datos_cultivo$peso_gr)\nhead(datos_cultivo) # Muestra las primeras filas del resultado\n\n  parcela    tratamiento bloque altura_cm peso_gr daño_plaga fecha_siembra\n1       1        Control      1      59.4    93.3      Medio    2024-01-10\n2       2        Control      2      62.7   114.6      Medio    2024-01-08\n3       3        Control      3        NA    94.3       Bajo    2024-01-04\n4       4        Control      4      65.7   101.8      Medio    2024-01-09\n5       5        Control      5      66.3   104.4      Medio    2024-01-10\n6       6 Fertilizante A      1      82.2    77.8       Bajo    2024-01-04\n  indice_crecimiento categoria_peso log_peso\n1          0.6366559           Bajo 4.535820\n2          0.5471204           Bajo 4.741448\n3                 NA           Bajo 4.546481\n4          0.6453831           Bajo 4.623010\n5          0.6350575           Bajo 4.648230\n6          1.0565553           Bajo 4.354141\n\n\nLa función ifelse(condición, valor_si_verdadero, valor_si_falso) permite crear variables categóricas a partir de condiciones lógicas.\n\n\n10.3.2 Recodificación de variables categóricas\nLa recodificación es útil para adaptar los niveles de factores a los requerimientos del análisis.\n\n# Recodificación de niveles de daño por plaga\ndatos_cultivo$nivel_daño &lt;- factor(datos_cultivo$daño_plaga, \n                                   levels = c(\"Bajo\", \"Medio\", \"Alto\"), \n                                   labels = c(\"1\", \"2\", \"3\"))\n\n# Variable indicadora para tratamiento control\ndatos_cultivo$es_control &lt;- ifelse(datos_cultivo$tratamiento == \"Control\", 1, 0)\nhead(datos_cultivo)  # Muestra las primeras filas del resultado\n\n  parcela    tratamiento bloque altura_cm peso_gr daño_plaga fecha_siembra\n1       1        Control      1      59.4    93.3      Medio    2024-01-10\n2       2        Control      2      62.7   114.6      Medio    2024-01-08\n3       3        Control      3        NA    94.3       Bajo    2024-01-04\n4       4        Control      4      65.7   101.8      Medio    2024-01-09\n5       5        Control      5      66.3   104.4      Medio    2024-01-10\n6       6 Fertilizante A      1      82.2    77.8       Bajo    2024-01-04\n  indice_crecimiento categoria_peso log_peso nivel_daño es_control\n1          0.6366559           Bajo 4.535820          2          1\n2          0.5471204           Bajo 4.741448          2          1\n3                 NA           Bajo 4.546481          1          1\n4          0.6453831           Bajo 4.623010          2          1\n5          0.6350575           Bajo 4.648230          2          1\n6          1.0565553           Bajo 4.354141          1          0\n\n\nLa función factor() permite definir el orden y las etiquetas de los niveles de una variable categórica, lo cual es relevante en análisis como ANOVA.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Manipulación de Datos con Herramientas Base de R</span>"
    ]
  },
  {
    "objectID": "08.2_manipulacion.html#ordenamiento-y-agrupamiento-de-datos",
    "href": "08.2_manipulacion.html#ordenamiento-y-agrupamiento-de-datos",
    "title": "10  Manipulación de Datos con Herramientas Base de R",
    "section": "10.4 Ordenamiento y agrupamiento de datos",
    "text": "10.4 Ordenamiento y agrupamiento de datos\nEl ordenamiento y el agrupamiento facilitan la exploración y el cálculo de estadísticas descriptivas por grupos, pasos previos a los análisis clásicos.\n\n10.4.1 Ordenamiento de datos\nEl ordenamiento se realiza con la función order(), que devuelve el índice de ordenación.\n\n# Ordenar por altura\ndatos_ordenados &lt;- datos_cultivo[order(datos_cultivo$altura_cm), ]\nhead(datos_ordenados) # Muestra las primeras filas del resultado\n\n   parcela    tratamiento bloque altura_cm peso_gr daño_plaga fecha_siembra\n18      18 Fertilizante C      3      45.3      NA       Alto    2024-01-11\n8        8 Fertilizante A      3      52.3   123.8       Alto    2024-01-04\n9        9 Fertilizante A      4      58.1    91.5      Medio    2024-01-08\n1        1        Control      1      59.4    93.3      Medio    2024-01-10\n20      20 Fertilizante C      5      60.3   110.5       Alto    2024-01-11\n10      10 Fertilizante A      5      60.5   151.3      Medio    2024-01-07\n   indice_crecimiento categoria_peso log_peso nivel_daño es_control\n18                 NA           &lt;NA&gt;       NA          3          0\n8           0.4224556           Alto 4.818667          3          0\n9           0.6349727           Bajo 4.516339          2          0\n1           0.6366559           Bajo 4.535820          2          1\n20          0.5457014           Bajo 4.705016          3          0\n10          0.3998678           Alto 5.019265          2          0\n\n# Ordenar por tratamiento y peso descendente\ndatos_ordenados_multi &lt;- datos_cultivo[order(datos_cultivo$tratamiento,\n                                             -datos_cultivo$peso_gr), ]\nhead(datos_ordenados_multi) # Muestra las primeras filas del resultado\n\n   parcela    tratamiento bloque altura_cm peso_gr daño_plaga fecha_siembra\n2        2        Control      2      62.7   114.6      Medio    2024-01-08\n5        5        Control      5      66.3   104.4      Medio    2024-01-10\n4        4        Control      4      65.7   101.8      Medio    2024-01-09\n3        3        Control      3        NA    94.3       Bajo    2024-01-04\n1        1        Control      1      59.4    93.3      Medio    2024-01-10\n10      10 Fertilizante A      5      60.5   151.3      Medio    2024-01-07\n   indice_crecimiento categoria_peso log_peso nivel_daño es_control\n2           0.5471204           Bajo 4.741448          2          1\n5           0.6350575           Bajo 4.648230          2          1\n4           0.6453831           Bajo 4.623010          2          1\n3                  NA           Bajo 4.546481          1          1\n1           0.6366559           Bajo 4.535820          2          1\n10          0.3998678           Alto 5.019265          2          0\n\n\nEl signo negativo delante de una variable numérica indica orden descendente.\n\n\n10.4.2 Cálculos estadísticos por grupo\nEl cálculo de medias, desviaciones estándar y otros estadísticos por grupo es esencial en la estadística clásica. Las funciones tapply(), aggregate() y by() permiten realizar estos cálculos.\n\n# Media de altura por tratamiento usando tapply\nmedias_altura &lt;- tapply(datos_cultivo$altura_cm, datos_cultivo$tratamiento, \n                        mean, na.rm = TRUE)\nmedias_altura\n\n       Control Fertilizante A Fertilizante B Fertilizante C \n        63.525         64.540         70.225         66.100 \n\n# Estadísticas descriptivas por tratamiento usando aggregate\nestadisticas_grupo &lt;- aggregate(cbind(altura_cm, peso_gr) ~ tratamiento, \n                                data = datos_cultivo, \n                                FUN = function(x) \n                                  c(media = mean(x, na.rm = TRUE), \n                                    sd = sd(x, na.rm = TRUE)))\nestadisticas_grupo\n\n     tratamiento altura_cm.media altura_cm.sd peso_gr.media peso_gr.sd\n1        Control       63.525000     3.168990    103.525000   8.773967\n2 Fertilizante A       63.275000    13.077812    111.100000  33.017066\n3 Fertilizante B       70.225000     4.823812    131.925000  13.978406\n4 Fertilizante C       71.300000     9.268945    123.475000  13.976021\n\n\nEn tapply(), el primer argumento es el vector de datos, el segundo es el factor de agrupamiento y el tercero es la función estadística. El argumento na.rm = TRUE indica que se deben omitir los valores faltantes.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Manipulación de Datos con Herramientas Base de R</span>"
    ]
  },
  {
    "objectID": "08.2_manipulacion.html#manejo-de-valores-faltantes-y-duplicados",
    "href": "08.2_manipulacion.html#manejo-de-valores-faltantes-y-duplicados",
    "title": "10  Manipulación de Datos con Herramientas Base de R",
    "section": "10.5 Manejo de valores faltantes y duplicados",
    "text": "10.5 Manejo de valores faltantes y duplicados\nEl tratamiento de valores faltantes y duplicados es crucial para evitar sesgos y errores en los análisis estadísticos clásicos (Wickham & Grolemund, 2017).\n\n10.5.1 Identificación y manejo de valores faltantes\n\n# Conteo de valores faltantes por columna\nna_por_columna &lt;- colSums(is.na(datos_cultivo))\nna_por_columna # Numero de valores faltantes por columna\n\n           parcela        tratamiento             bloque          altura_cm \n                 0                  0                  0                  2 \n           peso_gr         daño_plaga      fecha_siembra indice_crecimiento \n                 2                  0                  0                  4 \n    categoria_peso           log_peso         nivel_daño         es_control \n                 2                  2                  0                  0 \n\n# Eliminación de filas con valores faltantes\ndatos_completos &lt;- na.omit(datos_cultivo)\n\n# Imputación de valores faltantes con la media\ndatos_cultivo$altura_cm[is.na(datos_cultivo$altura_cm)] &lt;- \n  mean(datos_cultivo$altura_cm, na.rm = TRUE)\n\nLa función is.na() identifica los valores faltantes, colSums() suma por columna y na.omit() elimina filas con al menos un NA.\n\n\n10.5.2 Manejo de duplicados\n\n# Identificación de duplicados\nduplicados &lt;- duplicated(datos_cultivo[, c(\"tratamiento\", \"bloque\")])\nsummary(duplicados) # Resume el número de duplicados encontrados\n\n   Mode   FALSE \nlogical      20 \n\n# Eliminación de duplicados\ndatos_sin_duplicados &lt;- unique(datos_cultivo)\n\nLa función duplicated() devuelve un vector lógico que indica si una fila es duplicada respecto a las variables seleccionadas. unique() elimina las filas duplicadas.\n\n\n10.5.3 Ejemplo práctico: Preparación de datos para análisis de varianza (ANOVA)\nA continuación se muestra cómo preparar un conjunto de datos para un análisis de varianza, integrando las técnicas presentadas.\n\n# 1. Eliminar valores faltantes\ndatos_anova &lt;- na.omit(datos_cultivo)\n\n# 2. Seleccionar variables relevantes\ndatos_anova &lt;- datos_anova[, c(\"tratamiento\", \"bloque\", \"altura_cm\")]\n\n# 3. Recodificar variables como factores\ndatos_anova$tratamiento &lt;- factor(datos_anova$tratamiento)\ndatos_anova$bloque &lt;- factor(datos_anova$bloque)\n\n# 4. Estadísticas descriptivas previas\nestadisticas_previas &lt;- aggregate(altura_cm ~ tratamiento, \n                                  data = datos_anova,\n                                  FUN = function(x) \n                                    c(media = mean(x), \n                                      sd = sd(x), \n                                      n = length(x)))\nestadisticas_previas\n\n     tratamiento altura_cm.media altura_cm.sd altura_cm.n\n1        Control       63.525000     3.168990    4.000000\n2 Fertilizante A       63.275000    13.077812    4.000000\n3 Fertilizante B       70.225000     4.823812    4.000000\n4 Fertilizante C       71.300000     9.268945    4.000000\n\n# 5. Realizar ANOVA\nmodelo_anova &lt;- aov(altura_cm ~ tratamiento + bloque, data = datos_anova)\nsummary(modelo_anova)\n\n            Df Sum Sq Mean Sq F value Pr(&gt;F)\ntratamiento  3  219.3   73.09   1.277  0.346\nbloque       4  413.0  103.25   1.805  0.221\nResiduals    8  457.8   57.22               \n\n\nEn este ejemplo, se eliminan los valores faltantes, se seleccionan las variables necesarias, se recodifican como factores y se calculan estadísticas descriptivas antes de aplicar el modelo ANOVA, una técnica central en la estadística clásica para comparar medias entre grupos (Montgomery, 2017; R Core Team, 2023).",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Manipulación de Datos con Herramientas Base de R</span>"
    ]
  },
  {
    "objectID": "08.3_manipulacion.html",
    "href": "08.3_manipulacion.html",
    "title": "11  Manipulación de datos con dplyr y tidyr",
    "section": "",
    "text": "11.1 Introducción a los paquetes dplyr y tidyr\nLos paquetes dplyr y tidyr forman parte del ecosistema tidyverse y han sido diseñados específicamente para la manipulación y transformación de datos en R. En el contexto del análisis estadístico clásico, estas herramientas facilitan la preparación de datos para técnicas como ANOVA, regresión y pruebas de hipótesis, ofreciendo una sintaxis clara y consistente (Wickham & Grolemund, 2017).\nEl paquete dplyr se especializa en la manipulación de datos tabulares, proporcionando funciones específicas para operaciones comunes como filtrado, selección y agregación. Por su parte, tidyr se centra en la reorganización de datos, permitiendo transformaciones entre diferentes formatos según los requerimientos del análisis estadístico (Wickham et al., 2023).\nPara ilustrar el uso de estas herramientas, en esta sección se desarrollará un ejemplo práctico que permitirá explorar las principales funciones de manipulación de datos. El script correspondiente a este ejemplo está disponible en el siguiente repositorio: Repositorio de ejemplo - Manipulación de datos.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Manipulación de datos con dplyr y tidyr</span>"
    ]
  },
  {
    "objectID": "08.3_manipulacion.html#datos-ejemplo",
    "href": "08.3_manipulacion.html#datos-ejemplo",
    "title": "11  Manipulación de datos con dplyr y tidyr",
    "section": "11.2 Datos ejemplo",
    "text": "11.2 Datos ejemplo\nSe emplea el mismo conjunto de datos simulado del experimento agrícola utilizado en el capítulo anterior, lo que permite comparar directamente los enfoques de R base y tidyverse.\n\n# Cargar el paquete necesario\nlibrary(dplyr)\nlibrary(tidyr)\n\n# Crear datos de ejemplo\nset.seed(123) # Para reproducibilidad\n\ndatos_cultivo &lt;- data.frame(\n  parcela = 1:20,\n  tratamiento = rep(c(\"Control\", \"Fertilizante A\",\n                      \"Fertilizante B\", \"Fertilizante C\"), each = 5),\n  bloque = rep(1:5, times = 4),\n  altura_cm = round(rnorm(20, mean = 65, sd = 10), 1),\n  peso_gr = round(rnorm(20, mean = 120, sd = 25), 1),\n  daño_plaga = sample(c(\"Alto\", \"Medio\", \"Bajo\"), 20, replace = TRUE),\n  fecha_siembra = as.Date(\"2024-01-01\") + sample(1:10, 20, replace = TRUE)\n)\n\n# Agregar algunos valores NA para ejemplos posteriores\ndatos_cultivo$altura_cm[c(3, 15)] &lt;- NA\ndatos_cultivo$peso_gr[c(7, 18)] &lt;- NA",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Manipulación de datos con dplyr y tidyr</span>"
    ]
  },
  {
    "objectID": "08.3_manipulacion.html#operaciones-básicas-con-dplyr",
    "href": "08.3_manipulacion.html#operaciones-básicas-con-dplyr",
    "title": "11  Manipulación de datos con dplyr y tidyr",
    "section": "11.3 Operaciones básicas con dplyr",
    "text": "11.3 Operaciones básicas con dplyr\n\n11.3.1 Filtrado de datos con filter()\nLa función filter() permite seleccionar filas de un data frame que cumplen condiciones lógicas. Su sintaxis es:\n\nfilter(.data, ...)\n\n\n.data: el data frame o tibble sobre el que se aplicará el filtrado.\n...: una o más condiciones lógicas que deben cumplirse para que una fila sea seleccionada.\n\nEjemplo:\n\n# Filtrar las parcelas con tratamiento \"Control\"\ndatos_control &lt;- filter(datos_cultivo, tratamiento == \"Control\")\nhead(datos_control) # Visualizar el resultado\n\n  parcela tratamiento bloque altura_cm peso_gr daño_plaga fecha_siembra\n1       1     Control      1      59.4    93.3      Medio    2024-01-10\n2       2     Control      2      62.7   114.6      Medio    2024-01-08\n3       3     Control      3        NA    94.3       Bajo    2024-01-04\n4       4     Control      4      65.7   101.8      Medio    2024-01-09\n5       5     Control      5      66.3   104.4      Medio    2024-01-10\n\n# Filtrar parcelas con altura mayor a 65 cm y tratamiento distinto de \"Control\"\ndatos_altos &lt;- filter(datos_cultivo, altura_cm &gt; 65, tratamiento != \"Control\")\nhead(datos_altos)   # Visualizar el resultado\n\n  parcela    tratamiento bloque altura_cm peso_gr daño_plaga fecha_siembra\n1       6 Fertilizante A      1      82.2    77.8       Bajo    2024-01-04\n2       7 Fertilizante A      2      69.6      NA       Bajo    2024-01-08\n3      11 Fertilizante B      1      77.2   130.7       Alto    2024-01-11\n4      12 Fertilizante B      2      68.6   112.6      Medio    2024-01-06\n5      13 Fertilizante B      3      69.0   142.4       Alto    2024-01-06\n6      14 Fertilizante B      4      66.1   142.0       Alto    2024-01-09\n\n\nEn el primer caso, solo se seleccionan las filas donde la columna tratamiento es igual a “Control”. En el segundo, se seleccionan las filas donde la altura es mayor a 65 cm y el tratamiento no es “Control”. Es importante notar que, a diferencia de R base, no es necesario escribir el nombre del data frame en cada condición, lo que simplifica la sintaxis (Wickham & Grolemund, 2017).\n\n\n11.3.2 Selección de columnas con select()\nLa función select() permite extraer columnas específicas de un data frame. Su sintaxis es:\n\nselect(.data, ...)\n\n\n.data: el data frame o tibble de entrada.\n...: nombres de las columnas a seleccionar, o funciones auxiliares como starts_with(), ends_with(), contains(), etc.\n\nEjemplo:\n\n# Seleccionar las columnas altura_cm y peso_gr\ndatos_mediciones &lt;- select(datos_cultivo, altura_cm, peso_gr)\nhead(datos_mediciones)  # Visualizar el resultado\n\n  altura_cm peso_gr\n1      59.4    93.3\n2      62.7   114.6\n3        NA    94.3\n4      65.7   101.8\n5      66.3   104.4\n6      82.2    77.8\n\n# Excluir la columna fecha_siembra\ndatos_sin_fecha &lt;- select(datos_cultivo, -fecha_siembra)\nhead(datos_sin_fecha)  # Visualizar el resultado\n\n  parcela    tratamiento bloque altura_cm peso_gr daño_plaga\n1       1        Control      1      59.4    93.3      Medio\n2       2        Control      2      62.7   114.6      Medio\n3       3        Control      3        NA    94.3       Bajo\n4       4        Control      4      65.7   101.8      Medio\n5       5        Control      5      66.3   104.4      Medio\n6       6 Fertilizante A      1      82.2    77.8       Bajo\n\n# Seleccionar columnas que terminan en \"cm\" o \"gr\"\ndatos_numericos &lt;- select(datos_cultivo, ends_with(\"cm\"), ends_with(\"gr\"))\nhead(datos_numericos)  # Visualizar el resultado\n\n  altura_cm peso_gr\n1      59.4    93.3\n2      62.7   114.6\n3        NA    94.3\n4      65.7   101.8\n5      66.3   104.4\n6      82.2    77.8\n\n\nEl uso de funciones auxiliares permite seleccionar columnas de manera flexible, lo que resulta útil en bases de datos extensas (Wickham et al., 2023).\n\n\n11.3.3 Creación y transformación de variables con mutate()\nLa función mutate() permite crear nuevas columnas o modificar las existentes. Su sintaxis es:\n\nmutate(.data, ...)\n\n\n.data: el data frame o tibble de entrada.\n...: una o más expresiones que definen las nuevas columnas o transformaciones.\n\nEjemplo:\n\n# Crear una nueva variable: índice de crecimiento\ndatos_cultivo &lt;- mutate(datos_cultivo,\n                       indice_crecimiento = \n                         altura_cm / peso_gr)\n\n# Crear varias variables nuevas\ndatos_cultivo &lt;- mutate(datos_cultivo,\n                       altura_m = altura_cm / 100,\n                       peso_kg = peso_gr / 1000,\n                       categoria_altura = ifelse(\n                         altura_cm &gt; 65, \"Alto\", \"Bajo\"))\n\nLa función ifelse(condición, valor_si_verdadero, valor_si_falso) permite crear variables categóricas a partir de condiciones lógicas, lo que es común en la estadística clásica para definir grupos o categorías (Wickham & Grolemund, 2017).\n\n\n11.3.4 Agrupamiento y resumen con group_by() y summarize()\nLa función group_by() agrupa los datos según una o más variables, y summarize() calcula estadísticas resumen por grupo. Sus sintaxis son:\n\ngroup_by(.data, ...)\nsummarize(.data, ...)\n\n\n.data: el data frame o tibble de entrada.\n...: variables de agrupamiento (en group_by) o expresiones de resumen (en summarize).\n\nEjemplo:\n\n# Agrupar por tratamiento y calcular estadísticas descriptivas\nresumen_tratamiento &lt;- datos_cultivo %&gt;%\n  group_by(tratamiento) %&gt;%\n  summarize(\n    media_altura = mean(altura_cm, na.rm = TRUE),\n    sd_altura = sd(altura_cm, na.rm = TRUE),\n    n = n()\n  )\nresumen_tratamiento\n\n# A tibble: 4 × 4\n  tratamiento    media_altura sd_altura     n\n  &lt;chr&gt;                 &lt;dbl&gt;     &lt;dbl&gt; &lt;int&gt;\n1 Control                63.5      3.17     5\n2 Fertilizante A         64.5     11.7      5\n3 Fertilizante B         70.2      4.82     5\n4 Fertilizante C         66.1     14.1      5\n\n\n\nmean(altura_cm, na.rm = TRUE): calcula la media, ignorando los valores NA.\nsd(altura_cm, na.rm = TRUE): calcula la desviación estándar.\nn(): cuenta el número de observaciones en cada grupo.\n\nEstas funciones son esenciales para obtener resúmenes estadísticos por grupo, como promedios por tratamiento en un experimento clásico (Wickham et al., 2023).\n\n\n11.3.5 Ordenamiento de datos con arrange()\nLa función arrange() permite ordenar los datos según una o más variables. Su sintaxis es:\n\narrange(.data, ...)\n\n\n.data: el data frame o tibble de entrada.\n...: variables por las que se desea ordenar; se puede usar desc() para orden descendente.\n\nEjemplo:\n\n# Ordenar por altura de menor a mayor\ndatos_ordenados &lt;- arrange(datos_cultivo, altura_cm)\n# Ordenar por tratamiento y peso descendente\ndatos_ordenados_multi &lt;- arrange(datos_cultivo, \n                                 tratamiento, \n                                 desc(peso_gr))\n\nEl ordenamiento es útil para identificar valores extremos o preparar tablas para reportes (Wickham & Grolemund, 2017).",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Manipulación de datos con dplyr y tidyr</span>"
    ]
  },
  {
    "objectID": "08.3_manipulacion.html#introducción-a-los-pipes",
    "href": "08.3_manipulacion.html#introducción-a-los-pipes",
    "title": "11  Manipulación de datos con dplyr y tidyr",
    "section": "11.4 Introducción a los pipes (%>%)",
    "text": "11.4 Introducción a los pipes (%&gt;%)\nEl operador pipe (%&gt;%), introducido por el paquete magrittr y adoptado como parte fundamental del tidyverse, representa una innovación significativa en la sintaxis de R. Este operador permite construir secuencias de operaciones de manera clara y lógica, siguiendo un flujo natural de procesamiento de datos. El pipe toma el resultado de una expresión a su izquierda y lo pasa como primer argumento a la función a su derecha (Wickham & Grolemund, 2017).\nLa sintaxis básica del operador pipe es:\n\n# Estructura usando pipes\ndatos %&gt;% funcion()\n# Equivalente a la siguiente estructura anidada\nfuncion(datos)\n\n\n11.4.1 Ventajas del uso de pipes\nEl uso de pipes ofrece múltiples ventajas en el análisis estadístico (Wickham et al., 2023):\n\nLegibilidad mejorada: Las operaciones se leen de izquierda a derecha y de arriba hacia abajo, siguiendo el orden natural de lectura.\nReducción de objetos intermedios: No es necesario crear variables temporales para almacenar resultados intermedios.\nFacilidad de depuración: Cada paso puede ser comentado o modificado independientemente.\nClaridad en la secuencia de operaciones: El flujo de trabajo se hace explícito y fácil de seguir.\n\n\n\n11.4.2 Ejemplo práctico\nSin pipe (anidado): En la sintaxis tradicional, las funciones deben anidarse, lo que puede dificultar la lectura:\n\n# Calcular la media de altura por tratamiento, excluyendo valores NA\nresumen_tratamiento &lt;- summarize(\n  group_by(\n    filter(datos_cultivo, !is.na(altura_cm)),\n    tratamiento\n  ),\n  media_altura = mean(altura_cm)\n)\n\nEn este ejemplo, primero se filtran las filas sin valores faltantes en altura_cm, luego se agrupan por tratamiento y finalmente se calcula la media de altura para cada grupo.\nCon pipe (más legible) el mismo análisis, usando pipes, resulta más claro y fácil de seguir:\n\n# Calcular la media de altura por tratamiento, excluyendo valores NA\nresumen_tratamiento &lt;- datos_cultivo %&gt;%\n  # 1. Eliminar filas con NA en altura_cm\n  filter(!is.na(altura_cm)) %&gt;%      \n  # 2. Agrupar los datos por tratamiento\n  group_by(tratamiento) %&gt;%         \n  # 3. Calcular la media de altura por grupo\n  summarize(media_altura = mean(altura_cm)) \n\n\nEn la primera línea, se eliminan las filas donde la altura es NA.\nEn la segunda línea, se agrupan los datos por el tipo de tratamiento.\nEn la tercera línea, se calcula la media de la altura para cada tratamiento.\n\nCada paso es explícito y se puede leer de arriba hacia abajo, lo que facilita la comprensión y depuración del análisis (Wickham & Grolemund, 2017).",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Manipulación de datos con dplyr y tidyr</span>"
    ]
  },
  {
    "objectID": "08.3_manipulacion.html#transformaciones-de-datos-con-tidyr",
    "href": "08.3_manipulacion.html#transformaciones-de-datos-con-tidyr",
    "title": "11  Manipulación de datos con dplyr y tidyr",
    "section": "11.5 Transformaciones de datos con tidyr",
    "text": "11.5 Transformaciones de datos con tidyr\nEl paquete tidyr es una herramienta fundamental para la reorganización y transformación de datos en R, permitiendo adaptar la estructura de los conjuntos de datos a los requerimientos de los métodos estadísticos clásicos. Estas transformaciones son esenciales para preparar los datos antes de aplicar técnicas como ANOVA, regresión o análisis descriptivos, ya que muchos procedimientos requieren que los datos estén en un formato específico (Wickham & Grolemund, 2017).\n\n11.5.1 Transformación de formato ancho a largo con pivot_longer()\nLa función pivot_longer() convierte varias columnas de un data frame en pares de nombre-valor, generando un formato largo. Este formato es especialmente útil en análisis estadísticos donde cada observación debe ocupar una fila y las variables medidas se representan en una columna adicional, como en el caso de ANOVA de medidas repetidas (Wickham & Grolemund, 2017).\nLa sintaxis principal de pivot_longer() es la siguiente:\n\npivot_longer(\n  data,         # Data frame o tibble de entrada\n  cols,         # Columnas a transformar (vector de nombres, rango o función selectora)\n  names_to,     # Nombre de la nueva columna que contendrá los nombres originales de las variables\n  values_to     # Nombre de la nueva columna que contendrá los valores\n)\n\nPor ejemplo, considérese un subconjunto pequeño de datos con alturas y pesos de tres parcelas:\n\nlibrary(tidyr)\n# Crear un dataframe para visualizar mejor los ejemplos\nmini_datos &lt;- data.frame(\n  parcela = c(1, 2, 3),\n  altura_cm = c(70, 65, 60),\n  peso_gr = c(120, 115, 110)\n)\nmini_datos # visualizar el data frame original\n\n  parcela altura_cm peso_gr\n1       1        70     120\n2       2        65     115\n3       3        60     110\n\n\nPara transformar este data frame a formato largo, se utiliza:\n\nmini_largo &lt;- pivot_longer(\n  data = mini_datos,\n  cols = c(altura_cm, peso_gr), # Columnas a transformar\n  names_to = \"variable\",        # Nueva columna para los nombres de las variables originales\n  values_to = \"valor\"           # Nueva columna para los valores\n)\nmini_largo # Visualizar el resultado\n\n# A tibble: 6 × 3\n  parcela variable  valor\n    &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt;\n1       1 altura_cm    70\n2       1 peso_gr     120\n3       2 altura_cm    65\n4       2 peso_gr     115\n5       3 altura_cm    60\n6       3 peso_gr     110\n\n\nEn este ejemplo, el argumento cols indica las columnas a transformar, names_to define el nombre de la columna que almacenará los nombres de las variables originales y values_to define el nombre de la columna que almacenará los valores correspondientes (Wickham & Grolemund, 2017).\n\n\n11.5.2 Transformación de formato largo a ancho con pivot_wider()\nLa función pivot_wider() realiza la transformación inversa, es decir, convierte un data frame en formato largo a formato ancho. Esto es útil para reportes o análisis que requieren que cada variable esté en una columna separada (Wickham & Grolemund, 2017).\nLa sintaxis principal de pivot_wider() es:\n\npivot_wider(\n  data,         # Data frame o tibble de entrada\n  names_from,   # Columna cuyos valores se usarán como nombres de nuevas columnas\n  values_from   # Columna cuyos valores se distribuirán en las nuevas columnas\n)\n\nUtilizando el subconjunto mini_largo generado previamente:\n\nmini_ancho &lt;- pivot_wider(\n  data = mini_largo,\n  names_from = variable,  # Columna que define los nombres de las nuevas columnas\n  values_from = valor     # Columna que define los valores a distribuir\n)\nmini_ancho # Visualizar el resultado\n\n# A tibble: 3 × 3\n  parcela altura_cm peso_gr\n    &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1       1        70     120\n2       2        65     115\n3       3        60     110\n\n\nEn este caso, el argumento names_from indica la columna cuyos valores se convertirán en nombres de nuevas columnas y values_from indica la columna cuyos valores se colocarán en las nuevas columnas (Wickham & Grolemund, 2017).\n\n\n11.5.3 Manipulación de variables compuestas con separate() y unite()\nEn ocasiones, una columna puede contener información de varias variables codificadas en un solo valor. Para dividir o combinar estas variables, se utilizan las funciones separate() y unite() (Wickham & Grolemund, 2017).\nLa función separate() divide una columna en dos o más columnas, utilizando un carácter separador. Su sintaxis principal es:\n\nseparate(\n  data,         # Data frame o tibble de entrada\n  col,          # Columna a dividir\n  into,         # Vector con los nombres de las nuevas columnas\n  sep           # Carácter separador (por defecto, cualquier carácter no alfanumérico)\n)\n\nPor ejemplo, considérese el siguiente subconjunto:\n\n# Crear el dataframe para el ejemplo\nmini_datos_comp &lt;- data.frame(\n  parcela_bloque = c(\"1-1\", \"2-2\", \"3-3\"),\n  altura_cm = c(70, 65, 60)\n)\n# Visualizar el dataframe original\nmini_datos_comp\n\n  parcela_bloque altura_cm\n1            1-1        70\n2            2-2        65\n3            3-3        60\n\n\nPara separar la columna parcela_bloque en dos columnas llamadas parcela y bloque, se utiliza:\n\nmini_separado &lt;- separate(\n  data = mini_datos_comp,\n  col = parcela_bloque,         # Columna a dividir\n  into = c(\"parcela\", \"bloque\"),# Nombres de las nuevas columnas\n  sep = \"-\"                     # Carácter separador\n)\nmini_separado # Visualizar el resultado\n\n  parcela bloque altura_cm\n1       1      1        70\n2       2      2        65\n3       3      3        60\n\n\nEl argumento col indica la columna a dividir, into define los nombres de las nuevas columnas y sep especifica el carácter separador (Wickham & Grolemund, 2017).\nLa función unite() combina dos o más columnas en una sola, utilizando un carácter separador. Su sintaxis principal es:\n\nunite(\n  data,         # Data frame o tibble de entrada\n  col,          # Nombre de la nueva columna\n  ...,          # Columnas a unir\n  sep           # Carácter separador\n)\n\nPor ejemplo, para volver a unir las columnas parcela y bloque en una sola columna parcela_bloque:\n\nmini_unido &lt;- unite(\n  data = mini_separado,\n  col = \"parcela_bloque\", # Nombre de la nueva columna\n  parcela, bloque,        # Columnas a unir\n  sep = \"-\"               # Carácter separador\n)\nmini_unido # Visualizar el resultado\n\n  parcela_bloque altura_cm\n1            1-1        70\n2            2-2        65\n3            3-3        60\n\n\nEl argumento col define el nombre de la nueva columna resultante, los siguientes argumentos son las columnas a unir y sep indica el carácter separador (Wickham & Grolemund, 2017).",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Manipulación de datos con dplyr y tidyr</span>"
    ]
  },
  {
    "objectID": "08.3_manipulacion.html#ejemplo-integrado-preparación-de-datos-para-análisis-estadístico-clásico",
    "href": "08.3_manipulacion.html#ejemplo-integrado-preparación-de-datos-para-análisis-estadístico-clásico",
    "title": "11  Manipulación de datos con dplyr y tidyr",
    "section": "11.6 Ejemplo integrado: Preparación de datos para análisis estadístico clásico",
    "text": "11.6 Ejemplo integrado: Preparación de datos para análisis estadístico clásico\nA continuación se muestra un flujo de trabajo típico para preparar los datos del experimento agrícola antes de realizar un análisis de varianza (ANOVA), utilizando dplyr y tidyr.\n\n# 1. Eliminar valores faltantes en altura y peso\ndatos_limpios &lt;- datos_cultivo %&gt;%\n  filter(!is.na(altura_cm), !is.na(peso_gr))\n\n# 2. Crear variables derivadas\ndatos_limpios &lt;- datos_limpios %&gt;%\n  mutate(\n    indice_crecimiento = altura_cm / peso_gr,\n    categoria_altura = ifelse(altura_cm &gt; 65, \"Alto\", \"Bajo\")\n  )\n\n# 3. Agrupar por tratamiento y calcular estadísticas descriptivas\nresumen_tratamiento &lt;- datos_limpios %&gt;%\n  group_by(tratamiento) %&gt;%\n  summarize(\n    media_altura = mean(altura_cm),\n    sd_altura = sd(altura_cm),\n    n = n()\n  )\nresumen_tratamiento\n\n# A tibble: 4 × 4\n  tratamiento    media_altura sd_altura     n\n  &lt;chr&gt;                 &lt;dbl&gt;     &lt;dbl&gt; &lt;int&gt;\n1 Control                63.5      3.17     4\n2 Fertilizante A         63.3     13.1      4\n3 Fertilizante B         70.2      4.82     4\n4 Fertilizante C         71.3      9.27     4\n\n# 4. Transformar a formato largo para análisis multivariado\ndatos_largo &lt;- datos_limpios %&gt;%\n  pivot_longer(\n    cols = c(altura_cm, peso_gr),\n    names_to = \"variable\",\n    values_to = \"valor\"\n  )\nhead(datos_largo)\n\n# A tibble: 6 × 11\n  parcela tratamiento bloque daño_plaga fecha_siembra indice_crecimiento\n    &lt;int&gt; &lt;chr&gt;        &lt;int&gt; &lt;chr&gt;      &lt;date&gt;                     &lt;dbl&gt;\n1       1 Control          1 Medio      2024-01-10                 0.637\n2       1 Control          1 Medio      2024-01-10                 0.637\n3       2 Control          2 Medio      2024-01-08                 0.547\n4       2 Control          2 Medio      2024-01-08                 0.547\n5       4 Control          4 Medio      2024-01-09                 0.645\n6       4 Control          4 Medio      2024-01-09                 0.645\n# ℹ 5 more variables: altura_m &lt;dbl&gt;, peso_kg &lt;dbl&gt;, categoria_altura &lt;chr&gt;,\n#   variable &lt;chr&gt;, valor &lt;dbl&gt;",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Manipulación de datos con dplyr y tidyr</span>"
    ]
  },
  {
    "objectID": "08.3_manipulacion.html#comparación-entre-la-manipulación-de-datos-con-r-base-y-tidyverse",
    "href": "08.3_manipulacion.html#comparación-entre-la-manipulación-de-datos-con-r-base-y-tidyverse",
    "title": "11  Manipulación de datos con dplyr y tidyr",
    "section": "11.7 Comparación entre la manipulación de datos con R base y tidyverse",
    "text": "11.7 Comparación entre la manipulación de datos con R base y tidyverse\nLa manipulación de datos es una etapa fundamental en el análisis estadístico clásico. Existen dos enfoques principales en R: el uso de funciones base y el uso de paquetes del tidyverse, como dplyr y tidyr. A continuación se presenta un cuadro comparativo que resume las principales diferencias entre ambos enfoques, considerando aspectos como sintaxis, legibilidad, flexibilidad y reproducibilidad (Wickham & Grolemund, 2017).\n\n\n\n\n\n\n\n\nAspecto\nR base\ntidyverse (dplyr/tidyr)\n\n\n\n\nSintaxis\nUso de corchetes, funciones como subset(), apply(), y anidación.\nUso de funciones verbales (filter(), select(), mutate(), etc.) y pipes %&gt;%.\n\n\nLegibilidad\nEl código puede ser difícil de leer, especialmente con operaciones anidadas.\nEl flujo de trabajo es secuencial y fácil de seguir, cada paso en una línea.\n\n\nCreación de variables\nSe usa $ o transform().\nSe usa mutate(), que permite crear o modificar variables de forma clara.\n\n\nFiltrado de filas\nSe usan corchetes o subset().\nSe usa filter(), con sintaxis más intuitiva y sin necesidad de repetir el nombre del data frame.\n\n\nSelección de columnas\nSe usan corchetes o select().\nSe usa select(), con funciones auxiliares como starts_with(), ends_with().\n\n\nAgrupamiento y resumen\nSe usan tapply(), aggregate(), o bucles.\nSe usan group_by() y summarize(), facilitando el cálculo de estadísticas por grupo.\n\n\nTransformación de formato\nSe usan funciones como reshape(), melt(), cast().\nSe usan pivot_longer() y pivot_wider(), con sintaxis más clara y moderna.\n\n\nManejo de variables compuestas\nSe requiere manipulación manual con funciones como strsplit().\nSe usan separate() y unite(), que simplifican la división y combinación de columnas.\n\n\nReproducibilidad\nEl código puede ser menos reproducible y más propenso a errores.\nEl uso de pipes y funciones verbales mejora la reproducibilidad y la claridad del análisis.\n\n\nCurva de aprendizaje\nFamiliar para usuarios con experiencia previa en R, pero puede ser menos intuitivo para principiantes.\nMás accesible para principiantes, especialmente por la coherencia y claridad de la sintaxis.\n\n\n\nComo se observa, el enfoque tidyverse ofrece ventajas notables en términos de claridad, reproducibilidad y facilidad de uso, especialmente en flujos de trabajo complejos o colaborativos. No obstante, el conocimiento de las funciones base de R sigue siendo valioso, ya que permite comprender el funcionamiento interno del lenguaje y resolver tareas específicas de manera eficiente (Wickham & Grolemund, 2017).",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Manipulación de datos con dplyr y tidyr</span>"
    ]
  },
  {
    "objectID": "09.1_visualizacion.html",
    "href": "09.1_visualizacion.html",
    "title": "12  Introducción a la visualización de datos",
    "section": "",
    "text": "12.1 Historia y evolución de la visualización en estadística\nLa visualización de datos se define como el proceso de representar información cuantitativa y cualitativa mediante gráficos, diagramas y otras formas visuales. Su objetivo principal es facilitar la comprensión, el análisis y la comunicación de los datos, permitiendo identificar patrones, tendencias, relaciones y anomalías que podrían pasar desapercibidas en tablas numéricas o descripciones textuales. En el contexto del análisis estadístico, la visualización es una herramienta esencial tanto en la fase exploratoria como en la presentación de resultados, ya que ayuda a validar supuestos, comunicar hallazgos y respaldar la toma de decisiones informadas (Wickham, 2016).\nLa importancia de la visualización radica en su capacidad para transformar datos complejos en representaciones accesibles y comprensibles, promoviendo la transparencia y la reproducibilidad en la investigación científica. Además, los gráficos permiten detectar errores en los datos, identificar valores atípicos y comprender la distribución de las variables antes de aplicar técnicas estadísticas formales (Tufte, 2001).\nLa visualización de datos tiene una larga tradición en la historia de la estadística. Sus orígenes se remontan al siglo XVIII, cuando se comenzaron a utilizar gráficos para representar información demográfica y económica. Uno de los hitos más importantes fue la invención del gráfico de barras por William Playfair en 1786, quien también introdujo el gráfico de líneas y el gráfico circular. Posteriormente, Florence Nightingale empleó diagramas de área para comunicar la mortalidad en hospitales militares, demostrando el poder de los gráficos para influir en la opinión pública y en la toma de decisiones políticas (Friendly, 2008).\nA lo largo del siglo XX, la visualización se consolidó como una disciplina fundamental en la estadística, especialmente con el desarrollo de la computación y el software estadístico, que permitieron la creación de gráficos más complejos y personalizados. En la actualidad, la visualización de datos es un componente central en el análisis exploratorio de datos (EDA) y en la comunicación científica, siendo reconocida como una herramienta indispensable para el trabajo estadístico (Wickham, 2016).",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Introducción a la visualización de datos</span>"
    ]
  },
  {
    "objectID": "09.1_visualizacion.html#principios-básicos-de-la-visualización-efectiva",
    "href": "09.1_visualizacion.html#principios-básicos-de-la-visualización-efectiva",
    "title": "12  Introducción a la visualización de datos",
    "section": "12.2 Principios básicos de la visualización efectiva",
    "text": "12.2 Principios básicos de la visualización efectiva\nLa visualización efectiva de datos es un componente esencial para asegurar que la información transmitida sea comprensible, precisa y útil en la toma de decisiones estadísticas. Para lograr este objetivo, es fundamental considerar tres principios clave: claridad, precisión y eficiencia. Estos principios han sido ampliamente discutidos en la literatura especializada, destacando su relevancia en la comunicación gráfica de datos (Tufte, 2001; Cleveland, 1993).\n\n12.2.1 Claridad\nLa claridad en la visualización implica que el gráfico sea comprensible y transmita el mensaje principal de manera directa, sin ambigüedades ni elementos distractores. Para lograr claridad, se deben considerar los siguientes aspectos (Tufte, 2001):\n\nEliminar elementos decorativos innecesarios, como fondos llamativos, sombras o efectos tridimensionales que no aportan información relevante.\nUtilizar títulos descriptivos y etiquetas claras en los ejes, de modo que el lector comprenda de inmediato qué variables se están representando.\nIncluir leyendas explicativas cuando se utilicen colores, símbolos o líneas para diferenciar grupos o categorías.\nMantener un diseño limpio y ordenado, evitando la sobrecarga visual y el uso excesivo de colores o tipografías.\nPresentar la información de manera secuencial y lógica, facilitando la interpretación del gráfico desde el primer vistazo.\n\n\n\n12.2.2 Precisión\nLa precisión se refiere a la representación fiel y exacta de los datos, evitando distorsiones que puedan inducir a interpretaciones erróneas. Para asegurar la precisión en los gráficos, se recomienda (Cleveland, 1993):\n\nUtilizar escalas proporcionales y adecuadas al rango de los datos, evitando truncar ejes o manipular escalas que alteren la percepción de las diferencias o relaciones.\nRepresentar todos los datos relevantes, sin omitir valores atípicos o subconjuntos importantes que puedan influir en la interpretación.\nSeleccionar el tipo de gráfico adecuado para el tipo de variable y el objetivo del análisis, por ejemplo, no usar gráficos de barras para variables continuas.\nEvitar la exageración visual de diferencias mediante el uso de áreas, volúmenes o efectos visuales que no correspondan a la magnitud real de los datos.\nRevisar cuidadosamente los datos y la codificación del gráfico para prevenir errores de transcripción o interpretación.\n\n\n\n12.2.3 Eficiencia\nLa eficiencia en la visualización implica transmitir la mayor cantidad de información relevante con el menor esfuerzo cognitivo posible para el usuario. Para lograr eficiencia, se deben seguir estas recomendacionesndefined(Tufte, 2001; Cleveland, 1993):\n\nResumir la información de manera que el gráfico muestre los aspectos más importantes sin saturar de detalles innecesarios.\nUtilizar gráficos sintéticos, como diagramas de caja o gráficos de dispersión, que permiten visualizar múltiples características de los datos en una sola imagen.\nPriorizar la información relevante para el objetivo del análisis, evitando la inclusión de variables o elementos que no aportan al mensaje principal.\nFacilitar la comparación entre grupos o categorías mediante el uso de colores, formas o posiciones consistentes y fácilmente distinguibles.\nOptimizar el tamaño y la resolución del gráfico para que sea legible tanto en pantalla como en impresiones.\n\n\n\n12.2.4 Errores comunes a evitar en la visualización de datos\nExisten errores frecuentes que pueden comprometer la efectividad de una visualización. Entre los más relevantes se encuentran (Tufte, 2001; Cleveland, 1993):\n\nUso excesivo de colores, degradados o efectos visuales que dificultan la interpretación y distraen del mensaje principal.\nOmitir etiquetas, títulos o leyendas, lo que genera confusión sobre el significado de los elementos representados.\nElegir un tipo de gráfico inadecuado para el tipo de datos, como utilizar gráficos circulares para comparar muchas categorías o gráficos de líneas para variables categóricas.\nManipular escalas de los ejes para exagerar o minimizar diferencias, lo que puede inducir a conclusiones erróneas.\nPresentar demasiada información en un solo gráfico, lo que sobrecarga al usuario y dificulta la extracción de conclusiones claras.\n\n\n\n12.2.5 Recomendaciones para una visualización efectiva\nPara garantizar la integridad y la transparencia en la presentación de los datos, se recomienda (Tufte, 2001; Cleveland, 1993):\n\nSeleccionar el tipo de gráfico más adecuado según el objetivo del análisis y la naturaleza de las variables.\nMantener un diseño simple, claro y directo, priorizando la comprensión del mensaje principal.\nRevisar y validar los gráficos antes de su presentación, asegurando que representen fielmente los datos y sean interpretables por el público objetivo.\nUtilizar recursos visuales (colores, formas, tamaños) de manera coherente y justificada, evitando la sobrecarga visual.\nDocumentar las decisiones tomadas en la construcción del gráfico, facilitando la reproducibilidad y la transparencia en el análisis.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Introducción a la visualización de datos</span>"
    ]
  },
  {
    "objectID": "09.1_visualizacion.html#tipos-de-gráficos-y-su-utilidad-en-estadística-clásica",
    "href": "09.1_visualizacion.html#tipos-de-gráficos-y-su-utilidad-en-estadística-clásica",
    "title": "12  Introducción a la visualización de datos",
    "section": "12.3 Tipos de gráficos y su utilidad en estadística clásica",
    "text": "12.3 Tipos de gráficos y su utilidad en estadística clásica\nEn la estadística clásica, la selección adecuada del tipo de gráfico es fundamental para explorar los datos, validar supuestos y comunicar resultados de manera efectiva. A continuación, se describen los principales tipos de gráficos utilizados, sus características y su utilidad específica en el análisis estadístico, siguiendo las recomendaciones de la literatura especializada (Venables & Ripley, 2002; Cleveland, 1993).\n\n12.3.1 Gráficos de barras\nLos gráficos de barras permiten comparar frecuencias o proporciones entre categorías de una variable cualitativa. Cada barra representa una categoría y su altura es proporcional a la frecuencia o porcentaje correspondiente. Este tipo de gráfico facilita la identificación de categorías dominantes o poco representadas y es especialmente útil en el análisis de variables como sexo, grupo de tratamiento o respuestas dicotómicas. Además, los gráficos de barras ayudan a detectar patrones de distribución y posibles sesgos en la recolección de datos (Cleveland, 1993).\n\n\n\n\n\n\n\n12.3.2 Histogramas\nEl histograma es la herramienta principal para visualizar la distribución de variables cuantitativas continuas. Agrupa los datos en intervalos y muestra la frecuencia de observaciones en cada uno. Esta representación permite identificar la forma de la distribución, detectar asimetrías, curtosis, valores atípicos y la presencia de múltiples modos. Los histogramas son esenciales para evaluar el supuesto de normalidad, requisito frecuente en pruebas como el ANOVA y la regresión lineal (Venables & Ripley, 2002).\n\n\n\n\n\n\n\n12.3.3 Diagramas de caja (boxplots)\nEl diagrama de caja, o boxplot, resume la distribución de una variable cuantitativa mostrando la mediana, los cuartiles y los valores extremos. Este gráfico facilita la comparación entre grupos y la identificación de valores atípicos. Además, permite evaluar la homogeneidad de la varianza, aspecto crucial en el análisis de varianza. Su interpretación sencilla y su capacidad para sintetizar información lo convierten en una herramienta indispensable en la estadística descriptiva y comparativa (Cleveland, 1993).\n\n\n\n\n\n\n\n12.3.4 Gráficos de dispersión (scatterplots)\nLos gráficos de dispersión se utilizan para analizar la relación entre dos variables cuantitativas. Cada punto representa una observación y su posición refleja los valores de ambas variables. Este tipo de gráfico permite identificar patrones de asociación, linealidad, presencia de valores atípicos y posibles agrupamientos. Además, es fundamental para explorar la existencia de correlaciones y para evaluar el supuesto de linealidad en modelos de regresión (Venables & Ripley, 2002).\n\n\n\n\n\n\n\n12.3.5 Gráficos QQ (quantile-quantile)\nEl gráfico QQ compara la distribución de los datos observados con una distribución teórica, generalmente la normal. Si los puntos del gráfico se alinean sobre la diagonal, se puede concluir que los datos siguen la distribución teórica. Este gráfico es esencial para evaluar el supuesto de normalidad en pruebas paramétricas y para detectar desviaciones sistemáticas, colas pesadas o asimetrías en la distribución de los datos (Cleveland, 1993).\n\n\n\n\n\n\n\n12.3.6 Gráficos de residuos\nLos gráficos de residuos muestran la diferencia entre los valores observados y los valores ajustados por un modelo estadístico. Un patrón aleatorio en estos gráficos indica que el modelo es adecuado, mientras que la presencia de patrones sistemáticos sugiere problemas de especificación, heterocedasticidad o autocorrelación. Estos gráficos son fundamentales en la validación de modelos de regresión y en la toma de decisiones sobre la necesidad de transformar variables o ajustar el modelo (Venables & Ripley, 2002).",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Introducción a la visualización de datos</span>"
    ]
  },
  {
    "objectID": "09.2_visualizacion.html",
    "href": "09.2_visualizacion.html",
    "title": "13  Visualizaciones Base de R",
    "section": "",
    "text": "13.1 Funciones gráficas básicas de R\nLa comprensión de los principios básicos de la visualización efectiva constituye la base para una correcta interpretación y comunicación de los datos en el análisis estadístico. Sin embargo, para llevar estos principios a la práctica, es indispensable conocer y dominar las herramientas que permiten construir representaciones gráficas de calidad. En este sentido, el lenguaje R ofrece un conjunto robusto de funciones base que facilitan la creación de diversos tipos de gráficos, esenciales para la exploración y validación de los supuestos estadísticos en la estadística clásica. El siguiente capítulo se centra en el uso de estas funciones, proporcionando ejemplos y recomendaciones para su aplicación en el análisis de datos, y mostrando cómo los conceptos teóricos previamente expuestos se materializan en la práctica cotidiana del análisis estadístico (Venables & Ripley, 2002).\nEl sistema gráfico base de R constituye una de las herramientas más accesibles y versátiles para la visualización de datos en estadística clásica. Estas funciones permiten crear gráficos de manera rápida y flexible, facilitando tanto la exploración inicial de los datos como la comprobación de supuestos estadísticos fundamentales. El enfoque de R base se basa en la construcción secuencial de gráficos, donde cada elemento puede ser añadido o modificado mediante argumentos y funciones auxiliares, lo que resulta especialmente útil en el análisis exploratorio y diagnóstico (Murrell, 2018; Venables & Ripley, 2002).\nEntre las funciones más utilizadas se encuentran:\nEstas funciones son la base para la mayoría de los análisis gráficos en estadística clásica, permitiendo una rápida inspección visual de los datos y la validación de supuestos (Venables & Ripley, 2002).",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Visualizaciones Base de R</span>"
    ]
  },
  {
    "objectID": "09.2_visualizacion.html#funciones-gráficas-básicas-de-r",
    "href": "09.2_visualizacion.html#funciones-gráficas-básicas-de-r",
    "title": "13  Visualizaciones Base de R",
    "section": "",
    "text": "plot(): función genérica para gráficos de dispersión, líneas y otros tipos de visualizaciones.\nhist(): para la creación de histogramas que muestran la distribución de variables cuantitativas.\nboxplot(): para diagramas de caja que resumen la dispersión y los valores atípicos.\nbarplot(): para gráficos de barras de frecuencias o proporciones.\nqqnorm() y qqline(): para gráficos Q-Q que evalúan la normalidad de los datos.\npairs(): para matrices de gráficos de dispersión entre varias variables.",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Visualizaciones Base de R</span>"
    ]
  },
  {
    "objectID": "09.2_visualizacion.html#creación-de-gráficos-exploratorios",
    "href": "09.2_visualizacion.html#creación-de-gráficos-exploratorios",
    "title": "13  Visualizaciones Base de R",
    "section": "13.2 Creación de gráficos exploratorios",
    "text": "13.2 Creación de gráficos exploratorios\nLa creación de gráficos exploratorios en R base es fundamental para el análisis inicial de los datos y la detección de patrones, tendencias y anomalías. A continuación se detallan los principales tipos de gráficos, su sintaxis y los argumentos más relevantes, acompañados de ejemplos y explicaciones pedagógicas (Venables & Ripley, 2002; Murrell, 2018).\n\n13.2.1 Histogramas\nLa función principal para crear histogramas en R es hist(). Su sintaxis general es:\n\nhist(x, \n     breaks = \"Sturges\", \n     freq = TRUE, \n     col = NULL, \n     border = NULL, \n     main = NULL, \n     xlab = NULL, \n     ylab = NULL, \n     ...)\n\nExplicación de los argumentos:\n\nx: Vector numérico con los datos a graficar.\nbreaks: Define el número de intervalos (bins) o el método para calcularlos. Puede ser un número, un vector de puntos de corte, o un método como “Sturges”, “Scott”, “FD”.\nfreq: Si es TRUE, el eje Y muestra frecuencias absolutas; si es FALSE, muestra densidades.\ncol: Color de las barras.\nborder: Color del borde de las barras.\nmain: Título principal del gráfico.\nxlab, ylab: Etiquetas de los ejes X e Y.\n...: Otros argumentos gráficos adicionales.\n\nEjemplo detallado:\n\n# Simulación de datos\nset.seed(123)\nnotas &lt;- rnorm(200, mean = 70, sd = 10)\n\n# Histograma personalizado\nhist(notas,\n     breaks = 15,                # Número de intervalos\n     freq = TRUE,                # Mostrar frecuencias absolutas\n     col = \"lightblue\",          # Color de las barras\n     border = \"darkblue\",        # Color del borde\n     main = \"Histograma de calificaciones\", # Título\n     xlab = \"Puntaje\",           # Etiqueta eje X\n     ylab = \"Frecuencia\")        # Etiqueta eje Y\n\n\n\n\n\n\n\n\n\n\n13.2.2 Diagramas de caja (boxplots)\nLa función principal es boxplot(). Su sintaxis general es:\n\nboxplot(formula, \n        data = NULL, \n        main = NULL, \n        xlab = NULL, \n        ylab = NULL, \n        col = NULL, \n        border = NULL, \n        notch = FALSE, \n        outline = TRUE, \n        ...)\n\n\nformula: Expresión del tipo y ~ grupo para comparar grupos.\ndata: Data frame donde buscar las variables.\nmain, xlab, ylab: Títulos y etiquetas.\ncol: Colores de las cajas.\nborder: Color del borde de las cajas.\nnotch: Si es TRUE, añade una muesca para comparar medianas.\noutline: Si es TRUE, muestra valores atípicos.\n...: Otros argumentos gráficos.\n\nEjemplo detallado:\n\n# Simulación de datos para dos grupos\nset.seed(123)\ngrupo &lt;- factor(rep(c(\"Control\", \"Tratamiento\"), each = 100))\nvalores &lt;- c(rnorm(100, 70, 8), rnorm(100, 75, 10))\n\n# Boxplot personalizado\nboxplot(valores ~ grupo,\n        main = \"Comparación entre Grupos\",\n        xlab = \"Grupo\",\n        ylab = \"Valores\",\n        col = c(\"lightgreen\", \"lightcoral\"),\n        border = \"darkgray\",\n        notch = TRUE,             # Mostrar muesca para comparar medianas\n        outline = TRUE)           # Mostrar valores atípicos\n\n\n\n\n\n\n\n\n\n\n13.2.3 Gráficos de dispersión\nLa función principal es plot(). Su sintaxis general para dos variables es:\n\nplot(x, y, \n     type = \"p\", \n     main = NULL, \n     sub = NULL, \n     xlab = NULL, \n     ylab = NULL, \n     pch = 1, \n     col = NULL, \n     cex = 1, \n     ...)\n\nExplicación de los argumentos:\n\nx, y: Vectores numéricos de igual longitud.\ntype: Tipo de gráfico (“p” para puntos, “l” para líneas, “b” para ambos).\nmain, sub: Título principal y subtítulo.\nxlab, ylab: Etiquetas de los ejes.\npch: Tipo de símbolo para los puntos (1: círculo, 16: círculo sólido, 17: triángulo, etc.).\ncol: Color de los puntos.\ncex: Tamaño relativo de los puntos.\n...: Otros argumentos gráficos.\n\nEjemplo detallado:\n\n# Simulación de datos\nset.seed(123)\nx &lt;- rnorm(100, mean = 10, sd = 2)\ny &lt;- 2 * x + rnorm(100, 0, 3)\n\n# Gráfico de dispersión personalizado\nplot(x, y,\n     type = \"p\",                  # Tipo de gráfico: puntos\n     main = \"Relación entre X e Y\",\n     sub = \"Datos simulados\",\n     xlab = \"Variable X\",\n     ylab = \"Variable Y\",\n     pch = 16,                    # Círculo sólido\n     col = \"navy\",                # Color de los puntos\n     cex = 1.2)                   # Tamaño de los puntos\n\n# Añadir línea de regresión\nabline(lm(y ~ x), col = \"red\", lwd = 2, lty = 2)\n\n\n\n\n\n\n\n\n\n\n13.2.4 Gráficos de líneas\nPara series temporales o secuencias, se usa plot() con type = \"l\":\n\nplot(x, y, \n     type = \"l\", \n     main = NULL, \n     xlab = NULL, \n     ylab = NULL, \n     col = NULL, \n     lwd = 1, \n     ...)\n\n\ntype = \"l\": Dibuja una línea.\nlwd: Grosor de la línea.\n\nEjemplo detallado:\n\n# Simulación de serie temporal\nset.seed(123)\ntiempo &lt;- 1:50\nmedidas &lt;- cumsum(rnorm(50))\n\n# Gráfico de líneas\nplot(tiempo, medidas,\n     type = \"l\",                  # Tipo de gráfico: línea\n     main = \"Serie temporal simulada\",\n     xlab = \"Tiempo\",\n     ylab = \"Medida\",\n     col = \"darkred\",\n     lwd = 2)                     # Grosor de la línea\n\n# Añadir puntos sobre la línea\npoints(tiempo, medidas, pch = 16, col = \"black\")",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Visualizaciones Base de R</span>"
    ]
  },
  {
    "objectID": "09.2_visualizacion.html#visualización-para-la-comprobación-de-supuestos-estadísticos",
    "href": "09.2_visualizacion.html#visualización-para-la-comprobación-de-supuestos-estadísticos",
    "title": "13  Visualizaciones Base de R",
    "section": "13.3 Visualización para la comprobación de supuestos estadísticos",
    "text": "13.3 Visualización para la comprobación de supuestos estadísticos\nLa validación gráfica de supuestos estadísticos es fundamental para garantizar la validez de los análisis en estadística clásica. Esta sección se centra en las herramientas gráficas específicas que R base proporciona para evaluar los supuestos de normalidad, homocedasticidad y linealidad, esenciales en pruebas como ANOVA y regresión lineal (Venables & Ripley, 2002).\n\n13.3.1 Gráficos Q-Q para evaluar normalidad\nLos gráficos Q-Q (quantile-quantile) constituyen una herramienta visual poderosa para evaluar el ajuste de los datos a una distribución teórica. Cuando los puntos se alinean sobre la diagonal, se puede inferir que los datos siguen la distribución de referencia, típicamente la normal. Las desviaciones sistemáticas de esta línea sugieren alejamientos de la normalidad que pueden requerir transformaciones de datos o el uso de métodos no paramétricos (Cleveland, 1993).\nLa sintaxis básica para crear gráficos Q-Q en R incluye dos funciones principales: qqnorm() para crear el gráfico base y qqline() para añadir la línea de referencia. A continuación se presenta un ejemplo comentado que ilustra su implementación:\n\n# Simulación de tres conjuntos de datos con diferentes distribuciones\nset.seed(123)\ndatos_normales &lt;- rnorm(100, mean = 0, sd = 1)      # Distribución normal\ndatos_asimetricos &lt;- rexp(100, rate = 1)            # Distribución exponencial\ndatos_uniformes &lt;- runif(100, min = -3, max = 3)    # Distribución uniforme\n\n# Configuración de la ventana gráfica para múltiples gráficos\npar(mfrow = c(1,3))\n\n# Gráfico Q-Q para datos normales\nqqnorm(datos_normales,\n       main = \"Datos Normales\",\n       pch = 16,                # Tipo de punto: círculo sólido\n       col = \"navy\")           # Color de los puntos\nqqline(datos_normales,         # Línea de referencia\n       col = \"red\",            # Color de la línea\n       lwd = 2)                # Grosor de la línea\n\n# Gráfico Q-Q para datos asimétricos\nqqnorm(datos_asimetricos,\n       main = \"Datos Asimétricos\",\n       pch = 16,\n       col = \"darkgreen\")\nqqline(datos_asimetricos,\n       col = \"red\",\n       lwd = 2)\n\n# Gráfico Q-Q para datos uniformes\nqqnorm(datos_uniformes,\n       main = \"Datos Uniformes\",\n       pch = 16,\n       col = \"purple\")\nqqline(datos_uniformes,\n       col = \"red\",\n       lwd = 2)\n\n\n\n\n\n\n\n# Restaurar la configuración original de la ventana gráfica\npar(mfrow = c(1,1))\n\nLa interpretación de estos gráficos se basa en el patrón que forman los puntos en relación con la línea de referencia. Según Venables & Ripley (2002), las desviaciones más comunes incluyen: 1) Colas pesadas, cuando los extremos se alejan de la línea, 2) Asimetría, cuando se forma un patrón curvilíneo, y 3) Bimodalidad, cuando aparece un patrón en forma de S.\n\n\n13.3.2 Gráficos de diagnóstico para modelos de regresión\nLos gráficos de diagnóstico en regresión permiten evaluar simultáneamente varios supuestos del modelo lineal. R proporciona una serie de gráficos diagnósticos automáticos a través de la función plot() aplicada a objetos de clase lm. El siguiente ejemplo ilustra su implementación y uso:\n\n# Simulación de datos para regresión lineal\nset.seed(123)\nx &lt;- seq(1, 100)                           # Variable predictora\ny &lt;- 2 * x + rnorm(100, 0, 10)            # Variable respuesta con error normal\ndatos &lt;- data.frame(x = x, y = y)          # Crear data frame\n\n# Ajuste del modelo de regresión lineal\nmodelo &lt;- lm(y ~ x, data = datos)          # Ajustar modelo\n\n# Gráficos de diagnóstico\npar(mfrow = c(2,2))                        # Configurar ventana 2x2\nplot(modelo)                               # Generar gráficos diagnósticos\n\n\n\n\n\n\n\n# Restaurar la configuración original de la ventana gráfica\npar(mfrow = c(1,1))\n\nLos gráficos diagnósticos generados incluyen, según Murrell (2018): 1) Residuos vs valores ajustados, para evaluar linealidad y homocedasticidad, 2) Q-Q de residuos, para verificar normalidad, 3) Scale-Location, para examinar la homogeneidad de varianza, y 4) Residuos vs Leverage, para identificar observaciones influyentes.",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Visualizaciones Base de R</span>"
    ]
  },
  {
    "objectID": "09.2_visualizacion.html#personalización-de-gráficos-en-r-base",
    "href": "09.2_visualizacion.html#personalización-de-gráficos-en-r-base",
    "title": "13  Visualizaciones Base de R",
    "section": "13.4 Personalización de gráficos en R base",
    "text": "13.4 Personalización de gráficos en R base\nLa personalización se logra modificando los argumentos de las funciones gráficas y añadiendo elementos con funciones auxiliares. A continuación se explican los argumentos más importantes y se muestra un ejemplo integral (Murrell, 2018).\n\n13.4.1 Principales argumentos y funciones:\n\nmain, sub, xlab, ylab: Títulos y etiquetas.\ncol, border, pch, lty, lwd: Colores, símbolos, tipo y grosor de líneas.\ncex, cex.axis, cex.lab, cex.main: Tamaño de símbolos y textos.\nlegend(): Añade leyendas.\ntext(): Añade texto en posiciones específicas.\nabline(): Añade líneas horizontales, verticales o de regresión.\ngrid(): Añade cuadrícula.\n\n\n\n13.4.2 Ejemplo integral\n\n# Gráfico de dispersión personalizado\nplot(x, y,\n     main = \"Gráfico personalizado\",\n     sub = \"Datos simulados\",\n     xlab = \"Variable X\",\n     ylab = \"Variable Y\",\n     col = \"blue\",                # Color de los puntos\n     pch = 17,                    # Triángulo sólido\n     cex = 1.5,                   # Tamaño de los puntos\n     cex.main = 1.2,              # Tamaño del título\n     cex.lab = 1.1)               # Tamaño de etiquetas\n\n# Añadir línea de regresión\nabline(lm(y ~ x), col = \"red\", lwd = 2, lty = 2)\n\n# Añadir leyenda\nlegend(\"topleft\",\n       legend = c(\"Datos\", \"Ajuste lineal\"),\n       pch = c(17, NA),\n       lty = c(NA, 2),\n       col = c(\"blue\", \"red\"),\n       bty = \"n\",\n       cex = 0.8)\n\n# Añadir cuadrícula\ngrid(col = \"gray80\", lty = \"dotted\")\n\n\n\n\n\n\n\n\nEste ejemplo muestra cómo modificar títulos, etiquetas, colores, símbolos, tamaños, añadir líneas de tendencia, leyendas y cuadrículas para lograr una visualización clara y profesional (Murrell, 2018; Venables & Ripley, 2002).",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Visualizaciones Base de R</span>"
    ]
  },
  {
    "objectID": "09.3_visualizacion.html",
    "href": "09.3_visualizacion.html",
    "title": "14  Visualización de datos con ggplot2",
    "section": "",
    "text": "14.1 Contexto y origen de la base de datos utilizada\nLa base de datos empleada en este capítulo corresponde a un estudio transversal realizado en la Universidad de San Carlos de Guatemala en 2002. El objetivo del estudio fue caracterizar a la población estudiantil de primer ingreso, recolectando información de 460 estudiantes de diversas facultades. Las variables incluidas abarcan datos sociodemográficos (facultad, edad, sexo, estado civil, jornada de estudio, año de ingreso), antropométricos (peso, talla, IMC), clínicos (presión arterial) y de hábitos (tabaquismo, consumo de alcohol, actividad física, entre otros). Esta base de datos, disponible en formato Excel y CSV, constituye un recurso ideal para ilustrar las capacidades de visualización de ggplot2 en el análisis estadístico aplicado a datos reales (Wickham, 2016).\nAntes de iniciar cualquier análisis, es fundamental importar correctamente la base de datos y asegurarse de que las variables tengan el tipo de dato adecuado. Se recomienda guardar el archivo en la carpeta de trabajo del proyecto y utilizar los siguientes comandos para su importación y verificación:\n# Instalar y cargar los paquetes necesarios\nif (!require(\"tidyverse\")) install.packages(\"tidyverse\")\nif (!require(\"readxl\")) install.packages(\"readxl\")\n\n\n# Importar la base de datos USAC 2002\nUSAC2002 &lt;- read_excel(\"Base_de_datos_USAC_2002.xlsx\", sheet = \"DATOS\")\n\n# Comprobar la estructura de las variables\nstr(USAC2002)\n\ntibble [460 × 16] (S3: tbl_df/tbl/data.frame)\n $ FACULTAD   : chr [1:460] \"Admon.\" \"Admon.\" \"Admon.\" \"Admon.\" ...\n $ EDAD       : num [1:460] 21 21 31 38 24 34 34 22 42 39 ...\n $ SEXO       : chr [1:460] \"M\" \"M\" \"F\" \"M\" ...\n $ EST_CIVIL  : chr [1:460] \"soltero\" \"soltero\" \"casado\" \"unido\" ...\n $ TRABAJA    : num [1:460] 2 1 1 1 1 2 1 1 1 1 ...\n $ JORNADA    : chr [1:460] \"vespertina\" \"vespertina\" \"nocturna\" \"nocturna\" ...\n $ AÑO_ING    : num [1:460] 1998 1998 1991 1992 1995 ...\n $ PESO_lbs   : num [1:460] 150 150 197 120 175 156 190 137 198 150 ...\n $ PESO_kg    : num [1:460] 68.2 68.2 89.5 54.5 79.5 ...\n $ TALLA      : num [1:460] 1.7 1.72 1.55 1.7 1.7 1.7 1.74 1.71 1.82 1.68 ...\n $ IMC        : num [1:460] 23.6 23 37.3 18.9 27.5 ...\n $ OBESIDAD   : num [1:460] 2 2 1 2 1 2 1 2 1 2 ...\n $ Fuma       : chr [1:460] \"2\" \"2\" \"1\" \"2\" ...\n $ Alcohol    : num [1:460] 2 1 2 2 2 2 1 1 2 1 ...\n $ IMC_Clase  : chr [1:460] \"NORMAL\" \"NORMAL\" \"OBESO\" \"NORMAL\" ...\n $ Grupos_Edad: chr [1:460] \"Adulto_joven\" \"Adulto_joven\" \"Adulto_joven\" \"Adulto_maduro\" ...\nEste paso permite identificar si existen variables que requieren ser convertidas a factores (por ejemplo, SEXO, FACULTAD, JORNADA) o si es necesario ajustar nombres para facilitar su uso en R. La correcta preparación de los datos es esencial para obtener visualizaciones precisas y significativas (Wickham, 2016).",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Visualización de datos con ggplot2</span>"
    ]
  },
  {
    "objectID": "09.3_visualizacion.html#introducción-al-paquete-ggplot2",
    "href": "09.3_visualizacion.html#introducción-al-paquete-ggplot2",
    "title": "14  Visualización de datos con ggplot2",
    "section": "14.2 Introducción al paquete ggplot2",
    "text": "14.2 Introducción al paquete ggplot2\nggplot2 es un paquete de R que se utiliza para crear gráficos estadísticos de alta calidad de manera sencilla y flexible. Forma parte del conjunto de herramientas conocido como tidyverse, que está diseñado para facilitar el análisis y la visualización de datos. La principal característica de ggplot2 es que se basa en la “gramática de los gráficos”, una idea desarrollada por Wilkinson (2005) y adaptada por Wickham (2016), que permite construir gráficos complejos a partir de piezas simples y combinables.\nA diferencia de los gráficos base de R, donde cada tipo de gráfico tiene su propia función y la personalización puede ser complicada, ggplot2 utiliza una estructura modular. Esto significa que se puede empezar con un gráfico básico y, poco a poco, ir añadiendo o modificando elementos para adaptarlo a lo que se necesita. Así, se pueden crear gráficos claros, atractivos y personalizados para comunicar los resultados de un análisis de datos de forma efectiva (Wickham, 2016).\n\n14.2.1 Ventajas principales de ggplot2\n\nPermite crear muchos tipos de gráficos, como barras, líneas, puntos, histogramas y boxplots, entre otros.\nCada parte del gráfico se puede personalizar fácilmente: colores, títulos, etiquetas, escalas, temas y más.\nSe integra muy bien con otras herramientas del tidyverse, lo que facilita trabajar con datos y visualizarlos en un solo flujo de trabajo.\nUtiliza una lógica de “capas”, lo que significa que se pueden añadir diferentes elementos (como puntos, líneas o etiquetas) uno sobre otro, de manera ordenada y controlada.\n\n\n\n14.2.2 ¿Cómo funciona la gramática de los gráficos?\nLa gramática de los gráficos es como una receta que indica qué ingredientes debe tener un gráfico y cómo combinarlos. En ggplot2, cada gráfico se construye a partir de varios componentes básicos (Wickham, 2016; Wilkinson, 2005):\n\nDatos: Es el conjunto de información que se quiere visualizar, normalmente en forma de tabla o data frame.\nMapeos estéticos (aes): Son las instrucciones que indican cómo se relacionan las variables de los datos con los elementos visuales del gráfico, como la posición en los ejes, el color o el tamaño de los puntos.\nGeometrías (geoms): Son las formas que se usan para mostrar los datos, por ejemplo, barras para un gráfico de barras, puntos para un gráfico de dispersión, o cajas para un boxplot.\nEscalas: Permiten controlar cómo se muestran los valores en el gráfico, por ejemplo, los colores, los tamaños o los intervalos de los ejes.\nSistemas de coordenadas: Determinan el tipo de espacio en el que se dibuja el gráfico, como el sistema cartesiano (el más común) o el sistema polar (para gráficos circulares).\nFacetas: Sirven para dividir el gráfico en varios paneles, mostrando diferentes grupos de datos uno al lado del otro, lo que facilita la comparación entre categorías.\nTemas: Permiten cambiar el aspecto general del gráfico, como el fondo, los textos y las líneas de cuadrícula, para que el resultado sea más claro y profesional.",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Visualización de datos con ggplot2</span>"
    ]
  },
  {
    "objectID": "09.3_visualizacion.html#estructura-básica-de-un-gráfico-en-ggplot2",
    "href": "09.3_visualizacion.html#estructura-básica-de-un-gráfico-en-ggplot2",
    "title": "14  Visualización de datos con ggplot2",
    "section": "14.3 Estructura básica de un gráfico en ggplot2",
    "text": "14.3 Estructura básica de un gráfico en ggplot2\nLa construcción de un gráfico en ggplot2 sigue una lógica de capas, donde cada componente se añade mediante el operador +. El proceso básico incluye:\n\nIniciar el objeto gráfico con la función ggplot(), especificando el conjunto de datos y los mapeos estéticos principales mediante aes(). Por ejemplo, se puede representar la EDAD en el eje X y el IMC en el eje Y.\nAñadir una o más capas geométricas, como geom_point() para puntos, geom_histogram() para histogramas, o geom_boxplot() para diagramas de caja.\nIncorporar escalas para controlar la interpretación de los valores, como escalas de color o tamaño.\nAñadir etiquetas y títulos con labs() o ggtitle(), y modificar la apariencia general del gráfico con funciones de tema como theme_minimal().\nOpcionalmente, añadir facetas para dividir el gráfico en paneles según una variable categórica, como SEXO o JORNADA.\n\nEjemplo básico:\n\nggplot(data = USAC2002, aes(x = EDAD, y = IMC)) +\n  geom_point() +\n  labs(title = \"Relación entre edad e IMC\", \n       x = \"Edad (años)\", \n       y = \"Índice de Masa Corporal (IMC)\")   \n\n\n\n\n\n\n\n\nEn este ejemplo, cada línea añade un componente al gráfico. El mapeo estético aes(x = EDAD, y = IMC) define qué variables se representan en los ejes, mientras que geom_point() indica que se utilizarán puntos para visualizar la relación.",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Visualización de datos con ggplot2</span>"
    ]
  },
  {
    "objectID": "09.3_visualizacion.html#creación-de-gráficos-exploratorios-y-descriptivos",
    "href": "09.3_visualizacion.html#creación-de-gráficos-exploratorios-y-descriptivos",
    "title": "14  Visualización de datos con ggplot2",
    "section": "14.4 Creación de gráficos exploratorios y descriptivos",
    "text": "14.4 Creación de gráficos exploratorios y descriptivos\nEn el análisis de datos, la visualización inicial es clave para comprender la estructura y las características principales de las variables. ggplot2 permite construir de manera eficiente los gráficos más utilizados en la exploración y descripción de datos, facilitando la identificación de patrones, tendencias y diferencias entre grupos (Wickham, 2016).\n\n14.4.1 Gráficos de barras para variables categóricas\nEl gráfico de barras es una herramienta fundamental para mostrar la cantidad de observaciones en cada categoría de una variable cualitativa. En ggplot2, este tipo de gráfico se genera de forma automática a partir de los datos, permitiendo comparar visualmente la frecuencia de cada grupo.\n\n# Crear gráfico de barras para la variable JORNADA\n# Este gráfico muestra la distribución de estudiantes en las diferentes jornadas\n\nggplot(data = USAC2002,                    # Especificamos la base de datos\n       aes(x = JORNADA)) +                 # Variable categórica en el eje X\n  geom_bar(fill = \"orange\",                # Color de relleno de las barras\n           color = \"black\") +              # Color del borde de las barras\n  labs(title = \"Distribución de estudiantes por jornada\",  # Título del gráfico\n       x = \"Jornada\",                      # Etiqueta del eje X\n       y = \"Frecuencia\")                   # Etiqueta del eje Y\n\n\n\n\n\n\n\n\nExplicación del código:\n\nLa función ggplot() inicia la construcción del gráfico especificando los datos y el mapeo estético.\ngeom_bar() crea automáticamente las barras contando las observaciones en cada categoría.\nLos argumentos fill y color personalizan la apariencia de las barras.\nLa función labs() añade las etiquetas necesarias para la interpretación del gráfico.\n\n\n\n14.4.2 Histogramas para variables continuas\nEl histograma es el gráfico más adecuado para examinar la distribución de una variable numérica. Permite observar la forma general de los datos, la presencia de asimetrías y la existencia de valores extremos.\n\n# Crear histograma para la variable PESO_lbs\n# Este gráfico muestra la distribución del peso de los estudiantes\n\nggplot(data = USAC2002,                    # Especificamos la base de datos\n       aes(x = PESO_lbs)) +                # Variable numérica en el eje X\n  geom_histogram(bins = 15,                # Número de intervalos\n                 fill = \"lightblue\",       # Color de relleno de las barras\n                 color = \"darkblue\") +     # Color del borde de las barras\n  labs(title = \"Histograma del peso en libras\",  # Título del gráfico\n       x = \"Peso en libras\",              # Etiqueta del eje X\n       y = \"Frecuencia\")                  # Etiqueta del eje Y\n\n\n\n\n\n\n\n\nExplicación del código:\n\nEl parámetro bins determina el número de intervalos en que se dividirán los datos.\nLos colores se eligen para contrastar el relleno con el borde de las barras.\nLas etiquetas proporcionan contexto sobre la variable analizada.\n\n\n\n14.4.3 Gráficos de dispersión para relaciones entre variables numéricas\nEl gráfico de dispersión es la opción principal para explorar la relación entre dos variables cuantitativas. Cada punto representa una observación, ubicándose según sus valores en los ejes X e Y.\n\n# Crear gráfico de dispersión para TALLA vs PESO_lbs\n# Este gráfico muestra la relación entre la talla y el peso de los estudiantes\n\nggplot(data = USAC2002,                    # Especificamos la base de datos\n       aes(x = TALLA,                      # Variable numérica en el eje X\n           y = PESO_lbs)) +                # Variable numérica en el eje Y\n  geom_point(color = \"red\",                # Color de los puntos\n             size = 2) +                   # Tamaño de los puntos\n  labs(title = \"Relación entre talla y peso\",  # Título del gráfico\n       x = \"Talla (metros)\",              # Etiqueta del eje X\n       y = \"Peso (libras)\")               # Etiqueta del eje Y\n\n\n\n\n\n\n\n\nExplicación del código:\n\ngeom_point() crea un punto por cada par de valores (TALLA, PESO_lbs).\nEl argumento size controla el tamaño de los puntos para mejorar su visibilidad.\nLas etiquetas incluyen las unidades de medida para mayor claridad.\n\n\n\n14.4.4 Boxplots para comparación de grupos\nEl boxplot es un gráfico que resume la distribución de una variable numérica y facilita la comparación entre diferentes grupos definidos por una variable categórica (Wickham, 2016).\n\n# Crear boxplot para PESO_lbs por SEXO\n# Este gráfico compara la distribución del peso entre hombres y mujeres\n\nggplot(data = USAC2002,                    # Especificamos la base de datos\n       aes(x = SEXO,                       # Variable categórica en el eje X\n           y = PESO_lbs,                   # Variable numérica en el eje Y\n           fill = SEXO)) +                 # Color según el sexo\n  geom_boxplot() +                         # Crear el boxplot\n  labs(title = \"Distribución del peso por sexo\",  # Título del gráfico\n       x = \"Sexo\",                         # Etiqueta del eje X\n       y = \"Peso (libras)\")               # Etiqueta del eje Y\n\n\n\n\n\n\n\n\nExplicación del código:\n\nEl mapeo estético fill = SEXO asigna automáticamente diferentes colores a cada grupo.\ngeom_boxplot() crea las cajas que muestran la distribución de cada grupo.\nLas etiquetas ayudan a interpretar la comparación entre grupos.\n\nEstos gráficos constituyen la base del análisis exploratorio y descriptivo en R con ggplot2, permitiendo obtener una visión clara y rápida de los datos antes de aplicar técnicas estadísticas más avanzadas (Wickham, 2016).",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Visualización de datos con ggplot2</span>"
    ]
  },
  {
    "objectID": "09.3_visualizacion.html#personalización-de-gráficos-en-ggplot2",
    "href": "09.3_visualizacion.html#personalización-de-gráficos-en-ggplot2",
    "title": "14  Visualización de datos con ggplot2",
    "section": "14.5 Personalización de gráficos en ggplot2",
    "text": "14.5 Personalización de gráficos en ggplot2\nLa personalización de gráficos es un aspecto fundamental para comunicar efectivamente los resultados de un análisis estadístico. ggplot2 ofrece una amplia gama de opciones para adaptar cada elemento visual según las necesidades específicas del usuario y el contexto de presentación (Wickham, 2016).\n\n14.5.1 Modificación de colores y escalas\nLa elección adecuada de colores puede mejorar significativamente la interpretación de un gráfico. ggplot2 permite personalizar los colores tanto de manera directa como a través de escalas predefinidas o personalizadas.\n\n# Ejemplo de personalización de colores en un boxplot\n# Este gráfico compara el peso entre sexos con colores específicos\n\nggplot(data = USAC2002,                    # Especificamos la base de datos\n       aes(x = SEXO,                       # Variable categórica en eje X\n           y = PESO_lbs,                   # Variable numérica en eje Y\n           fill = SEXO)) +                 # Color de relleno según sexo\n  geom_boxplot() +                         # Crear boxplot\n  scale_fill_manual(                       # Personalizar colores de relleno\n    values = c(\"pink\", \"lightblue\")) +     # Asignar colores específicos\n  labs(title = \"Distribución del peso por sexo\",  # Título principal\n       x = \"Sexo\",                         # Etiqueta eje X\n       y = \"Peso (libras)\",               # Etiqueta eje Y\n       fill = \"Sexo\") +                   # Título de la leyenda\n  theme_minimal()                          # Tema minimalista\n\n\n\n\n\n\n\n\nExplicación del código:\n\nLa función scale_fill_manual() permite asignar colores específicos a cada categoría.\nLos colores se eligen para maximizar el contraste y la legibilidad.\nEl argumento fill en labs() personaliza el título de la leyenda.\n\n\n\n14.5.2 Etiquetas, títulos y leyendas\nLas etiquetas y títulos son esenciales para proporcionar contexto y facilitar la interpretación del gráfico. ggplot2 ofrece múltiples opciones para personalizar estos elementos.\n\n# Ejemplo de personalización completa de etiquetas\n# Este gráfico incluye título, subtítulo y nota al pie\n\nggplot(data = USAC2002,                    # Especificamos la base de datos\n       aes(x = FACULTAD)) +                # Variable categórica en eje X\n  geom_bar(fill = \"steelblue\",            # Color de las barras\n           alpha = 0.7) +                  # Transparencia de las barras\n  labs(\n    title = \"Distribución de estudiantes por facultad\",     # Título principal\n    subtitle = \"Datos del estudio de 2002, USAC\",          # Subtítulo\n    x = \"Facultad\",                                        # Etiqueta eje X\n    y = \"Cantidad de estudiantes\",                         # Etiqueta eje Y\n    caption = \"Fuente: Estudio realizado en 2002\"         # Nota al pie\n  ) +\n  theme_minimal() +                        # Tema base minimalista\n  theme(\n    axis.text.x = element_text(           # Personalizar texto eje X\n      angle = 45,                         # Rotar texto 45 grados\n      hjust = 1                          # Alinear texto\n    )\n  )\n\n\n\n\n\n\n\n\nExplicación del código:\n\nLa función labs() permite añadir múltiples elementos informativos.\nEl argumento alpha controla la transparencia de las barras.\nLa rotación del texto en el eje X mejora la legibilidad cuando hay muchas categorías.\n\n\n\n14.5.3 Aplicación y personalización de temas\nLos temas en ggplot2 permiten controlar la apariencia general del gráfico, desde el fondo hasta los elementos más pequeños. La personalización puede ser global o específica para cada elemento (Wickham, 2016).\n\n# Ejemplo de personalización avanzada de tema\n# Este gráfico muestra múltiples personalizaciones de elementos visuales\n\nggplot(data = USAC2002,                    # Especificamos la base de datos\n       aes(x = TALLA, y = PESO_lbs)) +     # Variables en ejes X e Y\n  geom_point(color = \"darkblue\",           # Color de los puntos\n             alpha = 0.6) +                # Transparencia de los puntos\n  theme_minimal() +                        # Tema base minimalista\n  theme(\n    # Personalización del título\n    plot.title = element_text(\n      hjust = 0.5,                        # Centrar título\n      size = 16,                          # Tamaño de fuente\n      face = \"bold\"                       # Texto en negrita\n    ),\n    # Personalización del texto de los ejes\n    axis.text = element_text(\n      size = 12,                          # Tamaño de fuente\n      color = \"darkgray\"                  # Color del texto\n    ),\n    # Personalización de títulos de ejes\n    axis.title = element_text(\n      size = 14,                          # Tamaño de fuente\n      face = \"italic\"                     # Texto en cursiva\n    ),\n    # Personalización de la cuadrícula\n    panel.grid.major = element_line(\n      color = \"gray\",                     # Color de líneas principales\n      linetype = \"dashed\"                 # Tipo de línea\n    ),\n    panel.grid.minor = element_blank()    # Eliminar líneas secundarias\n  ) +\n  labs(title = \"Relación entre talla y peso\",\n       x = \"Talla (metros)\",\n       y = \"Peso (libras)\")\n\n\n\n\n\n\n\n\nExplicación del código:\n\ntheme_minimal() establece un tema base limpio y profesional.\nelement_text() permite personalizar todos los elementos de texto.\nelement_line() controla la apariencia de las líneas de la cuadrícula.\nelement_blank() elimina elementos no deseados.\n\nLa personalización adecuada de un gráfico puede mejorar significativamente su capacidad para comunicar información, haciendo que los datos sean más accesibles y comprensibles para diferentes audiencias (Wickham, 2016).",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Visualización de datos con ggplot2</span>"
    ]
  },
  {
    "objectID": "09.3_visualizacion.html#uso-de-facetas-para-comparación-de-grupos",
    "href": "09.3_visualizacion.html#uso-de-facetas-para-comparación-de-grupos",
    "title": "14  Visualización de datos con ggplot2",
    "section": "14.6 Uso de facetas para comparación de grupos",
    "text": "14.6 Uso de facetas para comparación de grupos\nLas facetas en ggplot2 son una herramienta poderosa para dividir un gráfico en varios subgráficos, cada uno correspondiente a un grupo definido por una o más variables categóricas. Esto facilita la comparación visual entre diferentes segmentos de los datos, permitiendo identificar patrones, similitudes o diferencias que podrían pasar desapercibidas en un solo gráfico global (Wickham, 2016).\n\n14.6.1 Facet_wrap y facet_grid: sintaxis y aplicaciones\nggplot2 ofrece dos funciones principales para crear facetas: facet_wrap() y facet_grid(). Cada una tiene una lógica y utilidad específica.\n\n# Ejemplo 1: Uso de facet_wrap para comparar por facultad\n# Este gráfico muestra la relación entre talla y peso, generando un subgráfico para cada facultad\n\nggplot(data = USAC2002, aes(x = TALLA, y = PESO_lbs)) +  # Variables numéricas en los ejes\n  geom_point(color = \"darkgreen\", alpha = 0.6) +         # Puntos verdes con transparencia\n  facet_wrap(~ FACULTAD) +                               # Un panel por cada facultad\n  labs(\n    title = \"Relación entre talla y peso por facultad\",   # Título principal\n    x = \"Talla (metros)\",                                # Etiqueta eje X\n    y = \"Peso (libras)\"                                  # Etiqueta eje Y\n  ) +\n  theme_minimal()                                        # Tema limpio y profesional\n\n\n\n\n\n\n\n\n\nfacet_wrap(~ FACULTAD) divide el gráfico en tantos paneles como valores únicos tenga la variable FACULTAD, permitiendo comparar la relación entre talla y peso en cada facultad de manera individual.\nEs útil cuando se desea comparar un solo criterio de agrupación y se prefiere que los paneles se organicen en una cuadrícula flexible.\n\n\n# Ejemplo 2: Uso de facet_grid para comparar por sexo y jornada\n# Este gráfico muestra la relación entre talla y peso, generando una matriz de subgráficos según sexo y jornada\n\nggplot(data = USAC2002, aes(x = TALLA, y = PESO_lbs)) +  # Variables numéricas en los ejes\n  geom_point(color = \"purple\", alpha = 0.5) +             # Puntos morados con transparencia\n  facet_grid(SEXO ~ JORNADA) +                            # Filas por SEXO, columnas por JORNADA\n  labs(\n    title = \"Relación entre talla y peso por sexo y jornada\",  # Título principal\n    x = \"Talla (metros)\",                                    # Etiqueta eje X\n    y = \"Peso (libras)\"                                      # Etiqueta eje Y\n  ) +\n  theme_minimal()                                            # Tema limpio y profesional\n\n\n\n\n\n\n\n\n\nfacet_grid(SEXO ~ JORNADA) crea una matriz de paneles, donde las filas corresponden a los niveles de SEXO y las columnas a los niveles de JORNADA.\nEs especialmente útil para comparar dos criterios de agrupación de manera cruzada y ordenada.\n\n\n\n14.6.2 Cuadro resumen de diferencias de las funciones face_wrap y face_grid\n\n\n\n\n\n\n\n\n\n\nFunción\nUso principal\nOrganización de paneles\nVariables categóricas involucradas\nEjemplo de sintaxis\n\n\n\n\nfacet_wrap()\nComparar grupos definidos por una sola variable\nCuadrícula flexible (ajuste automático)\nUna variable categórica\nfacet_wrap(~ FACULTAD)\n\n\nfacet_grid()\nComparar grupos definidos por dos variables\nMatriz (filas y columnas fijas)\nDos variables categóricas (filas y columnas)\nfacet_grid(SEXO ~ JORNADA)",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Visualización de datos con ggplot2</span>"
    ]
  },
  {
    "objectID": "09.3_visualizacion.html#comparación-entre-ggplot2-y-el-sistema-gráfico-base-de-r",
    "href": "09.3_visualizacion.html#comparación-entre-ggplot2-y-el-sistema-gráfico-base-de-r",
    "title": "14  Visualización de datos con ggplot2",
    "section": "14.7 Comparación entre ggplot2 y el sistema gráfico base de R",
    "text": "14.7 Comparación entre ggplot2 y el sistema gráfico base de R\nAntes de elegir una herramienta de visualización en R, es importante conocer las diferencias clave entre ggplot2 y el sistema gráfico base. Cada uno tiene ventajas y limitaciones que pueden hacerlos más adecuados según el contexto y los objetivos del análisis (Wickham, 2016).\n\n\n\n\n\n\n\n\nCaracterística\nggplot2\nSistema gráfico base de R\n\n\n\n\nEnfoque\nModular, basado en la gramática de los gráficos\nFunciones específicas para cada gráfico\n\n\nPersonalización\nAvanzada y flexible\nLimitada y menos intuitiva\n\n\nSintaxis\nDeclarativa y estructurada\nImperativa y secuencial\n\n\nIntegración con tidyverse\nTotal\nParcial o nula\n\n\nCurva de aprendizaje\nInicialmente más alta\nMás baja para gráficos simples\n\n\nIdeal para\nInformes profesionales, gráficos complejos\nExploración rápida, gráficos sencillos\n\n\n\nEn resumen, ggplot2 es preferible cuando se requiere personalización, reproducibilidad y presentación profesional, mientras que el sistema gráfico base resulta útil para análisis exploratorios rápidos o cuando se necesita generar gráficos simples con poco código. La elección depende de las necesidades del usuario y del contexto del análisis (Wickham, 2016).",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Visualización de datos con ggplot2</span>"
    ]
  },
  {
    "objectID": "10.1_exportacion.html",
    "href": "10.1_exportacion.html",
    "title": "15  Introducción a la Gestión de Proyectos en R",
    "section": "",
    "text": "15.1 Importancia de la gestión de proyectos en análisis estadístico\nLa gestión de proyectos en R es esencial para mantener el orden, la claridad y la eficiencia en el análisis estadístico de datos, incluso en proyectos sencillos. Adoptar buenas prácticas desde el inicio permite evitar errores, facilita la revisión del trabajo y mejora la comunicación de los resultados, tanto para el propio usuario como para otros que puedan consultar el proyecto en el futuro (Wickham & Grolemund, 2017).\nEn el análisis estadístico, la gestión de proyectos consiste en organizar todos los elementos necesarios para el trabajo en un solo lugar. Esto incluye los datos, los scripts de análisis, los resultados exportados y cualquier archivo adicional relevante. Mantener todos estos archivos juntos en una carpeta específica para cada proyecto ayuda a evitar confusiones, pérdidas de información y errores al ejecutar los análisis.\nLa gestión adecuada de proyectos permite:\nEn proyectos simples, donde el análisis se limita a un solo conjunto de datos y un flujo de trabajo lineal, una carpeta por proyecto es suficiente para mantener el orden y la trazabilidad del trabajo (Wickham & Grolemund, 2017).",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Introducción a la Gestión de Proyectos en R</span>"
    ]
  },
  {
    "objectID": "10.1_exportacion.html#importancia-de-la-gestión-de-proyectos-en-análisis-estadístico",
    "href": "10.1_exportacion.html#importancia-de-la-gestión-de-proyectos-en-análisis-estadístico",
    "title": "15  Introducción a la Gestión de Proyectos en R",
    "section": "",
    "text": "Retomar el trabajo en cualquier momento sin perder el contexto.\nCompartir el proyecto con otras personas de manera sencilla.\nGarantizar que los resultados obtenidos sean reproducibles y verificables.\nEvitar la mezcla de archivos de diferentes análisis, lo que puede llevar a errores o a la utilización de datos incorrectos.",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Introducción a la Gestión de Proyectos en R</span>"
    ]
  },
  {
    "objectID": "10.1_exportacion.html#organización-de-archivos-en-proyectos-de-r",
    "href": "10.1_exportacion.html#organización-de-archivos-en-proyectos-de-r",
    "title": "15  Introducción a la Gestión de Proyectos en R",
    "section": "15.2 Organización de archivos en proyectos de R",
    "text": "15.2 Organización de archivos en proyectos de R\nPara proyectos de análisis estadístico simples, se recomienda crear una carpeta exclusiva para cada proyecto. Dentro de esta carpeta deben almacenarse todos los archivos relacionados con el análisis, lo que incluye:\n\nEl archivo de datos (por ejemplo, un archivo CSV o Excel).\nEl archivo del proyecto de RStudio (con extensión .Rproj), que facilita la gestión y el acceso al proyecto.\nEl script de análisis en R (por ejemplo, analisis.R), donde se escribe y ejecuta el código.\nLos resultados exportados, como gráficos en formato PNG o PDF y tablas en formato CSV o Excel.\n\nEsta organización básica permite que, al abrir la carpeta del proyecto, se tenga acceso inmediato a todos los elementos necesarios para reproducir el análisis o continuar trabajando. Además, facilita la identificación de los archivos y su propósito, evitando la dispersión de información.",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Introducción a la Gestión de Proyectos en R</span>"
    ]
  },
  {
    "objectID": "10.1_exportacion.html#uso-de-rstudio-projects-para-la-gestión-eficiente",
    "href": "10.1_exportacion.html#uso-de-rstudio-projects-para-la-gestión-eficiente",
    "title": "15  Introducción a la Gestión de Proyectos en R",
    "section": "15.3 Uso de RStudio Projects para la gestión eficiente",
    "text": "15.3 Uso de RStudio Projects para la gestión eficiente\nRStudio Projects es una herramienta integrada en el entorno RStudio que permite gestionar proyectos de manera eficiente, incluso en análisis simples. Al crear un proyecto en RStudio, se genera un archivo con extensión .Rproj dentro de la carpeta del proyecto. Este archivo define el directorio de trabajo y centraliza todos los archivos relacionados.\nLas ventajas de utilizar RStudio Projects en proyectos simples incluyen:\n\nFacilita la apertura y cierre del proyecto, restaurando el entorno de trabajo tal como se dejó la última vez.\nAsegura que el directorio de trabajo sea siempre el correcto, evitando errores al cargar o guardar archivos.\nPermite mantener separados los análisis de diferentes proyectos, lo que reduce el riesgo de mezclar datos o resultados.\n\nPara crear un proyecto en RStudio, se debe seleccionar la opción “File &gt; New Project”, elegir “New Directory” y luego “New Project”. Se asigna un nombre y una ubicación a la carpeta del proyecto, y RStudio creará automáticamente el archivo .Rproj en esa carpeta. A partir de ese momento, todos los archivos del análisis deben guardarse en esa misma carpeta para mantener la organización y la reproducibilidad (Wickham & Grolemund, 2017).",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Introducción a la Gestión de Proyectos en R</span>"
    ]
  },
  {
    "objectID": "10.1_exportacion.html#principios-de-reproducibilidad-y-documentación-en-proyectos-de-r",
    "href": "10.1_exportacion.html#principios-de-reproducibilidad-y-documentación-en-proyectos-de-r",
    "title": "15  Introducción a la Gestión de Proyectos en R",
    "section": "15.4 Principios de reproducibilidad y documentación en proyectos de R",
    "text": "15.4 Principios de reproducibilidad y documentación en proyectos de R\nLa reproducibilidad es un principio fundamental en el análisis estadístico. Consiste en la capacidad de repetir un análisis y obtener los mismos resultados, utilizando los mismos datos y scripts. Para lograrlo, es esencial mantener todos los archivos del proyecto juntos y documentar adecuadamente cada paso del proceso.\nEn proyectos simples, la reproducibilidad se puede asegurar mediante:\n\nEl uso de scripts bien comentados, donde se explique cada parte del análisis.\nLa inclusión de los datos originales en la carpeta del proyecto.\nLa exportación de los resultados (gráficos y tablas) en formatos accesibles y guardados en la misma carpeta.\nEl uso del archivo .Rproj para centralizar el entorno de trabajo.\n\nAdemás, es recomendable agregar comentarios en el script de análisis que expliquen el propósito de cada sección del código, los pasos seguidos y cualquier decisión relevante tomada durante el análisis. Esta documentación facilita la revisión, el aprendizaje y la colaboración, incluso en proyectos individuales (Wickham & Grolemund, 2017).",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Introducción a la Gestión de Proyectos en R</span>"
    ]
  },
  {
    "objectID": "10.2_exportacion.html",
    "href": "10.2_exportacion.html",
    "title": "16  Exportación de Resultados de Análisis en R",
    "section": "",
    "text": "16.1 Exportación de gráficos: formatos PNG y PDF\nLa exportación de resultados constituye una etapa fundamental en el análisis estadístico de datos, ya que permite almacenar y compartir los productos del análisis, como gráficos y tablas, para su posterior utilización en informes, presentaciones o análisis adicionales. La correcta elección del formato de exportación garantiza la accesibilidad, reutilización y compatibilidad de los resultados con otras herramientas y plataformas (R Core Team, 2023; Wickham, 2016).\nEn el contexto del análisis estadístico clásico, la exportación de resultados facilita la comunicación de hallazgos y la integración de los mismos en documentos científicos, reportes técnicos o presentaciones. R ofrece funciones específicas para exportar tanto gráficos como tablas de datos en los formatos más utilizados en la práctica profesional y académica, asegurando la calidad y la fidelidad de la información exportada (R Core Team, 2023).\nLa exportación de gráficos es fundamental para documentar visualmente los resultados del análisis. En R, la función ggsave() del paquete ggplot2 permite guardar gráficos en diversos formatos, siendo PNG y PDF los más empleados en la estadística clásica.",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Exportación de Resultados de Análisis en R</span>"
    ]
  },
  {
    "objectID": "10.2_exportacion.html#exportación-de-gráficos-formatos-png-y-pdf",
    "href": "10.2_exportacion.html#exportación-de-gráficos-formatos-png-y-pdf",
    "title": "16  Exportación de Resultados de Análisis en R",
    "section": "",
    "text": "16.1.1 Sintaxis general de ggsave()\nLa función ggsave() del paquete ggplot2 permite guardar gráficos en diferentes formatos. Su sintaxis básica es:\n\nggsave(\n  filename,\n  plot = last_plot(),\n  device = NULL,\n  path = NULL,\n  scale = 1,\n  width = NA,\n  height = NA,\n  units = c(\"in\", \"cm\", \"mm\"),\n  dpi = 300,\n  limitsize = TRUE\n)\n\nA continuación, se describen los argumentos principales de la función:\n\nfilename: Es el nombre del archivo de salida, incluyendo la extensión (por ejemplo, \"grafico.png\" o \"grafico.pdf\"). La extensión determina el formato del archivo.\nplot: Permite especificar el objeto gráfico que se desea guardar. Si se omite, se guarda el último gráfico creado en la sesión de R.\ndevice: Indica el tipo de formato del archivo, como \"png\" o \"pdf\". Si no se especifica, el formato se deduce automáticamente a partir de la extensión del archivo.\npath: Define el directorio donde se guardará el archivo. Si no se proporciona, el archivo se guarda en el directorio de trabajo actual.\nscale: Ajusta el tamaño del gráfico multiplicando las dimensiones especificadas en width y height por el valor de scale. El valor predeterminado es 1 (tamaño original).\nwidth y height: Determinan el ancho y la altura del gráfico en las unidades especificadas por units. Si no se definen, se usan las dimensiones predeterminadas.\nunits: Especifica las unidades de medida para width y height. Puede ser “in” (pulgadas), “cm” (centímetros) o “mm” (milímetros).\ndpi: Define la resolución del gráfico en puntos por pulgada, relevante para formatos rasterizados como PNG. El valor predeterminado es 300, adecuado para impresión.\nlimitsize: Controla si se permite guardar gráficos con dimensiones muy grandes (mayores a 50 pulgadas). Si está en TRUE, se genera un error al intentar guardar gráficos excesivamente grandes.\n\nEsta explicación permite comprender tanto la estructura general de la función como el propósito de cada argumento, facilitando su uso correcto en la exportación de gráficos en R (Wickham, 2016).\n\n\n16.1.2 Ejemplo práctico: creación y exportación de un gráfico\nSupóngase que se ha creado un gráfico de barras con ggplot2:\n\n# Cargar el paquete tidyverse, que incluye ggplot2\nif (!require(\"tidyverse\")) install.packages(\"tidyverse\")\nlibrary(tidyverse)\n\n# Importar una base de datos de ejemplo\ndatos &lt;- read_csv(\"datos_estudiantes.csv\")\n\n# Crear un gráfico de barras\nmi_grafico &lt;- ggplot(data = datos, aes(x = FACULTAD)) +\n  geom_bar(fill = \"steelblue\", color = \"black\", alpha = 0.8) +\n  labs(\n    title = \"Distribución de estudiantes por facultad\",\n    subtitle = \"Datos del estudio de 2002, USAC\",\n    x = \"Facultad\",\n    y = \"Cantidad de estudiantes\",\n    caption = \"Fuente: Estudio realizado en 2002\"\n  ) +\n  theme_minimal()+                  \n  theme(\n    axis.text.x = element_text( \n      angle = 45,                       \n      hjust = 1                       \n    )\n  )\nmi_grafico\n\n\n\n\n\n\n\n\nGuardar el gráfico en formato PNG\n\n# Guardar el gráfico en formato PNG con dimensiones de 8x6 pulgadas\nggsave(\n  filename = \"grafico.png\", # Nombre del archivo de salida\n  plot = mi_grafico,        # Objeto gráfico a guardar\n  width = 8,                # Ancho en pulgadas\n  height = 6,               # Alto en pulgadas\n  dpi = 300                 # Resolución adecuada para impresión\n)\n\nEn este ejemplo, el archivo “grafico.png” se guardará en el directorio de trabajo actual, con alta calidad para impresión o presentaciones digitales.\nGuardar el gráfico en formato PDF\n\n# Guardar el gráfico en formato PDF con dimensiones de 8x6 pulgadas\nggsave(\n  filename = \"grafico.pdf\", # Nombre del archivo de salida\n  plot = mi_grafico,        # Objeto gráfico a guardar\n  width = 8,                # Ancho en pulgadas\n  height = 6                # Alto en pulgadas\n  # No es necesario especificar dpi, ya que PDF es un formato vectorial\n)\n\nEl formato PDF es ideal para informes y publicaciones científicas, ya que permite escalar el gráfico sin pérdida de calidad (Wickham, 2016).",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Exportación de Resultados de Análisis en R</span>"
    ]
  },
  {
    "objectID": "10.2_exportacion.html#exportación-de-tablas-de-datos-formatos-csv-y-excel",
    "href": "10.2_exportacion.html#exportación-de-tablas-de-datos-formatos-csv-y-excel",
    "title": "16  Exportación de Resultados de Análisis en R",
    "section": "16.2 Exportación de tablas de datos: formatos CSV y Excel",
    "text": "16.2 Exportación de tablas de datos: formatos CSV y Excel\nLa exportación de tablas de datos es fundamental para compartir información, documentar resultados o realizar análisis adicionales en otras herramientas. Los formatos más utilizados en la estadística clásica son CSV y Excel, por su compatibilidad y facilidad de uso.\n\n16.2.1 Exportar a CSV con write.csv()\nLa función write.csv() permite exportar un data frame o matriz a un archivo de texto plano en formato CSV (Comma Separated Values). Este formato es ampliamente compatible con programas de hojas de cálculo y software estadístico.\nSintaxis general de write.csv():\n\nwrite.csv(\n  x,           \n  file,        \n  row.names = TRUE,   \n  na = \"NA\",          \n  fileEncoding = \"\",  \n)\n\nExplicación de los argumentos principales:\n\nx: Es el objeto de datos que se desea exportar, generalmente un data frame o una matriz.\nfile: Especifica el nombre del archivo de salida, incluyendo la extensión .csv. El archivo se guardará en el directorio de trabajo actual, a menos que se indique una ruta diferente.\nrow.names: Indica si se deben incluir los nombres de las filas como una columna adicional en el archivo exportado. El valor predeterminado es TRUE, pero es común establecerlo en FALSE para evitar agregar una columna innecesaria.\nna: Define la cadena de texto que se utilizará para representar los valores faltantes (NA) en el archivo exportado. El valor predeterminado es \"NA\".\nfileEncoding: Permite especificar la codificación del archivo de salida, útil para asegurar la compatibilidad con otros sistemas operativos o programas. El valor predeterminado es una cadena vacía, lo que significa que se utiliza la codificación por defecto del sistema.\n\nEjemplo:\n\n# Crear un data frame de ejemplo\nmi_tabla &lt;- data.frame(\n  Nombre = c(\"Ana\", \"Luis\", \"María\"),\n  Edad = c(25, 30, 22),\n  Ciudad = c(\"Madrid\", \"Barcelona\", \"Valencia\")\n)\n\n# Exportar el data frame a un archivo CSV\nwrite.csv(\n  x = mi_tabla,         # Objeto de datos a exportar\n  file = \"resultados.csv\", # Nombre del archivo de salida\n  row.names = FALSE     # No incluir los nombres de las filas \n)\n\nEl archivo “resultados.csv” se guardará en el directorio de trabajo actual y podrá ser abierto en cualquier editor de texto o programa de hojas de cálculo (R Core Team, 2023).\n\n\n16.2.2 Exportar a Excel con write_xlsx() del paquete writexl\nLa función write_xlsx() del paquete writexl permite exportar un data frame o una lista de data frames a un archivo en formato Excel (.xlsx). Este formato es ideal para compartir datos estructurados y aprovechar las funcionalidades avanzadas de hojas de cálculo.\nSintaxis general de write_xlsx()\n\nwrite_xlsx(\n  x,           # Objeto de datos a exportar \n  path,        # Nombre del archivo de salida \n  col_names = TRUE, \n  format_headers = TRUE \n)\n\nExplicación de los argumentos principales:\n\nx: Es el objeto de datos a exportar, que puede ser un data frame o una lista de data frames (en este caso, cada data frame se guardará en una hoja diferente del archivo Excel).\npath: Especifica el nombre del archivo de salida, incluyendo la extensión .xlsx. El archivo se guardará en el directorio de trabajo actual, a menos que se indique una ruta diferente.\ncol_names: Indica si se deben incluir los nombres de las columnas en la primera fila del archivo. El valor predeterminado es TRUE.\nformat_headers: Determina si los encabezados de las columnas deben tener un formato especial (por ejemplo, negrita). El valor predeterminado es TRUE.\n\nEjemplo:\n\n# Instalar y cargar el paquete writexl si no está disponible\nif (!require(\"writexl\")) install.packages(\"writexl\")\n\n# Exportar el data frame a un archivo Excel\nwrite_xlsx(\n  x = mi_tabla,            # Objeto de datos a exportar\n  path = \"resultados.xlsx\" # Nombre del archivo de salida\n  # col_names y format_headers se mantienen en TRUE por defecto\n)\n\nEl archivo “resultados.xlsx” se podrá abrir en Microsoft Excel o software compatible, permitiendo aprovechar las funcionalidades avanzadas de hojas de cálculo (R Core Team, 2023).",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Exportación de Resultados de Análisis en R</span>"
    ]
  },
  {
    "objectID": "10.2_exportacion.html#comparación-de-formatos-y-recomendaciones-de-uso",
    "href": "10.2_exportacion.html#comparación-de-formatos-y-recomendaciones-de-uso",
    "title": "16  Exportación de Resultados de Análisis en R",
    "section": "16.3 Comparación de formatos y recomendaciones de uso",
    "text": "16.3 Comparación de formatos y recomendaciones de uso\nLa elección del formato de exportación depende del objetivo y del público destinatario. A continuación se presenta un cuadro comparativo que distingue entre formatos de imágenes y de datos, resumiendo sus principales características, ventajas y desventajas (Wickham, 2016; R Core Team, 2023):\n\n\n\n\n\n\n\n\n\n\nTipo\nFormato\nUso principal\nVentajas\nDesventajas\n\n\n\n\nImagen\nPNG\nPresentaciones y documentos digitales\nAlta calidad, ampliamente compatible\nNo escalable sin pérdida de calidad\n\n\nImagen\nPDF\nPublicaciones científicas e informes impresos\nEscalable, ideal para impresión\nMenos compatible con editores básicos\n\n\nDatos\nCSV\nAnálisis de datos en herramientas simples\nLigero, multiplataforma, fácil de manipular\nNo admite formatos complejos (fórmulas, etc)\n\n\nDatos\nExcel\nCompartir datos estructurados y análisis\nCompatible con herramientas avanzadas\nRequiere software específico",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Exportación de Resultados de Análisis en R</span>"
    ]
  },
  {
    "objectID": "10.3_exportacion.html",
    "href": "10.3_exportacion.html",
    "title": "17  Uso de Git y GitHub en Proyectos de R",
    "section": "",
    "text": "17.1 Introducción al control de versiones y colaboración\nEl control de versiones y la colaboración en línea son prácticas cada vez más importantes en el análisis estadístico y la ciencia de datos. Git y GitHub permiten gestionar de manera eficiente los cambios en los archivos de un proyecto, compartir el trabajo con otros y mantener un historial completo de todas las modificaciones realizadas. Aunque estas herramientas pueden parecer complejas al principio, su integración con RStudio y su utilidad en proyectos de cualquier tamaño justifican su aprendizaje y uso desde etapas tempranas (Bryan, 2018).\nEl control de versiones es una metodología que permite registrar, organizar y recuperar los cambios realizados en los archivos de un proyecto a lo largo del tiempo. Git es el sistema de control de versiones más utilizado y se integra fácilmente con RStudio, lo que facilita su adopción en proyectos de análisis estadístico.\nVentajas del control de versiones con Git:\nGitHub es una plataforma en línea que permite alojar repositorios de Git, compartir proyectos y colaborar con otros usuarios. Además, ofrece herramientas para la gestión de proyectos, seguimiento de problemas (issues), revisión de código y documentación.\nEn el contexto de proyectos de R, Git y GitHub permiten mantener un registro ordenado de los scripts, datos y resultados, facilitando la colaboración y la reproducibilidad del análisis (Bryan, 2018).",
    "crumbs": [
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Uso de Git y GitHub en Proyectos de R</span>"
    ]
  },
  {
    "objectID": "10.3_exportacion.html#introducción-al-control-de-versiones-y-colaboración",
    "href": "10.3_exportacion.html#introducción-al-control-de-versiones-y-colaboración",
    "title": "17  Uso de Git y GitHub en Proyectos de R",
    "section": "",
    "text": "Permite guardar el historial de cambios, facilitando la recuperación de versiones anteriores de los archivos.\nAyuda a identificar cuándo, cómo y por qué se realizaron modificaciones, lo que mejora la trazabilidad y la transparencia.\nFacilita la colaboración entre varios usuarios, permitiendo que cada uno trabaje en su propia copia del proyecto y luego integre los cambios.\nReduce el riesgo de pérdida de información, ya que los archivos pueden ser restaurados a cualquier estado anterior.\nPermite experimentar con nuevas ideas sin temor a perder el trabajo anterior, gracias a la posibilidad de crear ramas (branches) y fusionarlas posteriormente.",
    "crumbs": [
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Uso de Git y GitHub en Proyectos de R</span>"
    ]
  },
  {
    "objectID": "10.3_exportacion.html#subida-de-un-proyecto-de-r-a-github",
    "href": "10.3_exportacion.html#subida-de-un-proyecto-de-r-a-github",
    "title": "17  Uso de Git y GitHub en Proyectos de R",
    "section": "17.2 Subida de un proyecto de R a GitHub",
    "text": "17.2 Subida de un proyecto de R a GitHub\nSubir un proyecto de R a GitHub implica crear un repositorio en la plataforma y sincronizarlo con la carpeta local del proyecto. Este proceso puede realizarse desde la interfaz de RStudio o utilizando la línea de comandos. A continuación se describe el proceso paso a paso para un usuario principiante:\n1. Crear una cuenta en GitHub\nPara comenzar, es necesario registrarse en https://github.com/ y crear una cuenta personal.\n2. Crear un repositorio nuevo en GitHub\nUna vez dentro de la cuenta, se debe hacer clic en el botón “New repository”. Se recomienda asignar un nombre descriptivo al repositorio (por ejemplo, “analisis_estadistico”) y, opcionalmente, agregar una breve descripción. Es posible elegir si el repositorio será público (visible para todos) o privado (solo accesible para el usuario y quienes él autorice). Al crear el repositorio, se puede dejar vacío, ya que los archivos se agregarán desde la computadora local.\n3. Inicializar Git en la carpeta del proyecto local\nEn la computadora, se debe ubicar la carpeta del proyecto de R (la que contiene el archivo .Rproj, los datos, el script y los resultados exportados).\n\nSi se utiliza RStudio, se puede activar el control de versiones seleccionando “Tools &gt; Project Options &gt; Git/SVN” y eligiendo Git.\nSi se prefiere la terminal, se debe abrir una consola en la carpeta del proyecto y ejecutar el comando:\n\n\ngit init\n\nEsto crea una carpeta oculta llamada .git que permitirá a Git rastrear los cambios en los archivos del proyecto.\n4. Conectar el repositorio local con el remoto en GitHub\n\nPara vincular la carpeta local con el repositorio creado en GitHub, se debe copiar la URL del repositorio (por ejemplo, https://github.com/usuario/analisis_estadistico.git) y ejecutar el siguiente comando en la terminal:\n\ngit remote add origin https://github.com/usuario/analisis_estadistico.git\n\n5. Agregar y confirmar los archivos del proyecto\n\nSe deben agregar los archivos del proyecto al control de versiones con el comando:\n\ngit add .\n\nEl punto (.) indica que se agregarán todos los archivos de la carpeta.\n\nLuego, se realiza el primer “commit” (registro de cambios) con un mensaje descriptivo:\n\ngit commit -m \"Primer commit: subida inicial del proyecto\"\n\n6. Subir los archivos a GitHub\n\nFinalmente, se suben los archivos al repositorio remoto con el comando:\n\ngit push -u origin master\n\nEn algunos casos, la rama principal puede llamarse “main” en lugar de “master”, por lo que el comando sería:\n\ngit push -u origin main\n\nUna vez completados estos pasos, el proyecto estará disponible en GitHub, permitiendo su consulta, descarga y colaboración. Desde la interfaz web de GitHub, se pueden visualizar los archivos, el historial de cambios y la documentación del proyecto (Bryan, 2018).",
    "crumbs": [
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Uso de Git y GitHub en Proyectos de R</span>"
    ]
  },
  {
    "objectID": "10.3_exportacion.html#modificación-y-seguimiento-de-proyectos-en-github",
    "href": "10.3_exportacion.html#modificación-y-seguimiento-de-proyectos-en-github",
    "title": "17  Uso de Git y GitHub en Proyectos de R",
    "section": "17.3 Modificación y seguimiento de proyectos en GitHub",
    "text": "17.3 Modificación y seguimiento de proyectos en GitHub\nUna vez que el proyecto está en GitHub, es posible continuar trabajando en él y mantener un registro detallado de todas las modificaciones. El flujo de trabajo básico consiste en:\n1. Realizar cambios en los archivos del proyecto\nPor ejemplo, modificar el script de análisis, agregar nuevos datos, actualizar los resultados exportados o mejorar la documentación.\n2. Guardar los cambios en Git\nCada vez que se desee registrar un avance, se puede utilizar el punto para indicarle al software que suba todos los archivos que fueron modificados y realizar un commit con un mensaje descriptivo. Por ejemplo:\n\ngit add .\ngit commit -m \"Actualización del script con nuevos gráficos\"\n\nEs importante que el mensaje del commit sea claro y específico, para facilitar la comprensión del historial de cambios.\n3. Sincronizar los cambios con GitHub\n\nPara mantener el repositorio remoto actualizado y respaldado, se utiliza el comando:\n\ngit push\n\nEsto sube los cambios al repositorio en línea, donde pueden ser consultados por otros usuarios o por el propio autor desde cualquier lugar.\n4. Visualizar el historial y colaborar\nGitHub permite revisar el historial completo de commits, comparar versiones de archivos y, en proyectos colaborativos, gestionar solicitudes de cambio (pull requests) y comentarios. Esto facilita la colaboración y la revisión del trabajo en equipo.\nEl uso regular de Git y GitHub asegura que el proyecto esté siempre respaldado, documentado y listo para ser compartido o retomado en cualquier momento (Bryan, 2018).",
    "crumbs": [
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Uso de Git y GitHub en Proyectos de R</span>"
    ]
  },
  {
    "objectID": "11.1_M_apoyo.html",
    "href": "11.1_M_apoyo.html",
    "title": "18  Material de apoyo",
    "section": "",
    "text": "Tutorial en YouTube “Cómo instalar R y RStudio en menos de 2 minutos - 2024”. Elaborado por Herbert Lizama.\nR para ciencia de datos por Handley Wickham & Garrett Grolemund\nRegresión lineal usando R.",
    "crumbs": [
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Material de apoyo</span>"
    ]
  },
  {
    "objectID": "estadistica_descriptiva.html",
    "href": "estadistica_descriptiva.html",
    "title": "20  Estadística descriptiva usando funciones en R",
    "section": "",
    "text": "20.1 Medidas principales en estadística descriptiva\nLa estadística descriptiva es una rama esencial de la estadística que se ocupa de resumir y describir las características principales de un conjunto de datos. Su propósito es proporcionar una visión clara y comprensible de los datos, permitiendo identificar patrones, tendencias y comportamientos generales sin realizar inferencias o predicciones. Este tipo de análisis es el primer paso en cualquier estudio estadístico, ya que organiza y presenta la información de manera que sea fácil de interpretar.\nEn R, la estadística descriptiva se puede realizar de manera eficiente gracias a una amplia variedad de herramientas y funciones predefinidas, así como paquetes especializados que amplían las capacidades del análisis. Estas herramientas permiten calcular medidas clave que se agrupan en tres categorías principales: medidas de tendencia central, medidas de dispersión y medidas de forma.",
    "crumbs": [
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Estadística descriptiva usando funciones en R</span>"
    ]
  },
  {
    "objectID": "estadistica_descriptiva.html#medidas-principales-en-estadística-descriptiva",
    "href": "estadistica_descriptiva.html#medidas-principales-en-estadística-descriptiva",
    "title": "20  Estadística descriptiva usando funciones en R",
    "section": "",
    "text": "20.1.1 Medidas de tendencia central\nLas medidas de tendencia central describen el valor típico o central de un conjunto de datos. Estas medidas son fundamentales para resumir los datos en un solo valor representativo.\nMedia aritmética: Es el promedio aritmético de los datos. Se calcula sumando todos los valores y dividiendo entre el número total de observaciones. Es sensible a valores extremos (outliers).\nFórmula:\n\n\n\n\n\nEjemplo en R:\n\ndatos &lt;- c(10, 20, 30, 40, 50)\nmedia &lt;- mean(datos)\nprint(media)  # Resultado: \n\n[1] 30\n\n\nMediana: Es el valor que divide el conjunto de datos en dos partes iguales, de modo que el 50% de los valores son menores o iguales a la mediana y el otro 50% son mayores o iguales. Es menos sensible a valores extremos que la media.\nEjemplo en R:\n\nmediana &lt;- median(datos)\nprint(mediana)  # Resultado: \n\n[1] 30\n\n\nModa: Es el valor o los valores que ocurren con mayor frecuencia en un conjunto de datos. En R base, no existe una función predefinida para calcular la moda, pero se puede implementar fácilmente.\nEjemplo de función para calcular la moda:\n\nmoda_ej &lt;- function(x) {\n  tabla &lt;- table(x)\n  moda &lt;- names(tabla[tabla == max(tabla)])\n  return(moda)\n}\ndatos_moda &lt;- c(10, 20, 20, 30, 40)\nprint(moda_ej(datos_moda))  # Resultado: \n\n[1] \"20\"\n\n\n\n\n20.1.2 Medidas de dispersión\nLas medidas de dispersión describen la variabilidad o el grado de dispersión de los datos en torno a la media. Estas medidas son esenciales para entender la distribución de los datos.\nVarianza: Mide la dispersión de los datos respecto a la media. Es el promedio de las diferencias al cuadrado entre cada valor y la media. Una varianza alta indica que los datos están muy dispersos.\nFórmula de la varianza muestral:\n\n\n\n\n\n\nvarianza &lt;- var(datos)\nprint(varianza)  # Resultado: \n\n[1] 250\n\n\nDesviación estándar: Es la raíz cuadrada de la varianza. Proporciona una medida de dispersión en las mismas unidades que los datos originales.\nFórmula:\n\n\n\n\n\nEjemplo en R:\n\ndesviacion &lt;- sd(datos)\nprint(desviacion)  # Resultado:\n\n[1] 15.81139\n\n\nRango: Es la diferencia entre el valor máximo y el valor mínimo de los datos. Es una medida simple pero útil para entender la amplitud de los datos.\nEjemplo en R:\n\nrango &lt;- max(datos)-min(datos)\nprint(rango)  # Resultado: \n\n[1] 40\n\n\nRango intercuartílico (IQR): Es la diferencia entre el tercer cuartil (Q3) y el primer cuartil (Q1). Representa la dispersión de la mitad central de los datos y es menos sensible a valores extremos.\nFórmula:\n\n\n\n\n\nEjemplo en R:\n\niqr &lt;- IQR(datos)\nprint(iqr)  # Resultado: \n\n[1] 20\n\n\n\n\n20.1.3 Medidas de forma\nLas medidas de forma describen la distribución de los datos en términos de su simetría y concentración en torno a la media.\nAsimetría (skewness): Mide el grado de simetría de la distribución de los datos. Una asimetría positiva indica que la cola derecha es más larga, mientras que una asimetría negativa indica que la cola izquierda es más larga.\nGuía gráfica para interpretar asimetría:\n\n\n\n\n\nFórmula:\n\n\n\n\n\nEjemplo en R (usando el paquete psych):\n\n# Instalación y carga del paquete psych\nif (!require(\"psych\")) install.packages(\"psych\")\n\n# Análisis de asimetria\ndatos &lt;- c(10, 20, 30, 40, 50)\nasimetria &lt;- skew(datos)\nprint(asimetria)  # Resultado: 0 (distribución simétrica)\n\n[1] 0\n\n\nCurtosis (kurtosis): Mide la concentración de los datos en torno a la media. Una curtosis alta indica una distribución con colas más pesadas (leptocúrtica), mientras que una curtosis baja indica colas más ligeras (platicúrtica).\nGuía gráfica para interpretar curtosis:\n\n\n\n\n\nFórmula:\n\n\n\n\n\nEjemplo en R (usando el paquete psych):\n\ncurtosis &lt;- kurtosi(datos)\nprint(curtosis)  # Resultado: -1.912 (distribución platicúrtica)\n\n[1] -1.912",
    "crumbs": [
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Estadística descriptiva usando funciones en R</span>"
    ]
  },
  {
    "objectID": "estadistica_descriptiva.html#base-de-datos-para-los-ejemplos",
    "href": "estadistica_descriptiva.html#base-de-datos-para-los-ejemplos",
    "title": "20  Estadística descriptiva usando funciones en R",
    "section": "20.2 Base de datos para los ejemplos",
    "text": "20.2 Base de datos para los ejemplos\nEn 2002, se llevó a cabo un estudio en la Universidad de San Carlos de Guatemala, en el que se recopilaron datos de 460 estudiantes de diversas facultades, generando una base de datos que incluye una amplia variedad de variables como: FACULTAD, EDAD, SEXO, EST_CIVIL, PESO_lbs, TALLA, entre otras. Esta base de datos, disponible para su descarga en formato CSV, se utilizará a lo largo de esta sección del manual para ilustrar diferentes métodos de análisis descriptivo de datos, adaptando las herramientas y conceptos desarrollados a las características de las variables incluidas. Para seguir los ejemplos prácticos, se recomienda que el usuario descargue el archivo y lo guarde en la carpeta correspondiente al proyecto en curso.\n\n20.2.1 Preparación del área de trabajo\nAntes de comenzar con el análisis, es necesario preparar el entorno de trabajo instalando y cargando los paquetes necesarios, estableciendo el directorio de trabajo y revisando la estructura de los datos.\n\n# Instalación y carga de paquetes  \n # Incluye ggplot2, dplyr, tidyr\nif (!require(\"tidyverse\")) install.packages(\"tidyverse\")\n\n # Exportación a Excel\nif (!require(\"writexl\")) install.packages(\"writexl\")  \n\n # Realiza analisis de estaística descriptiva completos\nif (!require(\"psych\")) install.packages(\"psych\")\n\n # Se utiliza para establecer el directorio de trabajo \nif (!require(\"rstudioapi\")) install.packages(\"rstudioapi\")\n\n\n\n20.2.2 Establecer directorio de trabajo\nEs importante asegurarse de que el archivo de datos esté en el directorio de trabajo correcto. Esto se puede hacer con el siguiente código una vez ya se ha guardado el script:\n\n# Establecer y verificar directorio de trabajo\nsetwd(dirname(rstudioapi::getActiveDocumentContext()$path))\ngetwd()\n\n\n\n20.2.3 Importar la base de datos\nUna vez establecido el directorio de trabajo, se puede importar la base de datos en formato CSV:\n\n# Importar la base de datos\nestudiantes&lt;- read_csv(\"datos_estudiantes.csv\")\n\n\n\n20.2.4 Revisar de la estructura de los datos\nEs fundamental revisar la estructura de los datos para entender el tipo de variables y su formato:\n\n# Revisar la estructura de los datos\nsapply(estudiantes, class)\n\n# Convertir todos los nombres de las columnas a minúsculas\nnames(estudiantes)&lt;- tolower(names(estudiantes))\n\n# Tener todas las variables en minúsculas facilita su manipulación\n\n# Revisar los valores de las variables categoricas \ncategoricas&lt;-list(facultad = c(unique(estudiantes$facultad)),\n           sexo = c(unique(estudiantes$sexo)), \n           est_civil = c(unique(estudiantes$est_civil)),\n           trabaja = c(unique(estudiantes$trabaja)),\n           jornada = c(unique(estudiantes$jornada)),\n           fuma = c(unique(estudiantes$fuma)),\n           alcohol = c(unique(estudiantes$alcohol)))\n\n\n\n20.2.5 Limpieza de la base de datos\nAntes de realizar el análisis, es necesario limpiar los datos para corregir valores inconsistentes y asegurarse de que las variables estén en el formato adecuado:\n\n# Corregir los valores incorrectos de la variable \"fuma\"\nestudiantes$fuma &lt;- ifelse(tolower(estudiantes$fuma) == \"sí\",\n                           1, estudiantes$fuma)\nunique(estudiantes$fuma)\n\n[1] \"2\" \"1\"\n\n# Establecer como varibales tipo factor a las variables categoricas\nestudiantes &lt;- estudiantes %&gt;%\n  mutate(across(\n    c(facultad, sexo, est_civil, trabaja, jornada, fuma, alcohol), \n    as.factor))",
    "crumbs": [
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Estadística descriptiva usando funciones en R</span>"
    ]
  },
  {
    "objectID": "estadistica_descriptiva.html#funciones-por-defecto-en-r-para-estadística-descriptiva",
    "href": "estadistica_descriptiva.html#funciones-por-defecto-en-r-para-estadística-descriptiva",
    "title": "20  Estadística descriptiva usando funciones en R",
    "section": "20.3 Funciones por defecto en R para estadística descriptiva",
    "text": "20.3 Funciones por defecto en R para estadística descriptiva\nR base proporciona varias funciones útiles para realizar análisis descriptivos básicos. A continuación, se presentan ejemplos utilizando la base de datos de estudiantes.\n\n20.3.1 Medidas de tendencia central\nLas medidas de tendencia central describen el valor típico o central de un conjunto de datos.\nMedia: Promedio de los valores.\nMediana: Valor que divide los datos en dos partes iguales.\nModa: Valor más frecuente (no existe una función por defecto en R para calcular la moda).\n\n# Calcular medidas de tendencia central para la variable \"edad\"\nmedia_edad &lt;- mean(estudiantes$edad, na.rm = TRUE)\nmediana_edad &lt;- median(estudiantes$edad, na.rm = TRUE)\n\n# Resultados\nprint(paste(\"Media:\", media_edad))\n\n[1] \"Media: 24.0195652173913\"\n\nprint(paste(\"Mediana:\", mediana_edad))\n\n[1] \"Mediana: 22\"\n\n\n\n\n20.3.2 Medidas de dispersión\nLas medidas de dispersión describen la variabilidad de los datos.\nVarianza: Dispersión respecto a la media.\nDesviación estándar: Raíz cuadrada de la varianza.\nRango: Diferencia entre el valor máximo y mínimo.\nRango intercuartílico (IQR): Diferencia entre el tercer y primer cuartil.\n\n# Calcular medidas de dispersión para la variable \"peso_lbs\"\nvarianza_peso &lt;- var(estudiantes$peso_lbs, na.rm = TRUE)\ndesviacion_peso &lt;- sd(estudiantes$peso_lbs, na.rm = TRUE)\nrango_peso &lt;- max(estudiantes$peso_lbs)-min(estudiantes$peso_lbs)\niqr_peso &lt;- IQR(estudiantes$peso_lbs, na.rm = TRUE)\n\n# Resultados\nprint(paste(\"Varianza:\", varianza_peso))\n\n[1] \"Varianza: 872.415330870512\"\n\nprint(paste(\"Desviación estándar:\", desviacion_peso))\n\n[1] \"Desviación estándar: 29.5366777222915\"\n\nprint(paste(\"Rango:\", paste(rango_peso)))\n\n[1] \"Rango: 170\"\n\nprint(paste(\"IQR:\", iqr_peso))\n\n[1] \"IQR: 40\"\n\n\n\n\n20.3.3 Medidas de forma\nLas medidas de forma describen la distribución de los datos en términos de simetría y concentración.\nAsimetría: Grado de simetría de la distribución.\nCurtosis: Concentración de los datos en torno a la media.\nLa asimetría y curtosis no se pueden calcular con la funciones base de R para ello se debe emplear el paquete psych, con este las medidas de forma se calculan fácilmente:\n\n# Calcular asimetría y curtosis para la variable \"talla\"\nasimetria_talla &lt;- skew(estudiantes$talla, na.rm = TRUE)\ncurtosis_talla &lt;- kurtosi(estudiantes$talla, na.rm = TRUE)\n\n# Resultados\nprint(paste(\"Asimetría:\", asimetria_talla))\n\n[1] \"Asimetría: 0.0362232638780007\"\n\nprint(paste(\"Curtosis:\", curtosis_talla))\n\n[1] \"Curtosis: -0.177190677008652\"\n\n\n\n\n20.3.4 Resumen general con summary()\nLa función summary() proporciona un resumen estadístico básico para variables numéricas y categóricas:\n\n# Resumen general de la variable talla\nresumen_general &lt;- summary(estudiantes$talla)\nprint(resumen_general)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.280   1.570   1.630   1.639   1.700   1.900",
    "crumbs": [
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Estadística descriptiva usando funciones en R</span>"
    ]
  },
  {
    "objectID": "estadistica_descriptiva.html#paquetes-especializados-para-estadística-descriptiva-el-paquete-psych",
    "href": "estadistica_descriptiva.html#paquetes-especializados-para-estadística-descriptiva-el-paquete-psych",
    "title": "20  Estadística descriptiva usando funciones en R",
    "section": "20.4 Paquetes especializados para estadística descriptiva (el paquete psych)",
    "text": "20.4 Paquetes especializados para estadística descriptiva (el paquete psych)\nEl paquete psych es una herramienta poderosa y versátil para realizar análisis estadísticos descriptivos avanzados en R. Este paquete es especialmente útil cuando se trabaja con variables categóricas y numéricas simultáneamente, ya que permite calcular estadísticas detalladas, realizar análisis por grupos y obtener medidas de forma como asimetría y curtosis. Además, incluye opciones para calcular errores estándar e intervalos de confianza, lo que lo convierte en una excelente opción para análisis más completos.\n\n20.4.1 Instalación y carga del paquete\n\n# Instalación y carga del paquete\nif (!require(\"psych\")) install.packages(\"psych\")\n\n\n\n20.4.2 Análisis descriptivo general\nA continuación, se utilizará la base de datos de estudiantes para realizar un análisis descriptivo detallado. Este análisis incluirá medidas de tendencia central, dispersión y forma.\nLa función describe() del paquete psych permite calcular estadísticas descriptivas detalladas para variables numéricas. Estas estadísticas incluyen: Media, Desviación estándar, Mediana, Rango, Asimetría, Curtosis, Errores estándar.\n\n# Análisis descriptivo general para variables numéricas\nresultado_general &lt;- describe(estudiantes[, c(\"edad\", \"peso_lbs\", \"talla\")])\n\n# Mostrar resultados\nprint(resultado_general)\n\n         vars   n   mean    sd median trimmed   mad   min   max  range skew\nedad        1 460  24.02  5.74  22.00   22.99  2.97 17.00  55.0  38.00 1.94\npeso_lbs    2 460 139.44 29.54 134.00  137.46 29.65 79.00 249.0 170.00 0.68\ntalla       3 460   1.64  0.09   1.63    1.64  0.10  1.28   1.9   0.62 0.04\n         kurtosis   se\nedad         4.39 0.27\npeso_lbs     0.42 1.38\ntalla       -0.18 0.00\n\n\nSalida esperada: El resultado incluye un resumen detallado de cada variable numérica, con estadísticas como la media, desviación estándar, asimetría y curtosis.\n\n\n20.4.3 Análisis descriptivo categorizado\nLa función describeBy() permite realizar un análisis descriptivo agrupado por una o más variables categóricas. Esto es útil para comparar estadísticas entre diferentes grupos.\n\n# Análisis descriptivo agrupado por sexo y trabaja\nresultado_agrupado &lt;- describeBy(\n  estudiantes[, c(\"edad\", \"peso_lbs\", \"talla\")], \n  group = list(estudiantes$sexo, estudiantes$trabaja)\n)\n\n# Mostrar resultados\nprint(resultado_agrupado)\n\n\n Descriptive statistics by group \n: F\n: 1\n         vars  n   mean    sd median trimmed   mad   min    max  range  skew\nedad        1 76  26.04  5.69  25.00   25.37  5.93 18.00  42.00  24.00  0.91\npeso_lbs    2 76 126.67 25.32 122.50  124.05 20.76 79.00 199.00 120.00  0.97\ntalla       3 76   1.57  0.08   1.57    1.57  0.07  1.28   1.75   0.47 -0.42\n         kurtosis   se\nedad         0.14 0.65\npeso_lbs     0.86 2.90\ntalla        1.73 0.01\n------------------------------------------------------------ \n: M\n: 1\n         vars   n   mean    sd median trimmed   mad    min    max  range  skew\nedad        1 105  27.58  7.49   25.0   26.59  5.93  18.00  55.00  37.00  1.26\npeso_lbs    2 105 156.31 26.94  152.0  154.75 25.20 102.00 238.00 136.00  0.61\ntalla       3 105   1.70  0.07    1.7    1.70  0.07   1.49   1.85   0.36 -0.09\n         kurtosis   se\nedad         1.34 0.73\npeso_lbs     0.41 2.63\ntalla       -0.15 0.01\n------------------------------------------------------------ \n: F\n: 2\n         vars   n   mean    sd median trimmed   mad  min    max  range skew\nedad        1 154  22.57  4.51  21.00   21.77  2.97 17.0  44.00  27.00 2.53\npeso_lbs    2 154 125.66 24.56 120.00  123.27 17.79 84.0 227.00 143.00 1.07\ntalla       3 154   1.59  0.07   1.58    1.58  0.06  1.4   1.78   0.38 0.44\n         kurtosis   se\nedad         7.79 0.36\npeso_lbs     1.37 1.98\ntalla       -0.07 0.01\n------------------------------------------------------------ \n: M\n: 2\n         vars   n   mean    sd median trimmed   mad   min   max  range skew\nedad        1 125  21.58  2.87   21.0   21.24  1.48 17.00  34.0  17.00 1.66\npeso_lbs    2 125 149.99 28.27  147.0  148.49 26.69 88.00 249.0 161.00 0.64\ntalla       3 125   1.69  0.08    1.7    1.69  0.07  1.52   1.9   0.38 0.10\n         kurtosis   se\nedad         4.34 0.26\npeso_lbs     0.92 2.53\ntalla       -0.05 0.01\n\n\nNota importante: Cuando se utiliza describeBy(), el paquete psych genera una tabla separada para cada combinación de las variables categóricas. Esto puede ser útil para análisis simples, pero puede volverse limitante en casos donde se necesite consolidar los resultados en un solo dataframe o realizar análisis más complejos.\n\n\n20.4.4 Exportación de resultados\nLos resultados del análisis descriptivo pueden exportarse fácilmente a un archivo Excel para su revisión o presentación:\n\n# Exportar resultados agrupados a Excel\nwrite_xlsx(resultado_agrupado, \"analisis_descriptivo_psych.xlsx\")\n\n\n\n20.4.5 Ventajas del paquete psych\nEl paquete psych ofrece varias ventajas para el análisis descriptivo:\n\nEstadísticas más detalladas: Incluye medidas avanzadas como asimetría, curtosis, errores estándar e intervalos de confianza.\nAnálisis por grupos: Permite calcular estadísticas descriptivas para diferentes combinaciones de variables categóricas.\nFlexibilidad: Facilita la categorización de variables numéricas en rangos personalizados.\nExportación de resultados: Los resultados pueden exportarse fácilmente a formatos como Excel para su análisis posterior.\n\n\n\n20.4.6 Limitaciones del paquete psych\nAunque el paquete psych es muy útil, presenta algunas limitaciones:\n\nResultados separados por combinación de categorías: La función describeBy() genera una tabla separada para cada combinación de las variables categóricas, lo que puede dificultar la consolidación de los resultados en un solo archivo o dataframe.\nFalta de personalización: No permite agregar estadísticas personalizadas, como percentiles específicos o medidas adicionales que no estén incluidas en las funciones predefinidas.\nManejo de valores faltantes: Aunque maneja valores faltantes de manera básica, no ofrece opciones avanzadas para imputación o análisis detallado de datos incompletos.\nExportación limitada: Los resultados no están listos para exportarse directamente en un formato tabular consolidado, lo que requiere pasos adicionales para su preparación.",
    "crumbs": [
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Estadística descriptiva usando funciones en R</span>"
    ]
  },
  {
    "objectID": "estadistica_descriptiva.html#función-personalizada-para-análisis-descriptivo-completo",
    "href": "estadistica_descriptiva.html#función-personalizada-para-análisis-descriptivo-completo",
    "title": "20  Estadística descriptiva usando funciones en R",
    "section": "20.5 Función personalizada para análisis descriptivo completo",
    "text": "20.5 Función personalizada para análisis descriptivo completo\nPara superar las limitaciones del paquete psych, se puede utilizar una función personalizada que ofrezca mayor flexibilidad y personalización. A continuación, se presenta una solución que incluye funciones auxiliares para calcular medidas avanzadas como la moda, asimetría y curtosis.\n\n20.5.1 Establecer funciones auxiliares\n\n20.5.1.1 Moda\n\n# Función de la moda\nmoda &lt;- function(x) {\n  # Eliminar valores NA\n  x &lt;- na.omit(x)\n  \n  # Verificar si el vector está vacío\n  if (length(x) == 0) return(NA_character_)\n  \n  # Calcular la frecuencia de cada valor\n  tabla &lt;- table(x)\n  \n  # Identificar el/los valores con mayor frecuencia\n  max_frecuencia &lt;- max(tabla)\n  modas &lt;- names(tabla[tabla == max_frecuencia])\n  \n  # Verificar si todos los valores son únicos (sin moda)\n  if (max_frecuencia == 1) return(NA_character_)\n  \n  # Retornar la moda como un string separado por comas\n  return(paste(modas, collapse = \", \"))\n}\n\n\n\n20.5.1.2 Asimetría\n\n# Función Asimentría\ncalcular_asimetria &lt;- function(x) {\n  # Eliminar valores NA\n  x &lt;- na.omit(x)\n  \n  # Verificar que haya suficientes datos\n  if (length(x) &lt; 3) return(NA_real_)\n  \n  # Calcular media y desviación estándar\n  m &lt;- mean(x)\n  s &lt;- sd(x)\n  \n  # Manejar el caso de desviación estándar cero\n  if (s == 0) return(0)\n  \n  # Calcular asimetría\n  asimetria &lt;- sum((x - m)^3) / (length(x) * s^3)\n  return(asimetria)\n}\n\n\n\n20.5.1.3 Curtosis\n\n# Función Curtosis \ncalcular_curtosis &lt;- function(x) {\n  # Eliminar valores NA\n  x &lt;- na.omit(x)\n  \n  # Verificar que haya suficientes datos\n  if (length(x) &lt; 4) return(NA_real_)\n  \n  # Calcular media y desviación estándar\n  m &lt;- mean(x)\n  s &lt;- sd(x)\n  \n  # Manejar el caso de desviación estándar cero\n  if (s == 0) return(0)\n  \n  # Calcular curtosis\n  curtosis &lt;- sum((x - m)^4) / (length(x) * s^4) - 3\n  return(curtosis)\n}\n\n\n\n\n20.5.2 Función principal: análisis por categorías\nLa función principal realiza el análisis descriptivo agrupando los datos según las variables categóricas especificadas. Calcula estadísticas clave como la media, mediana, moda, desviación estándar, varianza, rango, cuartiles, asimetría y curtosis.\n\n# Función Análisis por Categoría\nanalisis_por_categoria &lt;- function(datos, \n                                   columna_numerica,\n                                   columnas_categoricas) {\n  datos %&gt;%\n    group_by(across(all_of(columnas_categoricas))) %&gt;%\n    summarise(\n      Variable = columna_numerica,\n      N_validos = sum(!is.na(.data[[columna_numerica]])),\n      N_missing = sum(is.na(.data[[columna_numerica]])),\n      Media = mean(.data[[columna_numerica]], na.rm = TRUE),\n      Mediana = median(.data[[columna_numerica]], na.rm = TRUE),\n      Moda = moda(.data[[columna_numerica]]),\n      Desviacion_estandar = sd(.data[[columna_numerica]], na.rm = TRUE),\n      Varianza = var(.data[[columna_numerica]], na.rm = TRUE),\n      Rango_min = min(.data[[columna_numerica]], na.rm = TRUE),\n      Rango_max = max(.data[[columna_numerica]], na.rm = TRUE),\n      Rango = Rango_max - Rango_min,\n      IQR = IQR(.data[[columna_numerica]], na.rm = TRUE),\n      Q1 = quantile(.data[[columna_numerica]], probs = 0.25, na.rm = TRUE),\n      Q2 = quantile(.data[[columna_numerica]], probs = 0.50, na.rm = TRUE),\n      Q3 = quantile(.data[[columna_numerica]], probs = 0.75, na.rm = TRUE),\n      Asimetria = calcular_asimetria(.data[[columna_numerica]]),\n      Curtosis = calcular_curtosis(.data[[columna_numerica]]),\n      .groups = 'drop'\n    )\n}\n\n\n\n20.5.3 Función para análisis de múltiples variables numéricas\nPara analizar varias columnas numéricas simultáneamente, se puede usar la siguiente función, que aplica analisis_por_categoria a cada columna numérica especificada:\n\n# Función para anlisar multiples variables numericas simultaneamente \nanalisis_multiple &lt;- function(datos, \n                              columnas_numericas,\n                              columnas_categoricas) {\n  resultados &lt;- list()\n  for (col in columnas_numericas) {\n    resultados[[col]] &lt;- analisis_por_categoria(\n      datos = datos,\n      columna_numerica = col,\n      columnas_categoricas = columnas_categoricas\n    )\n  }\n  bind_rows(resultados)  # Combina todos los resultados en un dataframe\n}\n\n\n\n20.5.4 Ejemplo de uso\nPara ilustrar el uso de la función personalizada, se realizará un análisis descriptivo completo utilizando la base de datos de estudiantes de la Universidad de San Carlos de Guatemala. Este ejemplo mostrará cómo analizar múltiples variables numéricas categorizadas por diferentes variables cualitativas.\n\n20.5.4.1 Preparación del análisis\nAntes de ejecutar el análisis, es necesario definir las columnas numéricas y categóricas que se incluirán en el estudio. Las columnas numéricas representan las variables cuantitativas que se analizarán, mientras que las columnas categóricas se utilizarán para agrupar los datos.\n\n# Definir las columnas numéricas y categóricas\n# Variables cuantitativas\ncolumnas_numericas &lt;- c(\"talla\", \"peso_lbs\", \"edad\")  \n\n# Variables cualitativas\ncolumnas_categoricas &lt;- c(\"sexo\", \"trabaja\")         \n\nA continuación, se ejecuta la función analisis_multiple, que aplica el análisis descriptivo a cada variable numérica, agrupando los resultados según las categorías especificadas.\n\n# Ejecutar el análisis descriptivo completo\nresultados_finales &lt;- analisis_multiple(\n  datos = estudiantes,\n  columnas_numericas = columnas_numericas,\n  columnas_categoricas = columnas_categoricas\n)\n\n\n\n20.5.4.2 Visualización de resultados\nLos resultados del análisis se almacenan en un objeto llamado resultados_finales, que contiene un resumen estadístico detallado para cada combinación de las variables categóricas. Este resumen incluye medidas como la media, mediana, moda, desviación estándar, varianza, rango, asimetría y curtosis, entre otras.\nPara visualizar los resultados directamente en la consola, se utiliza la función print(). El resultado es una tabla organizada que muestra las estadísticas descriptivas para cada combinación de las categorías sexo y trabaja.\n\n# Mostrar resultados\nprint(resultados_finales)\n\n# A tibble: 12 × 19\n   sexo  trabaja Variable N_validos N_missing  Media Mediana Moda \n   &lt;fct&gt; &lt;fct&gt;   &lt;chr&gt;        &lt;int&gt;     &lt;int&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;\n 1 F     1       talla           76         0   1.57    1.57 1.57 \n 2 F     2       talla          154         0   1.59    1.58 1.6  \n 3 M     1       talla          105         0   1.70    1.7  1.7  \n 4 M     2       talla          125         0   1.69    1.7  1.7  \n 5 F     1       peso_lbs        76         0 127.    122.   130  \n 6 F     2       peso_lbs       154         0 126.    120    114  \n 7 M     1       peso_lbs       105         0 156.    152    150  \n 8 M     2       peso_lbs       125         0 150.    147    150  \n 9 F     1       edad            76         0  26.0    25    21   \n10 F     2       edad           154         0  22.6    21    21   \n11 M     1       edad           105         0  27.6    25    22   \n12 M     2       edad           125         0  21.6    21    21   \n# ℹ 11 more variables: Desviacion_estandar &lt;dbl&gt;, Varianza &lt;dbl&gt;,\n#   Rango_min &lt;dbl&gt;, Rango_max &lt;dbl&gt;, Rango &lt;dbl&gt;, IQR &lt;dbl&gt;, Q1 &lt;dbl&gt;,\n#   Q2 &lt;dbl&gt;, Q3 &lt;dbl&gt;, Asimetria &lt;dbl&gt;, Curtosis &lt;dbl&gt;\n\n\nAdemás de visualizar los resultados en la consola, es posible exportarlos a un archivo Excel para facilitar su revisión o presentación:\n\n# Exportar resultados a Excel para mejor visualización\nwrite_xlsx(resultados_finales, \"analisis_descriptivo_estudiantes.xlsx\")\n\nEste ejemplo demuestra cómo utilizar la función personalizada para realizar un análisis descriptivo completo y categorizado. La tabla resultante proporciona una visión detallada de las características de las variables numéricas, agrupadas por categorías cualitativas. Además, la posibilidad de exportar los resultados a Excel permite compartir y analizar los datos de manera más eficiente.",
    "crumbs": [
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Estadística descriptiva usando funciones en R</span>"
    ]
  },
  {
    "objectID": "estadistica_descriptiva.html#resumen-comparativo-funciones-base-de-r-paquete-psych-y-función-personalizada",
    "href": "estadistica_descriptiva.html#resumen-comparativo-funciones-base-de-r-paquete-psych-y-función-personalizada",
    "title": "20  Estadística descriptiva usando funciones en R",
    "section": "20.6 Resumen Comparativo: Funciones Base de R, Paquete psych y Función Personalizada",
    "text": "20.6 Resumen Comparativo: Funciones Base de R, Paquete psych y Función Personalizada\nA continuación, se presenta una comparación entre el paquete psych y la función personalizada para realizar análisis descriptivos, destacando las fortalezas y limitaciones de cada enfoque. Esta comparación permite identificar cuál es la mejor opción según las necesidades específicas del análisis.\n\n\n\n\n\n\n\n\n\nCaracterística\nFunciones Base de R\nPaquete psych\nFunción Personalizada\n\n\n\n\nEstadísticas avanzadas\nCalcula medidas básicas como media, mediana, desviación estándar, varianza y rango.\nIncluye medidas como asimetría y curtosis.\nIncluye asimetría, curtosis, moda y más estadísticas avanzadas.\n\n\nAnálisis por grupos\nRequiere pasos adicionales para agrupar y calcular estadísticas por categorías.\nGenera tablas separadas para cada combinación de categorías, lo que puede dificultar la consolidación.\nConsolida todos los resultados en un único dataframe, facilitando su manejo y análisis.\n\n\nFlexibilidad\nLimitada a las funciones predefinidas, sin opciones para personalización avanzada.\nLimitada a las funciones predefinidas del paquete.\nTotalmente personalizable, permitiendo agregar o modificar estadísticas según las necesidades.\n\n\nExportación\nRequiere pasos adicionales para preparar los resultados antes de exportarlos.\nRequiere pasos adicionales para preparar los resultados antes de exportarlos.\nLos resultados están listos para exportarse directamente en un formato tabular.\n\n\nFacilidad de uso\nMuy fácil de usar para cálculos básicos, pero limitada en análisis avanzados.\nFácil de usar para análisis avanzados estándar.\nRequiere más configuración inicial, pero ofrece mayor control y personalización.\n\n\nManejo de valores faltantes\nManejo básico con argumentos como na.rm = TRUE.\nManejo básico de valores faltantes.\nPermite un manejo avanzado y personalizado de valores faltantes.\n\n\n\nLas funciones base de R son ideales para cálculos rápidos y sencillos, como la media (mean()), mediana (median()), desviación estándar (sd()), varianza (var()), rango (range()), y el resumen general (summary()). Estas funciones son fáciles de usar y están disponibles de forma predeterminada, lo que las convierte en una excelente opción para análisis básicos. Sin embargo, su alcance es limitado cuando se requiere un análisis más detallado o agrupado, ya que no incluyen medidas avanzadas como asimetría o curtosis, ni permiten un análisis categorizado sin pasos adicionales.\nEl paquete psych es una herramienta poderosa y fácil de usar para realizar análisis descriptivos avanzados, especialmente cuando se busca rapidez y simplicidad en el cálculo de estadísticas estándar. Ofrece medidas avanzadas como asimetría y curtosis, y permite realizar análisis agrupados con la función describeBy(). Sin embargo, su enfoque en generar tablas separadas para cada combinación de categorías puede ser una limitación en proyectos que requieren consolidar resultados o realizar análisis más complejos. Además, la personalización de las estadísticas calculadas es limitada, ya que depende de las funciones predefinidas del paquete.\nPor otro lado, la función personalizada destaca por su flexibilidad y capacidad de adaptación. Permite incluir estadísticas adicionales, como la moda, y consolidar resultados en un único dataframe, lo que facilita su manejo y exportación en un formato listo para su uso. Además, ofrece un control total sobre el análisis, permitiendo adaptarlo a necesidades específicas, como el manejo avanzado de valores faltantes o la categorización de variables numéricas. Esto la convierte en una opción ideal para proyectos que demandan un mayor nivel de personalización y control.",
    "crumbs": [
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Estadística descriptiva usando funciones en R</span>"
    ]
  },
  {
    "objectID": "regresion_simple.html",
    "href": "regresion_simple.html",
    "title": "21  Regresión lineal simple usando R",
    "section": "",
    "text": "21.1 Conceptos fundamentales\nLa regresión lineal simple es una técnica estadística utilizada para modelar la relación entre una variable dependiente y una variable independiente. Su propósito principal es predecir el valor de la variable dependiente a partir de la variable independiente, lo que permite entender cómo varía una en función de la otra. Esta técnica es fundamental en el análisis estadístico, ya que proporciona una base para la inferencia y la toma de decisiones en diversos campos (Montgomery, Peck, & Vining, 2012).\nPor ejemplo, en economía, la regresión lineal simple puede utilizarse para predecir el consumo en función del ingreso. En biología, se aplica para analizar la relación entre la dosis de un fármaco y la respuesta de un organismo. En ciencias sociales, se utiliza para estudiar cómo factores como la educación influyen en los ingresos de una población (Field, 2013).\nLas variables dependientes son aquellas que se desean predecir o explicar, mientras que las variables independientes son las que se utilizan para realizar dicha predicción. La diferencia radica en que la variable dependiente es el resultado que se estudia, mientras que la variable independiente es el factor que se manipula o se observa (Cohen, Cohen, West, & Aiken, 2003).\nLa relación lineal implica que existe una conexión directa entre las variables, de tal manera que un cambio en la variable independiente produce un cambio proporcional en la variable dependiente.",
    "crumbs": [
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Regresión lineal simple usando R</span>"
    ]
  },
  {
    "objectID": "regresion_simple.html#modelo-de-regresión-lineal-simple",
    "href": "regresion_simple.html#modelo-de-regresión-lineal-simple",
    "title": "21  Regresión lineal simple usando R",
    "section": "21.2 Modelo de Regresión Lineal Simple",
    "text": "21.2 Modelo de Regresión Lineal Simple\nEl modelo de regresión lineal simple se expresa mediante la siguiente ecuación:\n\n\n\n\n\nEn esta ecuación, Y representa la variable dependiente, X es la variable independiente, ß0 es la intersección (el valor de Y) cuando X) es cero) y ß1 es la pendiente (que indica el cambio en Y) por cada unidad de cambio en X. El término epilson (ε) representa el error del modelo, que captura la variabilidad en Y que no se explica por X (Kutner, Nachtsheim, Neter, & Li, 2005).",
    "crumbs": [
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Regresión lineal simple usando R</span>"
    ]
  },
  {
    "objectID": "regresion_simple.html#supuestos-de-la-regresión-lineal",
    "href": "regresion_simple.html#supuestos-de-la-regresión-lineal",
    "title": "21  Regresión lineal simple usando R",
    "section": "21.3 Supuestos de la Regresión Lineal",
    "text": "21.3 Supuestos de la Regresión Lineal\nPara que el modelo de regresión lineal sea válido, es fundamental que se cumplan ciertos supuestos:\n\nLinealidad: La relación entre las variables debe ser lineal.\nIndependencia: Las observaciones deben ser independientes entre sí.\nHomoscedasticidad: La varianza de los errores debe ser constante a lo largo de todos los niveles de X.\nNormalidad: Los errores deben seguir una distribución normal (Tabachnick & Fidell, 2013).",
    "crumbs": [
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Regresión lineal simple usando R</span>"
    ]
  },
  {
    "objectID": "regresion_simple.html#evaluación-del-modelo",
    "href": "regresion_simple.html#evaluación-del-modelo",
    "title": "21  Regresión lineal simple usando R",
    "section": "21.4 Evaluación del Modelo",
    "text": "21.4 Evaluación del Modelo\nLa calidad del modelo de regresión lineal simple se evalúa a través de varias métricas:\n\nR-cuadrado: Indica la proporción de la variabilidad en la variable dependiente que es explicada por la variable independiente. Un valor cercano a 1 sugiere un buen ajuste del modelo.\nAnálisis de residuos: Es crucial analizar los residuos para verificar los supuestos del modelo, asegurando que no haya patrones sistemáticos que indiquen un mal ajuste (Belsley, Kuh, & Welsch, 1980).",
    "crumbs": [
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Regresión lineal simple usando R</span>"
    ]
  },
  {
    "objectID": "regresion_simple.html#ejemplo-práctico",
    "href": "regresion_simple.html#ejemplo-práctico",
    "title": "21  Regresión lineal simple usando R",
    "section": "21.5 Ejemplo Práctico",
    "text": "21.5 Ejemplo Práctico\nEste ejemplo práctico ilustra cómo realizar un análisis de regresión lineal simple utilizando un conjunto de datos sobre esporofitos. Los datos provienen de un estudio realizado en el laboratorio de cultivo de tejidos de la Facultad de Agronomía de la Universidad de San Carlos de Guatemala. En este estudio, se llevó a cabo la reproducción del helecho conocido como calahuala (Phlebodium pseudoaureum (Cav.) Lellinger).\nSe midió la altura de cada esporofito y se cuantificó la cantidad de esporofitos germinados en 30 frascos que contenían medio de cultivo Murashige y Skoog. Los resultados obtenidos se presentan en el siguiente archivo. Este análisis se basa en la investigación de Rosales Castillo (2005), quien realizó una micropropagación de Calahuala utilizando tres tipos de explantes en diferentes medios de cultivo in vitro.\nEl objetivo de este análisis es evaluar la relación entre la altura de los esporofitos y la cantidad de esporofitos germinados, utilizando la regresión lineal simple como herramienta estadística. A través de este proceso, se busca no solo ajustar un modelo que explique esta relación, sino también verificar los supuestos que sustentan la validez del modelo.\n\n21.5.1 Instalación y Carga de Paquetes\nPara comenzar, es necesario instalar y cargar los paquetes requeridos. Estos paquetes proporcionan funciones útiles para la manipulación de datos y la visualización.\n\n# Instalación y carga de paquetes  \n# Incluye ggplot2, dplyr, tidyr\nif (!require(\"tidyverse\")) install.packages(\"tidyverse\")\n\n# Se utiliza para evaluar el supuesto de homocedasticidad\nif (!require(\"car\")) install.packages(\"car\")\n\n# Se utiliza para importar archivos de Excel\nif (!require(\"readxl\")) install.packages(\"readxl\")\n\nExplicación:\n\ntidyverse: Este paquete incluye varias herramientas para la manipulación y visualización de datos, como ggplot2, dplyr y tidyr.\ncar: Proporciona funciones para realizar pruebas de hipótesis y diagnósticos de modelos, incluyendo la evaluación de homocedasticidad.\nreadxl: Permite importar datos desde archivos de Excel, facilitando la carga de conjuntos de datos.\n\n\n\n21.5.2 Importación de Datos\nA continuación, se importan los datos desde un archivo Excel.\n\n# Importar un archivo csv\ndatos &lt;- read_excel(\"esporofitos.xlsx\")\n\n# Visualizar los primeros registros del data frame\nhead(datos)\n\n# A tibble: 6 × 3\n  frasco cantidad_de_esporofitos altura_mm\n   &lt;dbl&gt;                   &lt;dbl&gt;     &lt;dbl&gt;\n1      1                      40      21.4\n2      2                      45      21  \n3      3                      60      20.5\n4      4                      55      20  \n5      5                      58      21  \n6      6                      40      21.7\n\n\nEste código carga el archivo de Excel que contiene los datos sobre esporofitos y muestra las primeras filas del conjunto de datos para verificar que se haya importado correctamente.\n\n\n21.5.3 Visualización de Datos\nSe elabora un gráfico de dispersión para observar la relación entre las variables.\n\n# Elaboración de un gráfico de dispersión entre altura y cantidad\nplot( datos$altura_mm, datos$cantidad_de_esporofitos)\n\n\n\n\n\n\n\n\nEste gráfico permite visualizar la relación entre la cantidad de esporofitos y la altura en milímetros, facilitando la identificación de patrones. Como se puede apreciar en el gráfico anterior hay una relación inversamente proporcional entre la altura de los esporofitos y la cantidad de esporofitos.\n\n\n21.5.4 Ajuste del Modelo de Regresión\nSe ajusta el modelo de regresión lineal simple utilizando la función lm().\n\n# Ajuste del modelo\nregsimple &lt;- lm(datos$altura_mm ~ datos $cantidad_de_esporofitos)\nsummary(regsimple)\n\n\nCall:\nlm(formula = datos$altura_mm ~ datos$cantidad_de_esporofitos)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.78523 -0.15056  0.01664  0.22403  0.62850 \n\nCoefficients:\n                                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                   22.8933399  0.1446248  158.29   &lt;2e-16 ***\ndatos$cantidad_de_esporofitos -0.0401248  0.0008826  -45.46   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3753 on 28 degrees of freedom\nMultiple R-squared:  0.9866,    Adjusted R-squared:  0.9862 \nF-statistic:  2067 on 1 and 28 DF,  p-value: &lt; 2.2e-16\n\n\nEl resumen del modelo ajustado proporciona información sobre los coeficientes, errores estándar y estadísticas de ajuste, permitiendo evaluar la calidad del modelo.\nExplicación del código:\n\nlm(): Esta función ajusta un modelo de regresión lineal donde la cantidad de esporofitos es la variable dependiente y la altura es la variable independiente.\nsummary(regsimple): Proporciona un resumen del modelo ajustado, incluyendo coeficientes, errores estándar y estadísticas de ajuste.\n\n\n\n21.5.5 Gráficos de Diagnóstico para evaluar los supuestos del modelo\nSe generan gráficos de diagnóstico para evaluar los supuestos del modelo.\n\n# Gráficos de diagnóstico de los supuestos\npar(mfrow=c(1,2)) # Crea una matriz de dos gráficos\nplot(regsimple, which=1:2)\n\n\n\n\n\n\n\npar(mfrow=c(1,1)) # Devuelve a su estado normal el área de gráficos\n\nEstos gráficos ayudan a verificar la linealidad y la homocedasticidad, asegurando que los supuestos del modelo se cumplan.\nExplicación del código:\nplot(regsimple, which=1:2): Genera los gráficos de residuos y ajuste, que ayudan a verificar la linealidad y la homocedasticidad.\n\n\n21.5.6 Prueba de Normalidad de los Residuos\nSe realiza la prueba de Shapiro-Wilk para evaluar la normalidad de los residuos.\n\n# Realizar la prueba de Shapiro-Wilk en los residuos\nshapiro.test(residuals(regsimple))\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(regsimple)\nW = 0.95651, p-value = 0.2516\n\n\nExplicación:\nshapiro.test(residuals(regsimple)): Esta prueba evalúa si los residuos del modelo siguen una distribución normal. Un valor p por debajo del nivel de significancia ( &lt; 0.05) indica que los residuos no son normales. Para el ejemplo el valor de p es de 0.2516 por lo que no se rechaza la hipótesis nula y por lo tanto no hay suficiente evidencia estadística para indicar que los residuos no son normales.\n\n\n21.5.7 Prueba de Homocedasticidad de la varianza\nFinalmente, se evalúa el supuesto de homocedasticidad utilizando la prueba de heterocedasticidad.\n\n# Realizar prueba para el supuesto de homocedasticidad\nncvTest(regsimple)\n\nNon-constant Variance Score Test \nVariance formula: ~ fitted.values \nChisquare = 0.07681442, Df = 1, p = 0.78166\n\n\nExplicación:\nncvTest(regsimple): Esta función evalúa si la varianza de los residuos es constante a lo largo de los valores de la variable independiente. Un valor p menor al nivel de significancia (&lt;0.05) sugiere que hay heterocedasticidad, lo que puede invalidar el modelo. Para este ejemplo el valor de p es 0.78166 por lo que no hay evidencia estadística suficiente para indicar que la varianza de los residuos no es contante.",
    "crumbs": [
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Regresión lineal simple usando R</span>"
    ]
  },
  {
    "objectID": "regresion_multiple.html",
    "href": "regresion_multiple.html",
    "title": "22  Regresión múltiple usando R",
    "section": "",
    "text": "22.1 Notas:\nEn esta sección se desarrollará un ejemplo de regresión multiple\nEsta pendiente de finalización y carga",
    "crumbs": [
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Regresión múltiple usando R</span>"
    ]
  },
  {
    "objectID": "license.html",
    "href": "license.html",
    "title": "Licencia",
    "section": "",
    "text": "Creative Commons Legal Code\nCC0 1.0 Universal\nCREATIVE COMMONS CORPORATION IS NOT A LAW FIRM AND DOES NOT PROVIDE\nLEGAL SERVICES. DISTRIBUTION OF THIS DOCUMENT DOES NOT CREATE AN\nATTORNEY-CLIENT RELATIONSHIP. CREATIVE COMMONS PROVIDES THIS\nINFORMATION ON AN \"AS-IS\" BASIS. CREATIVE COMMONS MAKES NO WARRANTIES\nREGARDING THE USE OF THIS DOCUMENT OR THE INFORMATION OR WORKS\nPROVIDED HEREUNDER, AND DISCLAIMS LIABILITY FOR DAMAGES RESULTING FROM\nTHE USE OF THIS DOCUMENT OR THE INFORMATION OR WORKS PROVIDED\nHEREUNDER.\nStatement of Purpose\nThe laws of most jurisdictions throughout the world automatically confer exclusive Copyright and Related Rights (defined below) upon the creator and subsequent owner(s) (each and all, an “owner”) of an original work of authorship and/or a database (each, a “Work”).\nCertain owners wish to permanently relinquish those rights to a Work for the purpose of contributing to a commons of creative, cultural and scientific works (“Commons”) that the public can reliably and without fear of later claims of infringement build upon, modify, incorporate in other works, reuse and redistribute as freely as possible in any form whatsoever and for any purposes, including without limitation commercial purposes. These owners may contribute to the Commons to promote the ideal of a free culture and the further production of creative, cultural and scientific works, or to gain reputation or greater distribution for their Work in part through the use and efforts of others.\nFor these and/or other purposes and motivations, and without any expectation of additional consideration or compensation, the person associating CC0 with a Work (the “Affirmer”), to the extent that he or she is an owner of Copyright and Related Rights in the Work, voluntarily elects to apply CC0 to the Work and publicly distribute the Work under its terms, with knowledge of his or her Copyright and Related Rights in the Work and the meaning and intended legal effect of CC0 on those rights.\n\nCopyright and Related Rights. A Work made available under CC0 may be protected by copyright and related or neighboring rights (“Copyright and Related Rights”). Copyright and Related Rights include, but are not limited to, the following:\n\n\n\nthe right to reproduce, adapt, distribute, perform, display, communicate, and translate a Work;\nmoral rights retained by the original author(s) and/or performer(s);\npublicity and privacy rights pertaining to a person’s image or likeness depicted in a Work;\nrights protecting against unfair competition in regards to a Work, subject to the limitations in paragraph 4(a), below;\nrights protecting the extraction, dissemination, use and reuse of data in a Work;\ndatabase rights (such as those arising under Directive 96/9/EC of the European Parliament and of the Council of 11 March 1996 on the legal protection of databases, and under any national implementation thereof, including any amended or successor version of such directive); and\nother similar, equivalent or corresponding rights throughout the world based on applicable law or treaty, and any national implementations thereof.\n\n\n\nWaiver. To the greatest extent permitted by, but not in contravention of, applicable law, Affirmer hereby overtly, fully, permanently, irrevocably and unconditionally waives, abandons, and surrenders all of Affirmer’s Copyright and Related Rights and associated claims and causes of action, whether now known or unknown (including existing as well as future claims and causes of action), in the Work (i) in all territories worldwide, (ii) for the maximum duration provided by applicable law or treaty (including future time extensions), (iii) in any current or future medium and for any number of copies, and (iv) for any purpose whatsoever, including without limitation commercial, advertising or promotional purposes (the “Waiver”). Affirmer makes the Waiver for the benefit of each member of the public at large and to the detriment of Affirmer’s heirs and successors, fully intending that such Waiver shall not be subject to revocation, rescission, cancellation, termination, or any other legal or equitable action to disrupt the quiet enjoyment of the Work by the public as contemplated by Affirmer’s express Statement of Purpose.\nPublic License Fallback. Should any part of the Waiver for any reason be judged legally invalid or ineffective under applicable law, then the Waiver shall be preserved to the maximum extent permitted taking into account Affirmer’s express Statement of Purpose. In addition, to the extent the Waiver is so judged Affirmer hereby grants to each affected person a royalty-free, non transferable, non sublicensable, non exclusive, irrevocable and unconditional license to exercise Affirmer’s Copyright and Related Rights in the Work (i) in all territories worldwide, (ii) for the maximum duration provided by applicable law or treaty (including future time extensions), (iii) in any current or future medium and for any number of copies, and (iv) for any purpose whatsoever, including without limitation commercial, advertising or promotional purposes (the “License”). The License shall be deemed effective as of the date CC0 was applied by Affirmer to the Work. Should any part of the License for any reason be judged legally invalid or ineffective under applicable law, such partial invalidity or ineffectiveness shall not invalidate the remainder of the License, and in such case Affirmer hereby affirms that he or she will not (i) exercise any of his or her remaining Copyright and Related Rights in the Work or (ii) assert any associated claims and causes of action with respect to the Work, in either case contrary to Affirmer’s express Statement of Purpose.\nLimitations and Disclaimers.\n\n\n\nNo trademark or patent rights held by Affirmer are waived, abandoned, surrendered, licensed or otherwise affected by this document.\nAffirmer offers the Work as-is and makes no representations or warranties of any kind concerning the Work, express, implied, statutory or otherwise, including without limitation warranties of title, merchantability, fitness for a particular purpose, non infringement, or the absence of latent or other defects, accuracy, or the present or absence of errors, whether or not discoverable, all to the greatest extent permissible under applicable law.\nAffirmer disclaims responsibility for clearing rights of other persons that may apply to the Work or any use thereof, including without limitation any person’s Copyright and Related Rights in the Work. Further, Affirmer disclaims responsibility for obtaining any necessary consents, permissions or other rights required for any use of the Work.\nAffirmer understands and acknowledges that Creative Commons is not a party to this document and has no duty or obligation with respect to this CC0 or use of the Work."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introducción al entorno de programacón R y su aplicación en el análisis estadístico de datos",
    "section": "",
    "text": "Introducción\nLa estadística clásica constituye un pilar esencial en la investigación científica y en la toma de decisiones fundamentadas en datos. Este manual ha sido elaborado para quienes se inician en el análisis estadístico, con el objetivo de introducir de manera gradual y comprensible las herramientas fundamentales del lenguaje R, ampliamente reconocido en la ciencia de datos y la estadística aplicada. A lo largo del texto, se abordan desde los conceptos básicos hasta técnicas más avanzadas, acompañando la teoría con ejemplos prácticos que facilitan la comprensión y la aplicación en contextos reales. El propósito central es ofrecer una base sólida que permita a los lectores utilizar R de forma efectiva en el análisis de datos, sin requerir experiencia previa en programación o estadística (Ihaka & Gentleman, 1996; R Core Team, 2023).",
    "crumbs": [
      "Introducción"
    ]
  },
  {
    "objectID": "index.html#propósito-del-manual",
    "href": "index.html#propósito-del-manual",
    "title": "Introducción al entorno de programacón R y su aplicación en el análisis estadístico de datos",
    "section": "Propósito del manual",
    "text": "Propósito del manual\nEl manual está diseñado para guiar a personas principiantes en el uso de R, abarcando desde la instalación y configuración del entorno hasta la aplicación de técnicas estadísticas clásicas y modernas. Se exploran temas como la manipulación y visualización de datos, la gestión de proyectos, la exportación de resultados y la realización de análisis estadísticos descriptivos e inferenciales. Cada tema se desarrolla con ejemplos prácticos y ejercicios que permiten aplicar los conocimientos adquiridos en situaciones reales. Además, se enfatiza el uso de R como una herramienta de código abierto, destacando su flexibilidad, capacidad de extensión y su papel en la promoción de la reproducibilidad científica (Ihaka & Gentleman, 1996; R Core Team, 2023).\nA lo largo del manual, se presentan las principales características de R y su entorno de desarrollo integrado, RStudio, resaltando su utilidad tanto en proyectos académicos como profesionales. El texto está dirigido a estudiantes, investigadores y profesionales interesados en adquirir competencias en programación estadística, priorizando la claridad, la organización y la reproducibilidad en los análisis.",
    "crumbs": [
      "Introducción"
    ]
  },
  {
    "objectID": "index.html#organización-del-manual",
    "href": "index.html#organización-del-manual",
    "title": "Introducción al entorno de programacón R y su aplicación en el análisis estadístico de datos",
    "section": "Organización del manual",
    "text": "Organización del manual\nEl contenido del manual se estructura de manera progresiva, iniciando con los aspectos más elementales y avanzando hacia herramientas y técnicas estadísticas de mayor complejidad. Cada sección incluye explicaciones detalladas, ejemplos prácticos y ejercicios diseñados para consolidar el aprendizaje. Asimismo, se incorporan recomendaciones y buenas prácticas que facilitan la asimilación de los conceptos y fomentan la reproducibilidad en los análisis realizados.\nEl manual se organiza en los siguientes capítulos principales:\n\nIntroducción a R y RStudio: En este capítulo se presentan los conceptos básicos de R y RStudio, incluyendo sus características principales, el proceso de instalación y configuración, así como la preparación del entorno de trabajo para el análisis de datos.\nConceptos básicos de R: Se abordan los fundamentos esenciales del lenguaje R, tales como los primeros pasos en la consola, la estructura de los datos, la importación de información, el uso de operadores, funciones y la gestión de paquetes.\nManipulación de datos: Este apartado introduce las técnicas fundamentales para la manipulación de datos en R, utilizando tanto las herramientas base del lenguaje como los paquetes dplyr y tidyr, permitiendo transformar, organizar y preparar los datos para su análisis.\nVisualización de datos: Se exploran las distintas opciones para la visualización de datos, comenzando con las herramientas básicas de R y avanzando hacia la creación de gráficos personalizados mediante el paquete ggplot2, facilitando la interpretación y comunicación de los resultados.\nGestión y exportación de resultados: En este capítulo se explica cómo gestionar proyectos en R, exportar resultados de análisis, gráficos y tablas en formatos adecuados para su uso en informes y presentaciones, así como la integración con herramientas de control de versiones como Git y GitHub.\nMaterial de apoyo y referencias: Se proporcionan recursos adicionales, materiales de consulta y referencias bibliográficas que permiten profundizar en el aprendizaje y la aplicación de R en distintos contextos.\nEjemplos de análisis estadístico con R: Finalmente, se desarrollan ejemplos detallados de análisis estadístico, incluyendo estadística descriptiva, regresión lineal simple y múltiple, mostrando la aplicación práctica de R en el análisis de datos reales.\n\nCada capítulo está diseñado para ser independiente, permitiendo que los lectores avancen a su propio ritmo y consulten las secciones según sus necesidades.",
    "crumbs": [
      "Introducción"
    ]
  },
  {
    "objectID": "index.html#pre-requisitos",
    "href": "index.html#pre-requisitos",
    "title": "Introducción al entorno de programacón R y su aplicación en el análisis estadístico de datos",
    "section": "Pre requisitos",
    "text": "Pre requisitos\nEste manual no requiere conocimientos previos en programación ni en análisis estadístico. Está diseñado específicamente para principiantes, por lo que se parte desde cero, explicando cada concepto de manera clara y detallada. Todo lo que se necesita es:\n\nInterés por aprender: La curiosidad y disposición para explorar un nuevo lenguaje de programación.\nAcceso a una computadora: Con capacidad para instalar R y RStudio, herramientas que se explican paso a paso en el manual.\nPaciencia y práctica: Como cualquier habilidad nueva, aprender R requiere tiempo y dedicación. Los ejemplos y ejercicios incluidos están diseñados para facilitar este proceso.\n\nCon este enfoque, cualquier persona, independientemente de su experiencia previa, podrá utilizar este manual como una guía para iniciarse en el análisis estadístico con R.",
    "crumbs": [
      "Introducción"
    ]
  },
  {
    "objectID": "index.html#software-y-convenciones",
    "href": "index.html#software-y-convenciones",
    "title": "Introducción al entorno de programacón R y su aplicación en el análisis estadístico de datos",
    "section": "Software y convenciones",
    "text": "Software y convenciones\nLa versión en línea de este manual está disponible en https://introduccion-r-cete.vercel.app/, y la fuente en español se encuentra alojada en el repositorio de GitHub https://github.com/Ludwing-MJ/introduccion_R_CETE. El desarrollo del manual se realizó utilizando Quarto, una herramienta que permite transformar archivos con extensión .qmd en formatos publicables como HTML, PDF y EPUB, facilitando la integración de código, resultados y texto en un solo documento reproducible.\nDurante la elaboración del manual se emplearon diversos paquetes del ecosistema de R, entre los que destacan knitr y bookdown, los cuales permiten combinar las ventajas de LaTeX y R para la generación de documentos dinámicos y reproducibles (Xie, 2015; Xie, 2024). Esta integración posibilita que los ejemplos de código y los resultados presentados sean fácilmente replicables por el lector.\nA lo largo del manual, se presentan fragmentos de código que pueden ser copiados y ejecutados directamente en la consola de R para obtener los mismos resultados que se muestran en el texto. Los bloques de código se destacan en recuadros similares al siguiente:\n\n4 + 6\na &lt;- c(1, 5, 6)\n5 * a\n1:10\n\nLos resultados generados por la ejecución de estos códigos se identifican con el numero uno encerrado entre cochetes ([1]) al inicio de cada línea, indicando que corresponden a la salida producida por R. Todo lo que comience con [1] representa resultados y no debe ser copiado como parte del código. Por ejemplo, al ejecutar el bloque anterior, se obtendrían los siguientes resultados:\n\n\n[1] 10\n\n\n[1]  5 25 30\n\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\nPara garantizar la reproducibilidad y transparencia, se recomienda que el lector utilice versiones actualizadas de R y de los paquetes mencionados. La información sobre el entorno de desarrollo y las versiones de los paquetes utilizados en la construcción de este manual puede consultarse ejecutando el siguiente comando en R:\n\ndevtools::session_info()\n\nWarning in system2(\"quarto\", \"-V\", stdout = TRUE, env = paste0(\"TMPDIR=\", : el\ncomando ejecutado '\"quarto\"\nTMPDIR=C:/Users/Usuario/AppData/Local/Temp/RtmpUDth68/file44a8592361ca -V'\ntiene el estatus 1\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.4.2 (2024-10-31 ucrt)\n os       Windows 11 x64 (build 26100)\n system   x86_64, mingw32\n ui       RTerm\n language (EN)\n collate  Spanish_Guatemala.utf8\n ctype    Spanish_Guatemala.utf8\n tz       America/Guatemala\n date     2025-04-21\n pandoc   3.2 @ C:/Program Files/RStudio/resources/app/bin/quarto/bin/tools/ (via rmarkdown)\n quarto   NA @ C:\\\\Users\\\\Usuario\\\\AppData\\\\Local\\\\Programs\\\\Quarto\\\\bin\\\\quarto.exe\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version date (UTC) lib source\n cachem        1.1.0   2024-05-16 [1] CRAN (R 4.4.2)\n cli           3.6.3   2024-06-21 [1] CRAN (R 4.4.2)\n devtools      2.4.5   2022-10-11 [1] CRAN (R 4.4.3)\n digest        0.6.37  2024-08-19 [1] CRAN (R 4.4.2)\n ellipsis      0.3.2   2021-04-29 [1] CRAN (R 4.4.3)\n evaluate      1.0.3   2025-01-10 [1] CRAN (R 4.4.2)\n fastmap       1.2.0   2024-05-15 [1] CRAN (R 4.4.2)\n fs            1.6.5   2024-10-30 [1] CRAN (R 4.4.2)\n glue          1.8.0   2024-09-30 [1] CRAN (R 4.4.2)\n htmltools     0.5.8.1 2024-04-04 [1] CRAN (R 4.4.2)\n htmlwidgets   1.6.4   2023-12-06 [1] CRAN (R 4.4.3)\n httpuv        1.6.15  2024-03-26 [1] CRAN (R 4.4.3)\n jsonlite      1.8.9   2024-09-20 [1] CRAN (R 4.4.2)\n knitr         1.49    2024-11-08 [1] CRAN (R 4.4.2)\n later         1.4.1   2024-11-27 [1] CRAN (R 4.4.3)\n lifecycle     1.0.4   2023-11-07 [1] CRAN (R 4.4.2)\n magrittr      2.0.3   2022-03-30 [1] CRAN (R 4.4.2)\n memoise       2.0.1   2021-11-26 [1] CRAN (R 4.4.2)\n mime          0.12    2021-09-28 [1] CRAN (R 4.4.0)\n miniUI        0.1.1.1 2018-05-18 [1] CRAN (R 4.4.3)\n pkgbuild      1.4.6   2025-01-16 [1] CRAN (R 4.4.3)\n pkgload       1.4.0   2024-06-28 [1] CRAN (R 4.4.3)\n profvis       0.4.0   2024-09-20 [1] CRAN (R 4.4.3)\n promises      1.3.2   2024-11-28 [1] CRAN (R 4.4.3)\n purrr         1.0.4   2025-02-05 [1] CRAN (R 4.4.2)\n R6            2.5.1   2021-08-19 [1] CRAN (R 4.4.2)\n Rcpp          1.0.14  2025-01-12 [1] CRAN (R 4.4.2)\n remotes       2.5.0   2024-03-17 [1] CRAN (R 4.4.3)\n rlang         1.1.5   2025-01-17 [1] CRAN (R 4.4.2)\n rmarkdown     2.29    2024-11-04 [1] CRAN (R 4.4.2)\n rstudioapi    0.17.1  2024-10-22 [1] CRAN (R 4.4.2)\n sessioninfo   1.2.3   2025-02-05 [1] CRAN (R 4.4.3)\n shiny         1.10.0  2024-12-14 [1] CRAN (R 4.4.3)\n urlchecker    1.0.1   2021-11-30 [1] CRAN (R 4.4.3)\n usethis       3.1.0   2024-11-26 [1] CRAN (R 4.4.3)\n vctrs         0.6.5   2023-12-01 [1] CRAN (R 4.4.2)\n xfun          0.50    2025-01-07 [1] CRAN (R 4.4.2)\n xtable        1.8-4   2019-04-21 [1] CRAN (R 4.4.3)\n\n [1] C:/Users/Usuario/AppData/Local/R/win-library/4.4\n [2] C:/Program Files/R/R-4.4.2/library\n\n──────────────────────────────────────────────────────────────────────────────",
    "crumbs": [
      "Introducción"
    ]
  },
  {
    "objectID": "10.3_exportacion.html#importación-de-repositorios-de-github-para-trabajo-local-o-personal",
    "href": "10.3_exportacion.html#importación-de-repositorios-de-github-para-trabajo-local-o-personal",
    "title": "17  Uso de Git y GitHub en Proyectos de R",
    "section": "17.4 Importación de repositorios de GitHub para trabajo local o personal",
    "text": "17.4 Importación de repositorios de GitHub para trabajo local o personal\nImportar un repositorio de GitHub permite descargar una copia completa del proyecto para trabajar localmente, modificarlo o adaptarlo a nuevas necesidades. Este proceso se conoce como “clonar” un repositorio y es útil tanto para uso personal como para colaborar en proyectos de otros usuarios.\nPasos para clonar un repositorio de GitHub:\n1. Obtener la URL del repositorio\nEn la página del repositorio en GitHub, hacer clic en el botón “Code” y copiar la URL que aparece (por ejemplo, https://github.com/usuario/analisis_estadistico.git).\n2. Clonar el repositorio en la computadora local\nAbrir una terminal o la consola de RStudio y ejecutar el siguiente comando:\n\ngit clone https://github.com/usuario/analisis_estadistico.git\n\nEsto creará una carpeta local con todos los archivos y el historial del proyecto.\n3. Trabajar localmente\nUna vez clonado el repositorio, se puede abrir la carpeta en RStudio, modificar los archivos, ejecutar los scripts y exportar nuevos resultados. Si se tiene permiso para hacerlo, los cambios pueden subirse nuevamente a GitHub con los comandos git add, git commit y git push. Si el objetivo es solo uso personal, los cambios pueden mantenerse localmente sin necesidad de sincronizarlos con el repositorio remoto.\nVentajas de clonar repositorios:\n\nPermite reutilizar análisis existentes y aprender de otros proyectos.\nFacilita la colaboración en equipo, ya que todos los miembros trabajan con la misma versión del proyecto.\nAsegura la trazabilidad y la integridad del trabajo, ya que todo el historial de cambios se conserva.\n\nLa importación de repositorios es una práctica recomendada para quienes desean aprovechar recursos existentes, colaborar en proyectos abiertos o mantener una copia de seguridad de su trabajo (Bryan, 2018).",
    "crumbs": [
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Uso de Git y GitHub en Proyectos de R</span>"
    ]
  }
]